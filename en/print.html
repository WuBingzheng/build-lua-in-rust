<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Build a Lua Interpreter in Rust</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="PREFACE.html">Preface</a></li><li class="chapter-item expanded "><a href="ch01-00.hello_world.html"><strong aria-hidden="true">1.</strong> hello, world!</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch01-01.principles.html"><strong aria-hidden="true">1.1.</strong> Basic Compilation Principles</a></li><li class="chapter-item expanded "><a href="ch01-02.byte_codes.html"><strong aria-hidden="true">1.2.</strong> Bytecode</a></li><li class="chapter-item expanded "><a href="ch01-03.value_and_type.html"><strong aria-hidden="true">1.3.</strong> Value and Type</a></li><li class="chapter-item expanded "><a href="ch01-04.lets_do_it.html"><strong aria-hidden="true">1.4.</strong> Let's Do It!</a></li></ol></li><li class="chapter-item expanded "><a href="ch02-00.variables.html"><strong aria-hidden="true">2.</strong> Variables and Assignments</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch02-01.more_types.html"><strong aria-hidden="true">2.1.</strong> More Types</a></li><li class="chapter-item expanded "><a href="ch02-02.local.html"><strong aria-hidden="true">2.2.</strong> Local Variables</a></li><li class="chapter-item expanded "><a href="ch02-03.assignment.html"><strong aria-hidden="true">2.3.</strong> Variable Assignment</a></li></ol></li><li class="chapter-item expanded "><a href="ch03-00.optimize_string.html"><strong aria-hidden="true">3.</strong> String Optimization</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch03-01.string_type.html"><strong aria-hidden="true">3.1.</strong> String Definition</a></li><li class="chapter-item expanded "><a href="ch03-02.from_trait.html"><strong aria-hidden="true">3.2.</strong> Type Conversion</a></li><li class="chapter-item expanded "><a href="ch03-03.read_input.html"><strong aria-hidden="true">3.3.</strong> Input Type</a></li><li class="chapter-item expanded "><a href="ch03-04.unicode_utf8.html"><strong aria-hidden="true">3.4.</strong> Unicode and UTF-8</a></li><li class="chapter-item expanded "><a href="ch03-05.gc_vs_rc.html"><strong aria-hidden="true">3.5.</strong> Garbage Collection and Rc</a></li></ol></li><li class="chapter-item expanded "><a href="ch04-00.table.html"><strong aria-hidden="true">4.</strong> Table and ExpDesc</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch04-01.table_definition.html"><strong aria-hidden="true">4.1.</strong> Table Definition</a></li><li class="chapter-item expanded "><a href="ch04-02.table_constructor.html"><strong aria-hidden="true">4.2.</strong> Table Construction</a></li><li class="chapter-item expanded "><a href="ch04-03.expdesc.html"><strong aria-hidden="true">4.3.</strong> ExpDesc Concept</a></li><li class="chapter-item expanded "><a href="ch04-04.expdesc_rewrite.html"><strong aria-hidden="true">4.4.</strong> ExpDesc Rewrite</a></li><li class="chapter-item expanded "><a href="ch04-05.table_rw_and_bnf.html"><strong aria-hidden="true">4.5.</strong> Table Read/Write and BNF</a></li></ol></li><li class="chapter-item expanded "><a href="ch05-00.arithmetic_ops.html"><strong aria-hidden="true">5.</strong> Numerical Operations</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch05-01.unary_ops.html"><strong aria-hidden="true">5.1.</strong> Unary Operations</a></li><li class="chapter-item expanded "><a href="ch05-02.binary_ops.html"><strong aria-hidden="true">5.2.</strong> Binary Operations</a></li><li class="chapter-item expanded "><a href="ch05-03.int_and_float.html"><strong aria-hidden="true">5.3.</strong> Integer and Float</a></li></ol></li><li class="chapter-item expanded "><a href="ch06-00.control_structures.html"><strong aria-hidden="true">6.</strong> Control Structures</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch06-01.if.html"><strong aria-hidden="true">6.1.</strong> if Statement</a></li><li class="chapter-item expanded "><a href="ch06-02.elseif_else.html"><strong aria-hidden="true">6.2.</strong> elseif and else Branches</a></li><li class="chapter-item expanded "><a href="ch06-03.while_break.html"><strong aria-hidden="true">6.3.</strong> while and break Statements</a></li><li class="chapter-item expanded "><a href="ch06-04.repeat_continue.html"><strong aria-hidden="true">6.4.</strong> repeat and continue Statements</a></li><li class="chapter-item expanded "><a href="ch06-05.numerical-for.html"><strong aria-hidden="true">6.5.</strong> numerical-for Statement</a></li><li class="chapter-item expanded "><a href="ch06-06.goto.html"><strong aria-hidden="true">6.6.</strong> goto Statement</a></li></ol></li><li class="chapter-item expanded "><a href="ch07-00.logical_relational.html"><strong aria-hidden="true">7.</strong> Logical and Relational Operations</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch07-01.logical_in_condition.html"><strong aria-hidden="true">7.1.</strong> Logical Operations in Conditional Judgment</a></li><li class="chapter-item expanded "><a href="ch07-02.logical_in_evalue.html"><strong aria-hidden="true">7.2.</strong> Logical Operations in Evalue</a></li><li class="chapter-item expanded "><a href="ch07-03.relational_in_condition.html"><strong aria-hidden="true">7.3.</strong> Relational Operations in Conditional Judgment</a></li><li class="chapter-item expanded "><a href="ch07-04.relational_in_evalue.html"><strong aria-hidden="true">7.4.</strong> Relational Operations in Evalue</a></li></ol></li><li class="chapter-item expanded "><a href="ch08-00.function.html"><strong aria-hidden="true">8.</strong> Function</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch08-01.define_and_call.html"><strong aria-hidden="true">8.1.</strong> Definition and Call</a></li><li class="chapter-item expanded "><a href="ch08-02.arguments.html"><strong aria-hidden="true">8.2.</strong> Arguments</a></li><li class="chapter-item expanded "><a href="ch08-03.results.html"><strong aria-hidden="true">8.3.</strong> Return Value</a></li><li class="chapter-item expanded "><a href="ch08-04.rust_functions_and_api.html"><strong aria-hidden="true">8.4.</strong> Rust Functions and API</a></li><li class="chapter-item expanded "><a href="ch08-05.tail_call.html"><strong aria-hidden="true">8.5.</strong> Tail Call</a></li></ol></li><li class="chapter-item expanded "><a href="ch09-00.closure.html"><strong aria-hidden="true">9.</strong> Closure</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch09-01.upvalue.html"><strong aria-hidden="true">9.1.</strong> Upvalue</a></li><li class="chapter-item expanded "><a href="ch09-02.escape_and_closure.html"><strong aria-hidden="true">9.2.</strong> Upvalue Escape and Closure</a></li><li class="chapter-item expanded "><a href="ch09-03.escape_from_block_and_goto.html"><strong aria-hidden="true">9.3.</strong> Escape from Block and goto</a></li><li class="chapter-item expanded "><a href="ch09-04.rust_closure.html"><strong aria-hidden="true">9.4.</strong> Rust Closures</a></li><li class="chapter-item expanded "><a href="ch09-05.generic_for.html"><strong aria-hidden="true">9.5.</strong> generic-for Statement</a></li><li class="chapter-item expanded "><a href="ch09-06.environment.html"><strong aria-hidden="true">9.6.</strong> Environment _ENV</a></li></ol></li><li class="chapter-item expanded "><a href="TO_BE_CONTINUED.html">To Be Continued</a></li><li class="chapter-item expanded affix "><a href="REFERENCES.html">References</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Build a Lua Interpreter in Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/WuBingzheng/build-lua-in-rust" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="preface"><a class="header" href="#preface">Preface</a></h1>
<blockquote>
<p>This series was <a href="https://wubingzheng.github.io/build-lua-in-rust/zh/">written in Chinese</a> originally. This English version is mainly translated by <a href="https://translate.google.com/">Google Translate</a>. So please forgive me for the terrible writing.</p>
</blockquote>
<p>This series of articles introduces the implementation of a Lua interpreter from scratch in the Rust language.</p>
<p>The Rust language has a distinctive personality and is also <a href="https://survey.stackoverflow.co/2022/?utm_source=so-owned&amp;utm_medium=announcement-banner&amp;utm_campaign=dev-survey-2022&amp;utm_content=results#section-most-loved-dreaded-and-wanted-programming-scripting-and-markup-languages">widely popular</a>, however the learning curve is steep. After I finished reading <a href="https://doc.rust-lang.org/stable/book/title-page.html">&quot;Rust Programming Language&quot;</a> and wrote some practice codes, I deeply felt that I had to go through a larger project practice to understand and master.</p>
<p><a href="http://lua-users.org/wiki/LuaImplementations">Implementing a Lua Interpreter</a> is very suitable as this exercise project. Because of its moderate scale, it is enough to cover most of the basic features of Rust without being difficult to reach; <a href="https://www.lua.org/manual/5.4/">clear goal</a>, no need to spend energy discussing requirements; in addition, Lua language It is also an excellently designed and widely used language. Implementing a Lua interpreter can not only practice Rust language skills, but also gain an in-depth understanding of Lua language.</p>
<p>This series of articles documents the learning and exploration process during this project. Similar to other from scratch <a href="https://build-your-own-x.vercel.app/">Build your own X</a> projects, this project also has a clear big goal, an unknown exploration process and a continuous sense of accomplishment, but with some differences:</p>
<ul>
<li>
<p>Most of the authors of other projects have been immersed in related fields for many years, but my job is not in the direction of programming language or compilation principles. I don't have complete theoretical knowledge for implementing an interpreter, and I just cross the river by feeling the stones. But think of the good in everything, which also <a href="https://en.wikipedia.org/wiki/Curse_of_knowledge">provides a real beginner's perspective</a>.</p>
</li>
<li>
<p>Most of the other projects are for the purpose of learning or teaching, simplifying the complexity and realizing a prototype with only the most basic functions. But my goal is to implement a production-level Lua interpreter, pursuing stability, completeness, and performance.</p>
</li>
</ul>
<p>In addition, since the original intention of the project is to learn the Rust language, there will also be some learning notes and usage experience of the Rust language in the article.</p>
<h2 id="content"><a class="header" href="#content">Content</a></h2>
<p>The content is organized as follows. Chapter 1 implements a minimal interpreter that can only parse <code>print &quot;hello, world!&quot;</code> statements. Although simple, it includes the complete process of the interpreter and builds the basic framework. Subsequent chapters will gradually add Lua features to this minimal interpreter.</p>
<p>Chapter 2 introduces the most basic concepts of types and variables in programming languages. Chapter 3 introduces several features of the Rust language with the goal of perfecting the string type. Chapter 4 implements the table structure in Lua and introduces the key ExpDesc concept in syntax analysis. Chapter 5 is about tedious arithmetic calculations.</p>
<p>In Chapter 6 Control Structures, things start to get interesting, jumping back and forth between bytecodes based on judgment conditions. Chapter 7 introduces logical and relational operations, combined with the control structures of the previous chapter through specific optimizations.</p>
<p>Chapter 8 introduces functions. The basic concept and implementation of functions are relatively simple, but variable parameters and multiple return values require careful management of the stack. The closure introduced in Chapter 9 is a powerful feature in the Lua language, and the key here is Upvalue and its escape.</p>
<p>Every feature is designed on demand, but not completed in one step like a prophet. Take the conditional jump instruction as example, at the beginning, in order to support the <a href="./ch06-01.if.html"><code>if</code> statement</a>, we add <code>Test(u8, u16)</code> bytecode, which means if the value of the first associated parameter is <em>false</em>, then jump <em>forward</em> to the distance represented by the second associated parameter; then in order to support the <a href="./ch06-03.while_break.html"><code>while</code> statement</a> and need to jump <em>backward</em>, we change the second associated parameter from <code>u16</code> to <code>i16</code> type, and use a negative number to represent backward jump; then in order to support <a href="./ch07-01.logical_in_condition.html">logical operations</a>, which may jump if <em>true</em> or <em>false</em> both, we add <code>TestAndJump</code> and <code>TestOrJump</code> two bytecodes to replace <code>Test</code>. As a result, according to our own learning and development path, we produced a set of bytecodes slightly different from the official version of Lua.</p>
<p>Each chapter starts with Lua's functional features, discussing how to design and then introducing specific implementations. It's not only important to explain &quot;how to do it,&quot; but also to explain &quot;why to do it&quot;. However, to achieve complete Lua features, some articles may be boring, especially in the first few chapters. Readers can browse the relatively interesting <a href="./ch03-01.string_type.html">Definition of String Type</a> and <a href="./ch09-02.escape_and_closure.html">Escape of Upvalue</a>, to judge whether this series of articles is to your taste.</p>
<p>Each chapter has a complete <a href="https://github.com/WuBingzheng/build-lua-in-rust/tree/main/listing">runnable code</a>, and the code for each chapter is based on the final code of the previous chapter, ensuring that the entire project is continuous. In the beginning chapters, after introducing the design principles, the code will be explained line by line; later on, only the key parts of the code will be explained; and in the last two chapters will basically not talk about the code.</p>
<p>At present, these chapters only complete the core part of the Lua interpreter, and are still far from a complete interpreter. The <a href="./TO_BE_CONTINUED.html">To be continued</a> section lists a partial list of unfinished features.</p>
<p>The basic syntax of Lua and Rust will not be explained in this article. We expect readers to have a basic understanding of both languages. The more familiar with the Lua language, the better. There are no high requirements for the Rust language, as long as you have read &quot;Rust Programming Language&quot; and understand the basic grammar. After all, the original intention of this project is to learn Rust. In addition, when it comes to implementing a language interpreter, it will remind people of the difficult compilation principle. However, in reality, since Lua is a very simple language and there is Lua's official implementation of the interpreter code as a reference, this project requires little theoretical knowledge and is mainly focused on practical engineering.</p>
<p>Due to my limited technical ability in compiling principles, Lua language, Rust language, etc., there must be mistakes in projects and articles. In addition, this English version articles are automatically translated from the <a href="https://wubingzheng.github.io/build-lua-in-rust/zh/">Chinese version</a> mostly, so there may be many not appropriate or not fluent sentences. You are welcome to come to the project's <a href="https://github.com/WuBingzheng/build-lua-in-rust">github homepage</a> to submit issue feedback.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hello-world"><a class="header" href="#hello-world">hello, world!</a></h1>
<p>Following the tradition of introducing programming languages, we start with &quot;hello, world!&quot;. However, instead of writing a program to directly output this sentence, we need to implement a minimal Lua interpreter to interpret and execute the following Lua code:</p>
<pre><code class="language-lua">print &quot;hello, world!&quot;
</code></pre>
<p>Although this code is simple, our minimal version of the interpreter will still contain the complete process of a general-purpose interpreter, including steps such as lexical analysis, syntax analysis, bytecode generation, and virtual machine execution. In the future, as long as features are added on the basis of this process, a complete Lua interpreter can be gradually realized.</p>
<p>However, this Lua code is not as simple as it seems. It contains many concepts such as global variables (print), string constants (&quot;hello, world!&quot;), standard library (print) and function calls. These concepts depend on Lua's internal concepts such as values and stacks. Being able to interpret and execute this code gives you an intuitive understanding of how the interpreter works.</p>
<p>In order to complete this interpreter, this chapter first introduces the necessary knowledge of compilation principles. This should be the only theoretical part in the entire series of articles, and it may also be the section with the most errors. It then introduces the two core concepts of bytecode and value. Then gradually implement lexical analysis, syntax analysis and virtual machine. Finally, an interpreter (only) capable of executing the above Lua code is completed.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compilation-principle"><a class="header" href="#compilation-principle">Compilation principle</a></h1>
<p>The principle of compilation is a very profound and mature subject. It is not necessary or capable to give a complete or accurate introduction here. It is just a simple concept introduction according to the subsequent implementation process. If you are familiar with the concept of an interpreter, you can skip this section.</p>
<h2 id="compiled-and-interpreted-language"><a class="header" href="#compiled-and-interpreted-language">Compiled and Interpreted language</a></h2>
<p>Regardless of the programming language, before the source code is handed over to the computer for execution, a translation process is necessary to translate the source code into a computer-executable language. According to the timing of this translation, programming languages can be roughly divided into two types:</p>
<ul>
<li>
<p>Compiled type, that is, the compiler first compiles the source code into a computer language and generates an executable file. This file is subsequently executed directly by the computer. For example, under Linux, use the compiler gcc to compile the C language source code into an executable file.</p>
</li>
<li>
<p>Interpreted type requires an interpreter, which loads and parses the source program in real time, and then maps the parsed results to pre-compiled subroutine and executes them. This interpreter is generally implemented by the above compiled language.</p>
</li>
</ul>
<pre><code>                                                                    interprete
+-------------+  compile  +-----------------+      +-------------+  &amp; execute   +-----------------+
| source file | --------&gt; | executable file |      | source file | -----------&gt; | Lua interpreter |
|  bar.c      |           |  bar.exe        |      |  bar.lua    |              |  lua.exe        |
+-------------+           +-----------------+      +-------------+              +-----------------+
                               ^                                                     ^
                               | execute                                             | execute
                               | machine code                                        | machine code
                           +----------------+                                    +----------------+
                           |    computer    |                                    |    computer    |
                           +----------------+                                    +----------------+

                 Compiled                                           Interpreted
</code></pre>
<p>The figure above roughly shows the two types of translation and execution processes. Lua is an interpreted language, and our goal is to implement a Lua interpreter.</p>
<h2 id="parse-and-execute"><a class="header" href="#parse-and-execute">Parse and Execute</a></h2>
<p>The general compilation principle process is as follows:</p>
<pre><code>            Lexical Analysis        Syntax Analysis       Semantic Analysis
Character Stream --------&gt; Token Stream --------&gt; Syntax Tree --------&gt; Intermediate Code ...
</code></pre>
<ul>
<li>
<p>The character stream corresponds to the source code, that is, the source code is treated as a character stream.</p>
</li>
<li>
<p>Lexical analysis, which splits the character stream into tokens supported by the language. For example, the above Lua code is split into two Tokens: &quot;identification <code>print</code>&quot; and &quot;string <code>&quot;hello, world!&quot;</code>&quot;. Lua ignores whitespace characters.</p>
</li>
<li>
<p>Syntax analysis, which parses the Token stream into a syntax tree according to grammer rules. For example, the two tokens just now are recognized as a function call statement, in which &quot;identity <code>print</code>&quot; is the function name, and &quot;string <code>&quot;hello, world!&quot;</code>&quot; is the parameter.</p>
</li>
<li>
<p>Semantic analysis, which generates the corresponding intermediate code from the statement of this function call, these codes indicate where to find the function body, where to load the parameters and so on.</p>
</li>
</ul>
<p>After intermediate code is generated, compiled and interpreted languages diverge. The compiled language moves on, eventually generating machine code that can be executed directly, and packaged as an executable file. For the interpreted language, this is the end, the generated intermediate code (generally called bytecode) is the result of compilation; and the execution of the bytecode is the task of the virtual machine.</p>
<p>The virtual machine converts the bytecode into a corresponding series of precompiled subroutine, and then executes them. For example, to execute the bytecode generated above, the virtual machine first finds the corresponding function, namely <code>print</code>, which is a function in the Lua standard library; then loads the parameters, namely &quot;hello, world&quot;; finally calls the <code>print</code> function which outputs &quot;hello, world!&quot;.</p>
<p>The above just describes a general process. Specific to each language or each interpreter process may be different. For example, some interpreters may not generate bytecode, but let the virtual machine directly execute the syntax tree. The official implementation of Lua omits the syntax tree, and the bytecode is directly generated by syntax analysis. Each of these options has advantages and disadvantages, but they are beyond the scope of our topic and will not be discussed here. Our interpreter is a full reference to the official Lua implementation in the main process, so the final process is as follows:</p>
<pre><code>            Lexical Analysis         Syntax Analysis
Character Stream --------&gt; Token Stream --------&gt; Bytecode
                                                     ^
                                                     |
                                                 virtual machine
</code></pre>
<p>From this we can clarify the main functional components of our interpreter: lexical analysis, syntax analysis and virtual machine. The combination of lexical analysis and syntax analysis can be called the &quot;parsing&quot; process, and the virtual machine is the &quot;execution&quot; process, then the bytecode is the link connecting the two processes. The two processes of parsing and execution are relatively independent. Next, we use the bytecode as a breakthrough to start implementing our interpreter.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bytecode"><a class="header" href="#bytecode">Bytecode</a></h1>
<p>As a beginner, it is natural to feel lost and unsure of how to start implementing an interpreter. No way to start.</p>
<p>Fortunately, the <a href="./ch01-01.principles.html">previous section</a> introduces the bytecode at the end, and divides the entire interpreter process into two stages: parsing and execution. Then we can start with the bytecode:</p>
<ul>
<li>Determine the bytecode first,</li>
<li>then let the parsing process (lexical analysis and parsing) try to generate this set of bytecodes,</li>
<li>Then let the execution process (virtual machine) try to execute this set of bytecodes.</li>
</ul>
<pre><code>           generate           execute
     parse -------&gt; bytecode &lt;------- virtual machine
</code></pre>
<p>But what does bytecode look like? How to define? What type? We can refer to the official implementation of Lua.</p>
<h2 id="output-of-luac"><a class="header" href="#output-of-luac">Output of <code>luac</code></a></h2>
<p>For the convenience of description, the object code is listed again here:</p>
<pre><code class="language-lua">print &quot;hello, world!&quot;
</code></pre>
<p>The official implementation of Lua comes with a very useful tool, <code>luac</code>, namely Lua Compiler, which translates the source code into bytecode and outputs it. It is our right-hand man in this project. Take a look at its output to the &quot;hello, world!&quot; program:</p>
<pre><code>$ luac -l hello_world.lua

main &lt;hello_world.lua:0,0&gt; (5 instructions at 0x600000d78080)
0+ params, 2 slots, 1 upvalue, 0 locals, 2 constants, 0 functions
	1	[1]	VARARGPREP	0
	2	[1]	GETTABUP 	0 0 0	; _ENV &quot;print&quot;
	3	[1]	LOADK    	1 1	; &quot;hello, world!&quot;
	4	[1]	CALL     	0 2 1	; 1 in 0 out
	5	[1]	RETURN   	0 1 1	; 0 out
</code></pre>
<p>The first 2 lines of the output are incomprehensible, so ignore them now. The following should be the bytecode, and there are comments, which is great. But still do not understand. Check out Lua's <a href="https://www.lua.org/manual/5.4/">official manual</a>, but I can't find any explanation about bytecode. It turns out that the Lua language standard only defines the characteristics of the language, while the bytecode belongs to the &quot;concrete implementation&quot; part, just like the variable naming in the interpreter code, which does not belong to the definition scope of the Lua standard. In fact, the Luajit project, that is fully compatible with Lua 5.1, uses a <a href="https://github.com/LuaJIT/LuaJIT/blob/v2.1/src/lj_bc.h">completely different bytecode</a>. We can even implement an interpreter without bytecode. Since the manual does not explain it, we can only check the <a href="https://github.com/lua/lua/blob/v5.4.0/lopcodes.h#L196">the comment in source code</a>. Here we only introduce the 5 bytecodes that appear above:</p>
<ol>
<li>VARARGPREP, temporarily unused, ignored.</li>
<li>GETTABUP, this is a bit complicated, it can be temporarily understood as: loading global variables onto the stack. The three parameters are the stack index (0) as the target address, (ignore the second one,) and the index (0) of the global variable name in the constant table. The global variable name listed in the comments later is &quot;print&quot;.</li>
<li>LOADK, load constants onto the stack. The two parameters are the stack index (1) as the destination address, and the constant index (1) as the loading source. The value of the constant listed in the comment below is &quot;hello, world!&quot;.</li>
<li>CALL, function call. The three parameters are the stack index (0) of the function, the number of parameters, and the number of return values. The following comment indicates that there is 1 parameter and 0 return value.</li>
<li>RETURN, temporarily unused, ignored.</li>
</ol>
<p>Take a look at it together:</p>
<ul>
<li>First load the global variable named <code>print</code> into the stack (0);</li>
<li>Then load the string constant <code>&quot;hello, world!&quot;</code> into the stack (1);</li>
<li>Then execute the function at the stack (0) position, and take the stack (1) position as a parameter.</li>
</ul>
<p>The stack diagram during execution is as follows:</p>
<pre><code>  +-----------------+
0 | print           | &lt;- function
  +-----------------+
1 | &quot;hello, world!&quot; |
  +-----------------+
  |                 |
</code></pre>
<p>We currently only need to implement the above three bytecodes 2, 3, and 4.</p>
<h2 id="bytecode-definition"><a class="header" href="#bytecode-definition">Bytecode Definition</a></h2>
<p>Now define the bytecode format.</p>
<p>First refer to the format definition of Lua's official implementation. <a href="https://github.com/lua/lua/blob/v5.4.0/lopcodes.h#L13">Source code</a> has comments on the bytecode format:</p>
<pre><code>  We assume that instructions are unsigned 32-bit integers.
  All instructions have an opcode in the first 7 bits.
  Instructions can have the following formats:

        3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
        1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
iABC          C(8)     |      B(8)     |k|     A(8)      |   Op(7)     |
iABx                Bx(17)               |     A(8)      |   Op(7)     |
iAsBx              sBx (signed)(17)      |     A(8)      |   Op(7)     |
iAx                           Ax(25)                     |   Op(7)     |
isJ                           sJ(25)                     |   Op(7)     |

  A signed argument is represented in excess K: the represented value is
  the written unsigned value minus K, where K is half the maximum for the
  corresponding unsigned argument.
</code></pre>
<p>The bytecode is represented by a 32bit unsigned integer. The first 7 bits represent the command, and the following 25 bits represent the parameters. There are 5 formats of bytecode, and the parameters of each format are different. If you like this sense of precise bit control, you may immediately think of various bit operations, and you may already be excited. But don’t worry, let's look at Luajit’s bytecode format first:</p>
<pre><code>A single bytecode instruction is 32 bit wide and has an 8 bit opcode field and
several operand fields of 8 or 16 bit. Instructions come in one of two formats:

+---+---+---+---+
| B | C | A | OP|
|   D   | A | OP|
+---+---+---+---+
</code></pre>
<p>It is also a 32bit unsigned integer, but the division of fields is only accurate to bytes, and there are only 2 formats, which is much simpler than the official Lua implementation. In C language, by defining matching struct and union, bytecode can be constructed and parsed more conveniently, thus avoiding bit operations.</p>
<p>Since the Lua language does not specify the bytecode format, we can also design our own bytecode format. For different types of commands like this, where each command has unique associated parameters, it is very suitable to use Rust's enum: use tags as commands, and use associated values ​​as parameters. Let's define the bytecodes like this:</p>
<pre><code class="language-rust  ignore">#[derive(Debug)]
pub enum ByteCode {
    GetGlobal(u8, u8),
    LoadConst(u8, u8),
    Call(u8, u8),
}</code></pre>
<p>Luajit's bytecode definition can avoid bit operations, and using Rust's enum can go a step further, where you don't even need to care about the memory layout of each bytecode. You can use the enum creation syntax to construct bytecode, such as <code>ByteCode::GetGlobal(1,2)</code>; use pattern matching <code>match</code> to parse bytecode. The parsing and virtual-matchine modules in <a href="./ch01-04.lets_do_it.html">Section 1.4</a> construct and parse bytecodes respectively.</p>
<p>But also pay attention to ensure that the enum does not exceed 32bit, so we still need to understand the layout of the enum. The size of the enum tag in Rust is in bytes and is allocated on demand. So as long as there are less than 2^8=256 kinds of bytecodes, the tag only needs 1 byte. Only 7 bits are used to indicate the command type in Lua's official bytecode, so 256 is enough. Then there is still 3 bytes of space to store parameters. In the two bytecode types of Luajit, the parameters only occupy 3 bytes, which is enough. <a href="https://stackoverflow.com/questions/62547749/can-i-limit-the-size-of-a-rust-enum">This article</a> introduces the method of static checking, but due to the need for third-party libraries or macros, we don't use it here for the time being.</p>
<blockquote>
<p>Rust's enum is really nice!</p>
</blockquote>
<h2 id="two-tables"><a class="header" href="#two-tables">Two Tables</a></h2>
<p>As you can see from <a href="ch01-02.byte_codes.html#output-of-luac">analysis above</a>, we also need two tables except the bytecodes.</p>
<p>First, we need a <em>constant table</em> to store all the constants during the parsing process. The generated bytecodes refer to the corresponding constant through the index parameter. And during the execution process, the virtual machine reads the constants from this table through the bytecodes' parameter. In this example, there are two constants, one is the name of the global variable <code>print</code>, and the other is the string constant &quot;hello, world!&quot;. This is the meaning of <code>2 constants</code> in the second line of the above <code>luac</code> output.</p>
<p>Then we need a <em>global variable table</em> to save global variables according to variable names. During execution the virtual matchine first queries the global variable name in the constant table through the parameters in the bytecodes, and then queries the global variable table according to the name. The global variable table is only used (add, read, modify) during execution, and has nothing to do with the parsing process.</p>
<p>The specific definition of these two tables needs to rely on the concept of Lua's &quot;value&quot;, which will be introduced in the next section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="value-and-type"><a class="header" href="#value-and-type">Value and Type</a></h1>
<p>The previous section defined the bytecode, and mentioned at the end that we need two tables, the constant table and the global variable table, respectively to maintain the relationship between constants/variables and &quot;values&quot;, so their definitions depend on the &quot;Value&quot; 's definition in Lua. This section introduces and defines Lua's value.</p>
<p>For the convenience of description, all the words &quot;variable&quot; in this section later include variables and constants.</p>
<p>Lua is a dynamically typed language, and the &quot;type&quot; is bound to a value, not to a variable. For example, in the first line of the following code, the variable <code>n</code> contains the information: &quot;the name is n&quot;; while value <code>10</code> contains the information: &quot;the type is an integer&quot; and &quot;the value is 10&quot;. So in line 2, it's OK to assign <code>n</code> to a different type value.</p>
<pre><code class="language-lua">local n = 10
n = &quot;hello&quot; -- OK
</code></pre>
<p>For comparison, here's the statically typed language Rust. In the first line, the information of <code>n</code> is: &quot;the name is n&quot; and &quot;the type is i32&quot;; the information of <code>10</code> is: &quot;the value is 10&quot;. It can be seen that the &quot;type&quot; information has changed from the attribute of the variable to the attribute of the value. So you can't assign <code>n</code> to a string value later.</p>
<pre><code class="language-rust  ignore">let mut n: i32 = 10;
n = &quot;hello&quot;; // !!! Wrong</code></pre>
<p>The following two diagrams represent the relationship between variables, values, and types in dynamically typed and statically typed languages, respectively:</p>
<pre><code> variable         values                   variable               values
+---------+      +---------------+        +---------------+      +-----------+
| name: n |--\--&gt;| type: Integer |        | name: n       |-----&gt;| value: 10 |
+---------+  |   | value: 10     |        | type: Integer |  |   +-----------+
             |   +---------------+        +---------------+  X
             |                                               |
             |   +----------------+                          |   +----------------+
             \--&gt;| type: String   |                          \--&gt;| value: &quot;hello&quot; |
                 | value: &quot;hello&quot; |                              +----------------+
                 +----------------+

          dynamic type                              static type
    &quot;type&quot; is bound to values                 &quot;type&quot; is bound to variables
</code></pre>
<h2 id="value"><a class="header" href="#value">Value</a></h2>
<p>In summary, the value of Lua contains type information. This is also very suitable for defining with enum:</p>
<pre><code class="language-rust  ignore">use std::fmt;
use crate::vm::ExeState;

#[derive(Clone)]
pub enum Value {
    Nil,
    String(String),
    Function(fn (&amp;mut ExeState) -&gt; i32),
}

impl fmt::Debug for Value {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; Result&lt;(), fmt::Error&gt; {
        match self {
            Value::Nil =&gt; write!(f, &quot;nil&quot;),
            Value::String(s) =&gt; write!(f, &quot;{s}&quot;),
            Value::Function(_) =&gt; write!(f, &quot;function&quot;),
        }
    }
}</code></pre>
<p>Currently 3 types are defined:</p>
<ul>
<li><code>Nil</code>, Lua's null value.</li>
<li><code>String</code> for the <code>hello, world!</code> string. For the associated value type, the simplest <code>String</code> is temporarily used, and it will be optimized later.</li>
<li><code>Function</code> for <code>print</code>. The associated function type definition refers to the C API function definition <code>typedef int (*lua_CFunction) (lua_State *L);</code> in Lua, and will be improved later. Among them, <code>ExeState</code> corresponds to <code>lua_State</code>, which will be introduced in the next section.</li>
</ul>
<p>Other types such as integers, floating-point numbers and tables will be added in the future.</p>
<p>Above the Value definition, the <code>Clone</code> trait is implemented via <code>#[derive(Clone)]</code>. This is because Value will definitely involve assignment operations, and the String type includes Rust's string <code>String</code>, which <a href="https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html#memory-and-allocation">does not support direct copying</a>, namely the <code>Copy</code> trait is not implemented, or it owns the data on the heap. So we can only declare the whole Value as <code>Clone</code>. All assignments involving Value need to be done through <code>clone()</code>. It seems that the performance is worse than direct assignment. We will discuss this issue later when we define more types.</p>
<p>We also manually implemented the <code>Debug</code> trait to define the print format, after all, the function of the current object code is to print &quot;hello, world!&quot;. Since the function pointer parameter associated with <code>Function</code> does not support the <code>Debug</code> trait, it cannot be automatically implemented by <code>#[derive(Debug)]</code>.</p>
<h2 id="two-tables-1"><a class="header" href="#two-tables-1">Two Tables</a></h2>
<p>After defining the Value, we can define the two tables mentioned at the end of the previous section.</p>
<p>Constant table stores constants. Bytecodes refer to constants by index directly, so constant tables can be represented by Rust's variable-length array <code>Vec&lt;Value&gt;</code>.</p>
<p>The global variable table, which stores global variables according to their names, can <em>temporarily</em> be represented by Rust's <code>HashMap&lt;String, Value&gt;</code>. We will change this later.</p>
<blockquote>
<p>Compared with the ancient C language, components such as <code>Vec</code> and <code>HashMap</code> in the Rust standard library have brought great convenience and consistent experience.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lets-do-it"><a class="header" href="#lets-do-it">Let's Do It</a></h1>
<p>The previous chapters introduced the basics of compilation principles, and defined the two most important concepts, ByteCode and Value. Next, we can start coding to implement our interpreter!</p>
<p>The code corresponding to this series of articles is all managed by Cargo that comes with Rust. Projects currently using the binary type will be changed to the library type in the future.</p>
<p>The minimalist interpreter to be implemented at present is very simple, with very little code. I wrote all the code in one file at the beginning. However, it is foreseeable that the code volume of this project will increase with the increase of features. So in order to avoid subsequent changes to the file, we directly create multiple files now:</p>
<ul>
<li>Program entry: <code>main.rs</code>;</li>
<li>Three components: lexical analysis <code>lex.rs</code>, syntax analysis <code>parse.rs</code>, and virtual machine <code>vm.rs</code>;</li>
<li>Two concepts: byte code <code>byte_code.rs</code>, and value <code>value.rs</code>.</li>
</ul>
<p>The latter two concepts and their codes have been introduced before. The other 4 files are described below. Let's start with the program entry.</p>
<h2 id="program-entry"><a class="header" href="#program-entry">Program Entry</a></h2>
<p>For the sake of simplicity, our interpreter has only one way of working, which is to accept a parameter as a Lua source code file, and then parse and execute it. Here is the code:</p>
<pre><code class="language-rust  ignore">use std::env;
use std::fs::File;

mod value;
mod bytecode;
mod lex;
mod parse;
mod vm;

fn main() {
    let args: Vec&lt;String&gt; = env::args().collect();
    if args.len() != 2 {
        println!(&quot;Usage: {} script&quot;, args[0]);
        return;
    }
    let file = File::open(&amp;args[1]).unwrap();

    let proto = parse::load(file);
    vm::ExeState::new().execute(&amp;proto);
}</code></pre>
<p>The first 2 lines reference two standard libraries. <code>env</code> is used to <a href="https://doc.rust-lang.org/stable/book/ch12-01-accepting-command-line-arguments.html#reading-the-argument-values">obtain command line arguments</a>. <code>fs::File</code> is used to open Lua source files.</p>
<p>The middle lines refer to other <a href="https://doc.rust-lang.org/stable/book/ch07-04-bringing-paths-into-scope-with-the-use-keyword.html">file modules</a> through <code>use</code> keyword.</p>
<p>Then look at the <code>main()</code> function. The first few lines read the parameters and open the source file. For the sake of simplicity, we use <code>unwrap()</code> 
to terminate the program if fail to open file. We will improve the error handing later.</p>
<p>The last 2 lines are the core function:</p>
<ul>
<li>First, the syntax analysis module <code>parse</code> (who also calls lexical analysis <code>lex</code> internally) parses the file and returns the parsing result <code>proto</code>;</li>
<li>Then create a virtual machine and execute <code>proto</code>.</li>
</ul>
<p>This process is different from Lua's officially APIs (<a href="https://www.lua.org/pil/24.1.html">complete example</a>) :</p>
<pre><code class="language-c">lua_State *L = lua_open(); // Create lua_State
luaL_loadfile(L, filename); // Parse and put the parsing result on the top of the stack
lua_pcall(L, 0, 0, 0); // top of execution stack
</code></pre>
<p>This is because the official implementation of Lua is a &quot;library&quot;, and the API only exposes the <code>lua_State</code> data structure, which contains both parsing and executing parts. So you must first create <code>lua_State</code>, and then call parsing and execution based on it. The parsing result is also passed through the stack of <code>Lua_state</code>. However, we currently do not have a similar unified state data structure, so we can only call the parsing and execution functions separately.</p>
<p>Let's look at the analysis and execution process respectively.</p>
<h2 id="lexical-analysis"><a class="header" href="#lexical-analysis">Lexical Analysis</a></h2>
<p>Although the <code>main()</code> function calls the syntax analysis <code>parse</code> module firstly, but the syntax analysis calls the lexical analysis <code>lex</code> module internally. So let's see the lexical analysis first.</p>
<p>The output of lexical analysis is Token stream. For the &quot;hello, world!&quot; program, you only need to use the two Tokens &quot;identity <code>print</code>&quot; and &quot;string <code>&quot;hello, world!&quot;</code>&quot;. For simplicity, we only support these two kinds of tokens for the time being. In addition, we also define an <code>Eos</code> to indicate the end of the file:</p>
<pre><code class="language-rust  ignore">#[derive(Debug)]
pub enum Token {
    Name(String),
    String(String),
    Eos,
}</code></pre>
<p>Instead of returning a whole Token list after parsing the input file at one time, we provide a function similar to an iterator so that the syntax analysis module can be called on demand. To do this first define a lexical analyzer:</p>
<pre><code class="language-rust  ignore">#[derive(Debug)]
pub struct Lex {
    input: File,
}</code></pre>
<p>For now only one member is included, the input file.</p>
<p>It provides 2 APIs: <code>new()</code> creates a parser based on the input file; <code>next()</code> returns the next Token.</p>
<pre><code class="language-rust  ignore">impl Lex {
     pub fn new(input: File) -&gt; Self ;
     pub fn next(&amp;mut self) -&gt; Token;
}</code></pre>
<p>The specific parsing process is pure and boring string handling, and the code is skipped.</p>
<p>According to the Rust convention, the return value of the <code>next()</code> function here should be defined as <code>Option&lt;Token&gt;</code>, where <code>Some&lt;Token&gt;</code> means that a new token has been read, and <code>None</code> means the end of the file. But since <code>Token</code> itself is an <code>enum</code>, it seems more convenient to directly add an <code>Eos</code> in it. And if it is changed to the <code>Option&lt;Token&gt;</code> type, then an additional layer of judgment will be required in the syntax analysis call, as shown in the following code. So I chose to add the <code>Eos</code> type.</p>
<pre><code class="language-rust  ignore">loop {
     if let Some(token) = lex.next() { // extra check
         match token {
             ... // parse
         }
     } else {
         break
     }
}</code></pre>
<h2 id="syntax-analysis"><a class="header" href="#syntax-analysis">Syntax Analysis</a></h2>
<p>The parsing result <code>proto</code> in the <code>main()</code> function concats the parsing and execution phases. But in view of Rust's powerful type mechanism, <code>proto</code> does not show a specific type in the above code. Now let's define it. It has been introduced in the <a href="./ch01-02.byte_codes.html">bytecode</a> section that the analysis result needs to contain two parts: bytecode sequence and constant table. Then you can define the format of the parsing result as follows:</p>
<pre><code class="language-rust  ignore">#[derive(Debug)]
pub struct ParseProto {
    pub constants: Vec::&lt;Value&gt;,
    pub byte_codes: Vec::&lt;ByteCode&gt;,
}</code></pre>
<p>The constant table <code>constants</code> is a <code>Vec</code> containing the <code>Value</code> type, and the bytecode sequence <code>byte_codes</code> is a <code>Vec</code> containing the <code>ByteCode</code> type. They are both <code>Vec</code> structures with the same functionality but different containment types. In the ancient C language, to include the two types <code>Value</code> and <code>ByteCode</code>, either write a set of codes for each type, or use complex features such as macros or function pointers. <a href="https://doc.rust-lang.org/stable/book/ch10-01-syntax.html">Generics</a> in the Rust language can abstract the same set of logic for different types. More features of generics will be used in subsequent code.</p>
<p>After defining <code>ParseProto</code>, let's look at the syntax analysis process. We currently only support the statement of <code>print &quot;hello, world!&quot;</code>, which is the format of <code>Name String</code>. The Name is first read from the lexer, followed by the string constant. If it is not in this format, an error will be reported. The specific code is as follows:</p>
<pre><code class="language-rust  ignore">pub fn load(input: File) -&gt; ParseProto {
    let mut constants = Vec::new();
    let mut byte_codes = Vec::new();
    let mut lex = Lex::new(input);

    loop {
        match lex.next() {
            Token::Name(name) =&gt; { // `Name LiteralString` as function call
                constants.push(Value::String(name));
                byte_codes.push(ByteCode::GetGlobal(0, (constants.len()-1) as u8));

                if let Token::String(s) = lex.next() {
                    constants.push(Value::String(s));
                    byte_codes.push(ByteCode::LoadConst(1, (constants.len()-1) as u8));
                    byte_codes.push(ByteCode::Call(0, 1));
                } else {
                    panic!(&quot;expected string&quot;);
                }
            }
            Token::Eos =&gt; break,
            t =&gt; panic!(&quot;unexpected token: {t:?}&quot;),
        }
    }

    dbg!(&amp;constants);
    dbg!(&amp;byte_codes);
    ParseProto { constants, byte_codes }
}</code></pre>
<p>The input is the source file <code>File</code>, and the output is the <code>ParseProto</code> just defined.</p>
<p>The main body of the function is a loop, and the Token is cyclically read through the <code>next()</code> function provided by the lexical analyzer <code>lex</code> created at the beginning of the function. We currently only support one type of statement, <code>Name LiteralString</code>, and the semantics are function calls. So the analysis logic is also very simple:</p>
<ul>
<li>When <code>Name</code> is encountered, it is considered to be the beginning of a statement:
<ul>
<li>Use <code>Name</code> as a global variable and store it in the constant table;</li>
<li>Generate <code>GetGlobal</code> bytecode, load the global variable on the stack according to the name. The first parameter is the index of the target stack. Since we currently only support the function call statement, the stack is only used for function calls, so the function must be at position 0; the second parameter is the index of the global variable name in the global variable;</li>
<li>Read the next Token, and it is expected to be a string constant, otherwise panic;</li>
<li>Add string constants to the constant table;</li>
<li>Generate <code>LoadConst</code> bytecode to load constants onto the stack. The first parameter is the target stack index, which is behind the function and is 1; the second parameter is the index of the constant in the constant table;</li>
<li>Once the function and parameters are ready, <code>Call</code> bytecode can be generated to call the function. At present, the two parameters are the function position and the number of parameters, which are fixed at 0 and 1 respectively.</li>
</ul>
</li>
<li>When <code>Eos</code> is encountered, exit the loop.</li>
<li>When encountering other Tokens (currently only of <code>Token::String</code> type), panic.</li>
</ul>
<p>After the function, the constant table and bytecode sequence are output through <code>dbg!</code> for debugging. It can be compared with the output of <code>luac</code>.</p>
<p>Finally returns <code>ParseProto</code>.</p>
<h2 id="virtual-machine-execution"><a class="header" href="#virtual-machine-execution">Virtual Machine Execution</a></h2>
<p>After parsing and generating <code>ParseProto</code>, it is the turn of the virtual machine to execute. According to the previous analysis, the virtual machine currently requires two components: the stack and the global variable table. So define the virtual machine state as follows:</p>
<pre><code class="language-rust  ignore">pub struct ExeState {
    globals: HashMap&lt;String, Value&gt;,
    stack: Vec::&lt;Value&gt;,
}</code></pre>
<p>When creating a virtual machine, you need to add the <code>print</code> function in the global variable table in advance:</p>
<pre><code class="language-rust  ignore">impl ExeState {
    pub fn new() -&gt; Self {
        let mut globals = HashMap::new();
        globals.insert(String::from(&quot;print&quot;), Value::Function(lib_print));

        ExeState {
            globals,
            stack: Vec::new(),
        }
    }</code></pre>
<p>The <code>print</code> function is defined as follows:</p>
<pre><code class="language-rust  ignore">// &quot;print&quot; function in Lua's std-lib.
// It supports only 1 argument and assumes the argument is at index:1 on stack.
fn lib_print(state: &amp;mut ExeState) -&gt; i32 {
    println!(&quot;{:?}&quot;, state.stack[1]);
    0
}</code></pre>
<p>Currently the <code>print</code> function only supports one parameter, and it is assumed that this parameter is at position 1 of the stack. The function prints this parameter. Because this function does not need to return data to the caller, it returns 0.</p>
<p>After the initialization is completed, the following is the core virtual machine execution function, that is, the big bytecode dispatching loop: read the bytecode sequence in turn and execute the corresponding predefined subrotines. The specific code is as follows:</p>
<pre><code class="language-rust  ignore">    pub fn execute(&amp;mut self, proto: &amp;ParseProto) {
        for code in proto.byte_codes.iter() {
            match *code {
                ByteCode::GetGlobal(dst, name) =&gt; {
                    let name = &amp;proto.constants[name as usize];
                    if let Value::String(key) = name {
                        let v = self.globals.get(key).unwrap_or(&amp;Value::Nil).clone();
                        self.set_stack(dst, v);
                    } else {
                        panic!(&quot;invalid global key: {name:?}&quot;);
                    }
                }
                ByteCode::LoadConst(dst, c) =&gt; {
                    let v = proto.constants[c as usize].clone();
                    self.set_stack(dst, v);
                }
                ByteCode::Call(func, _) =&gt; {
                    let func = &amp;self.stack[func as usize];
                    if let Value::Function(f) = func {
                        f(self);
                    } else {
                        panic!(&quot;invalid function: {func:?}&quot;);
                    }
                }
            }
        }
    }</code></pre>
<p>Currently only 3 bytecodes are supported. All subrotines are clear, needless to explain.</p>
<h2 id="test"><a class="header" href="#test">Test</a></h2>
<p>So far, we have implemented a Lua interpreter with a complete process! Look at the running effect:</p>
<pre><code>$ cargo r -q --test_lua/hello.lua
[src/parse.rs:39] &amp;constants = [
     print,
     hello, world!,
]
[src/parse.rs:40] &amp;byte_codes = [
     GetGlobal(
         0,
         0,
     ),
     LoadConst(
         1,
         1,
     ),
     Call(
         0,
     ),
]
hello world!
</code></pre>
<p>The output is divided into 3 parts. Part 1 is the constant table, containing 2 string constants. The second part is the bytecode sequence, which can be compared with the output of <code>luac</code> in the <a href="./ch01-02.byte_codes.html">Bytecode</a> section. The last line is the result we expected: &quot;hello, world!&quot;.</p>
<p>There is an additional function. The parsing part does not support only one line statement, but a loop. So we can support multiple <code>print</code> statements, such as:</p>
<pre><code class="language-lua">print &quot;hello, world!&quot;
print &quot;hello, again...&quot;
</code></pre>
<p>There is a small problem which is <code>print</code> appears twice in the constant table. It can be optimized here that every time adding a value to the constant table, check whether it already exists first. We will finish this in the next chapter.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The purpose of this chapter is to implement a minimal Lua interpreter but with complete process, in order to get familiar with the interpreter architecture. To this end, we first introduced the basics of compiling principles, then introduced the two core concepts of Lua's bytecode and value, and finally accomplished it!</p>
<p>We have been emphasizing the &quot;complete process&quot; because we only need to add features onto this framework in the following chapters. Let's move on!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="variables-and-assignment"><a class="header" href="#variables-and-assignment">Variables and Assignment</a></h1>
<p>In the last chapter, we completed a simple Lua interpreter but with a complete process. In the future, we will continue to add new features based on this interpreter.</p>
<p>This chapter begins by adding some simple types, including boolean, integer, and floating-point number. Then it introduces local variables.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="more-types"><a class="header" href="#more-types">More Types</a></h1>
<p>This section adds simple types, including boolean, integer, and float. Other types such as Table and UserData will be implemented in subsequent chapters.</p>
<p>We first improve the lexical analysis to support the tokens corresponding to these types, and then generate the corresponding bytecodes through the syntax analysis, and add support for these bytecodes in the virtual machine. Finally we modify the function call to support printing these types.</p>
<h2 id="improve-lexical-analysis"><a class="header" href="#improve-lexical-analysis">Improve Lexical Analysis</a></h2>
<p>The lexical analysis in the previous chapter only supports 2 tokens. So now no matter what features are added, the lexical analysis must be changed first to add the corresponding Tokens. In order to avoid adding tokens piecemeal in each chapter in the future, it is now added here in one go.</p>
<p>The Lua official website lists the complete <a href="https://www.lua.org/manual/5.4/manual.html#3.1">lexical conventions</a>. It includes:</p>
<ul>
<li>
<p>Name, which has been implemented before, is used for variables, etc.</p>
</li>
<li>
<p>Constants, including string, integer, and floating-point constants.</p>
</li>
<li>
<p>Keywords:</p>
<pre><code>  and break do else else if end
  false for function goto if in
  local nil not or repeat return
  then true until while
</code></pre>
</li>
<li>
<p>Symbols:</p>
<pre><code>  + - * / % ^ #
  &amp; ~ | &lt;&lt; &gt;&gt; //
  == ~= &lt;= &gt;= &lt; &gt; =
  ( ) { } [ ] ::
  ; : , . .. ...
</code></pre>
</li>
</ul>
<p>The corresponding Token is defined as:</p>
<pre><code class="language-rust  ignore">#[derive(Debug, PartialEq)]
pub enum Token {
    // keywords
    And,    Break,  Do,     Else,   Elseif, End,
    False,  For,    Function, Goto, If,     In,
    Local,  Nil,    Not,    Or,     Repeat, Return,
    Then,   True,   Until,  While,

 // +       -       *       /       %       ^       #
    Add,    Sub,    Mul,    Div,    Mod,    Pow,    Len,
 // &amp;       ~       |       &lt;&lt;      &gt;&gt;      //
    BitAnd, BitXor, BitOr,  ShiftL, ShiftR, Idiv,
 // ==       ~=     &lt;=      &gt;=      &lt;       &gt;        =
    Equal,  NotEq,  LesEq,  GreEq,  Less,   Greater, Assign,
 // (       )       {       }       [       ]       ::
    ParL,   ParR,   CurlyL, CurlyR, SqurL,  SqurR,  DoubColon,
 // ;               :       ,       .       ..      ...
    SemiColon,      Colon,  Comma,  Dot,    Concat, Dots,

    // constant values
    Integer(i64),
    Float(f64),
    String(String),

    // name of variables or table keys
    Name(String),

    // end
    Eos,
}</code></pre>
<p>The specific implementation is nothing more than tedious string parsing, which is skipped here. For the sake of simplicity, this implementation only supports most simple types, but does not support complex types such as long strings, long comments, string escapes, hexadecimal numbers, and floating point numbers only support scientific notation Law. These do not affect the main features to be added later.</p>
<h2 id="type-of-values"><a class="header" href="#type-of-values">Type of Values</a></h2>
<p>After lexical analysis supports more types, we add these types to Value:</p>
<pre><code class="language-rust  ignore">#[derive(Clone)]
pub enum Value {
    Nil,
    Boolean(bool),
    Integer(i64),
    Float(f64),
    String(String),
    Function(fn (&amp;mut ExeState) -&gt; i32),
}

impl fmt::Debug for Value {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; Result&lt;(), fmt::Error&gt; {
        match self {
            Value::Nil =&gt; write!(f, &quot;nil&quot;),
            Value::Boolean(b) =&gt; write!(f, &quot;{b}&quot;),
            Value::Integer(i) =&gt; write!(f, &quot;{i}&quot;),
            Value::Float(n) =&gt; write!(f, &quot;{n:?}&quot;),
            Value::String(s) =&gt; write!(f, &quot;{s}&quot;),
            Value::Function(_) =&gt; write!(f, &quot;function&quot;),
        }
    }
}</code></pre>
<p>One of the special places is that the debug mode is used for the output of floating-point numbers: <code>{:?}</code>. Because Rust's common output format <code>{}</code> for floating-point numbers is integer + decimal format, and a more reasonable way should be to choose a more suitable one between &quot;integer decimal&quot; and &quot;scientific notation&quot;, corresponding to <code>%g</code> in C language's <code>printf</code>. For example, it is unreasonable to output <code>&quot;0.000000&quot;</code> for the number <code>1e-10</code>. This seems to be a <a href="https://internals.rust-lang.org/t/pre-rfc-draft-g-or-floating-points-for-humans/9110">historical issue</a> of Rust. For compatibility and other reasons, only the debug mode <code>{:?}</code> can be used to correspond to <code>%g</code>. I don't get into it here.</p>
<p>In addition, in order to facilitate the distinction between &quot;integer&quot; and &quot;floating point number without decimal part&quot;, in Lua's official implementation, <code>.0</code> will be added after the latter. For example, <code>2</code> will be output as <code>2.0</code> for the floating point number. The code is as follows. This is so sweet. And this is also the default behavior of Rust's <code>{:?}</code> mode, so we don't need special handling for this.</p>
<pre><code class="language-c">     if (buff[strspn(buff, &quot;-0123456789&quot;)] == '\0') { /* looks like an int? */
       buff[len++] = lua_getlocaledecpoint();
       buff[len++] = '0'; /* adds '.0' to result */
     }
</code></pre>
<blockquote>
<p>Before <a href="http://www.lua.org/versions.html#5.3">Lua 5.3</a>, Lua has only one numeric type, the default is floating point. I understand this because Lua was originally intended for configuration files, for users rather than programmers. For ordinary users, the concepts of integer and floating point numbers are not distinguished, and there is no difference between configuring <code>10 seconds</code> and <code>10.0 seconds</code>; in addition, for some calculations, such as <code>7/2</code>, the result is obviously <code>3.5</code> and Not <code>3</code>. However, with the expansion of Lua's use, for example, as a glue language between many large programs, the demand for integers has become increasingly strong, so integers and floating-point numbers are distinguished at the language level.</p>
</blockquote>
<h2 id="syntax-analysis-1"><a class="header" href="#syntax-analysis-1">Syntax Analysis</a></h2>
<p>Now we add support for these types in the parser. Since currently only the function call statement is supported, that is, the format of <code>function parameter</code>; and the &quot;function&quot; only supports global variables, so this time only the &quot;parameter&quot; part needs to support these new types. For function calls in Lua voice, if the parameter is a string constant or a table structure, then the parentheses <code>()</code> can be omitted, as in the &quot;hello, world!&quot; example in the previous chapter. But for other cases, such as several new types added this time, brackets <code>()</code> must be required. So the modification of the parameter part is as follows:</p>
<pre><code class="language-rust  ignore">Token::Name(name) =&gt; {
     // function, global variable only
     let ic = add_const(&amp;mut constants, Value::String(name));
     byte_codes.push(ByteCode::GetGlobal(0, ic as u8));

     // argument, (var) or &quot;string&quot;
     match lex. next() {
         Token::ParL =&gt; { // '('
             let code = match lex. next() {
                 Token::Nil =&gt; ByteCode::LoadNil(1),
                 Token::True =&gt; ByteCode::LoadBool(1, true),
                 Token::False =&gt; ByteCode::LoadBool(1, false),
                 Token::Integer(i) =&gt;
                     if let Ok(ii) = i16::try_from(i) {
                         ByteCode::LoadInt(1, ii)
                     } else {
                         load_const(&amp;mut constants, 1, Value::Integer(i))
                     }
                 Token::Float(f) =&gt; load_const(&amp;mut constants, 1, Value::Float(f)),
                 Token::String(s) =&gt; load_const(&amp;mut constants, 1, Value::String(s)),
                 _ =&gt; panic!(&quot;invalid argument&quot;),
             };
             byte_codes. push(code);

             if lex.next() != Token::ParR { // ')'
                 panic!(&quot;expected `)`&quot;);
             }
         }
         Token::String(s) =&gt; {
             let code = load_const(&amp;mut constants, 1, Value::String(s));
             byte_codes. push(code);
         }
         _ =&gt; panic!(&quot;expected string&quot;),
     }
}</code></pre>
<p>This code first parses the function. Like the code in the previous chapter, it still only supports global variables. Then parse the parameters. In addition to the support for string constants, a more general way of parentheses <code>()</code> is added. Which handles various type constants:</p>
<ul>
<li>
<p>Floating-point constants, similar to string constants, call the <code>load_const()</code> function, put it in the constant table at compile time, and then load it through <code>LoadConst</code> bytecode during execution.</p>
</li>
<li>
<p>Nil and Boolean types, there is no need to put Nil, true and false in the constant table. It is more convenient to encode directly into bytecode, and it is faster at execution time (because there is one less memory read). So <code>LoadNil</code> and <code>LoadBool</code> bytecodes are added.</p>
</li>
<li>
<p>Integer constants combine the above two approaches. Because a bytecode has 4 bytes, the opcode occupies 1 byte, the destination address occupies 1 byte, and there are 2 bytes left, which can store the integer of <code>i16</code>. Therefore, for numbers in the range of <code>i16</code> (this is also a high probability event), it can be directly encoded into the bytecode, and the <code>LoadInt</code> bytecode is added for this purpose; if it exceeds the range of <code>i16</code>, it is stored in the constant table . This is also the official implementation of Lua for reference. From this we can see Lua's pursuit of performance, it adds a bytecode and process codes in order to reduce a memory access only. We will see many such cases in the future.</p>
</li>
</ul>
<p>Since only the function call statment is currently supported, the function is fixed at the <code>0</code> position of the stack during execution, and the parameter is fixed at the <code>1</code> position. The target addresses of the above bytecodes are also fixedly filled with <code>1</code>.</p>
<p>The main code has been introduced. The definition of the function <code>load_const()</code> used to generate <code>LoadConst</code> bytecode is listed below:</p>
<pre><code class="language-rust  ignore">fn add_const(constants: &amp;mut Vec&lt;Value&gt;, c: Value) -&gt; usize {
     constants. push(c);
     constants. len() - 1
}

fn load_const(constants: &amp;mut Vec&lt;Value&gt;, dst: usize, c: Value) -&gt; ByteCode {
     ByteCode::LoadConst(dst as u8, add_const(constants, c) as u8)
}</code></pre>
<h2 id="test-1"><a class="header" href="#test-1">Test</a></h2>
<p>So far, the parsing process has completed the support for new types. The rest of the virtual machine execution part just supports the newly added bytecode <code>LoadInt</code>, <code>LoadBool</code> and <code>LoadNil</code>. Skip it here.</p>
<p>Then you can test the following code:</p>
<pre><code class="language-lua">print(nil)
print(false)
print(123)
print(123456)
print(123456.0)
</code></pre>
<p>The output is as follows:</p>
<pre><code>[src/parse.rs:64] &amp;constants = [
     print,
     print,
     print,
     print,
     123456,
     print,
     123456.0,
]
byte_codes:
   GetGlobal(0, 0)
   LoadNil(1)
   Call(0, 1)
   GetGlobal(0, 0)
   LoadBool(1, false)
   Call(0, 1)
   GetGlobal(0, 0)
   LoadInt(1, 123)
   Call(0, 1)
   GetGlobal(0, 0)
   LoadConst(1, 1)
   Call(0, 1)
   GetGlobal(0, 0)
   LoadConst(1, 2)
   Call(0, 1)
nil
false
123
123456
123456.0
</code></pre>
<p>There is a small problem left over from the last chapter, that is, <code>print</code> appears many times in the constant table. This needs to be modified to check whether it already exists every time a constant is added.</p>
<h2 id="add-constants"><a class="header" href="#add-constants">Add Constants</a></h2>
<p>Modify the <code>add_const()</code> function above as follows:</p>
<pre><code class="language-rust  ignore">fn add_const(constants: &amp;mut Vec&lt;Value&gt;, c: Value) -&gt; usize {
     constants.iter().position(|v| v == &amp;c)
         .unwrap_or_else(|| {
             constants. push(c);
             constants.len() - 1
         })
}</code></pre>
<p><code>constants.iter().position()</code> positions the index. Its parameter is a <a href="https://doc.rust-lang.org/stable/book/ch13-01-closures.html">closure</a>, which needs to compare two <code>Value</code>, for which <code>Value</code> needs to be implemented <code>PartialEq</code> trait:</p>
<pre><code class="language-rust  ignore">impl PartialEq for Value {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        // TODO compare Integer vs Float
        match (self, other) {
            (Value::Nil, Value::Nil) =&gt; true,
            (Value::Boolean(b1), Value::Boolean(b2)) =&gt; *b1 == *b2,
            (Value::Integer(i1), Value::Integer(i2)) =&gt; *i1 == *i2,
            (Value::Float(f1), Value::Float(f2)) =&gt; *f1 == *f2,
            (Value::String(s1), Value::String(s2)) =&gt; *s1 == *s2,
            (Value::Function(f1), Value::Function(f2)) =&gt; std::ptr::eq(f1, f2),
            (_, _) =&gt; false,
        }
    }
}</code></pre>
<p>Here we think that two integers and floating point numbers that are numerically equal are different, such as <code>Integer(123456)</code> and <code>Float(123456.0)</code>, because these are indeed two values, and the two cannot be combined when dealing with constant tables value, otherwise in the test code in the previous section, the last line will also load the integer <code>123456</code>.</p>
<p>But during Lua execution, these two values are equal, that is, the result of <code>123 == 123.0</code> is <code>true</code>. We will deal with this issue in a later chapter.</p>
<p>Going back to the <code>position()</code> function, its return value is <code>Option&lt;usize&gt;</code>, <code>Some(i)</code> means found, and returns the index directly; while <code>None</code> means not found, you need to add a constant first, and then return the index. According to the programming habit of C language, it is the following if-else judgment, but here we try to use a more functional way. Personally, I feel that this method is not clearer, but since you are learning Rust, try to use the Rust method first.</p>
<pre><code class="language-rust  ignore">     if let Some(i) = constants.iter().position(|v| v == &amp;c) {
         i
     } else {
         constants. push(c);
         constants.len() - 1
     }</code></pre>
<p>After completing the transformation of the <code>add_const()</code> function, duplicate values can be avoided in the constant table. The relevant output is intercepted as:</p>
<pre><code>[src/parse.rs:64] &amp;constants = [
     print,
     123456,
     123456.0,
]
</code></pre>
<p>Although the above will check for duplicates when adding constants, the check is done by traversing the array. The time complexity of adding all constants is O(N^2). If a Lua code segment contains a lot of constants, such as 1 million, the parsing will be too slow. For this we need a hash table to provide fast lookups. TODO.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="local-variables"><a class="header" href="#local-variables">Local Variables</a></h1>
<p>This section describes the definition and access of local variables, while the assignment is covered in the next section.</p>
<p>For the sake of simplicity, we only support the simplified format for defining local variable statements: <code>local name = expression</code>, that is to say, it does not support multiple variables or no initialization. We will support the full format in later chapter. The target code is as follows:</p>
<pre><code class="language-lua">local a = &quot;hello, local!&quot; -- define new local var 'a'
print(a) -- use 'a'
</code></pre>
<p>How are local variables managed, stored, and accessed? First refer to the results of <code>luac</code>:</p>
<pre><code>main &lt;local.lua:0,0&gt; (6 instructions at 0x6000006e8080)
0+ params, 3 slots, 1 upvalue, 1 local, 2 constants, 0 functions
	1	[1]	VARARGPREP	0
	2	[1]	LOADK    	0 0	; &quot;hello, world!&quot;
	3	[2]	GETTABUP 	1 0 1	; _ENV &quot;print&quot;
	4	[2]	MOVE     	2 0
	5	[2]	CALL     	1 2 1	; 1 in 0 out
	6	[2]	RETURN   	1 1 1	; 0 out
</code></pre>
<p>Compared with the program that directly prints &quot;hello, world!&quot; in the previous chapter, there are several differences:</p>
<ul>
<li><code>1 local</code> in the second line of the output, indicating that there is 1 local variable. But this is just an illustration and has nothing to do with the following bytecode.</li>
<li>LOADK, loads the constant at index 0 of the stack. Corresponding to line [1] of the source code, that is, defining local variables. It can be seen that variables are stored on the stack and assigned during execution.</li>
<li>The target address of GETTABUP is 1 (it was 0 in the previous chapter), that is, <code>print</code> is loaded into location 1, because location 0 is used to store local variables.</li>
<li>MOVE, the new bytecode, is used to copy the value in the stack. The two parameters are the destination index and the source index. Here is to copy the value of index 0 to index 2. It is to use the local variable a as the parameter of print.</li>
</ul>
<p>After the first 4 bytecodes are executed, the layout on the stack is as follows:</p>
<pre><code>  +-----------------+   MOVE
0 | local a         |----\
  +-----------------+    |
1 | print           |    |
  +-----------------+    |
2 | &quot;hello, world!&quot; |&lt;---/
  +-----------------+
  |                 |
</code></pre>
<p>It can be seen that local variables are stored on the stack during execution. In the previous chapter, the stack was only used for <em>function calls</em>, and now it <em>stores local variables</em> too. Relatively speaking, local variables are more persistent and only become invalid after the end of the current block. The function call is invalid after the function returns.</p>
<h2 id="define-local-variables"><a class="header" href="#define-local-variables">Define Local Variables</a></h2>
<p>Now we add support of handling local variables. First define the local variable table <code>locals</code>. In the <a href="./ch01-03.value_and_type.html">value and type</a> section, it shows that Lua variables only contain variable name information, but no type information, so this table only saves variable names, defined as<code> Vec&lt;String&gt;</code>. In addition, this table is only used during syntax analysis, but not needed during virtual machine execution, so it does not need to be added to <code>ParseProto</code>.</p>
<p>Currently, 2 statements are supported (2 formats of function calls):</p>
<pre><code>Name String
Name ( exp )
</code></pre>
<p>Among them, <code>exp</code> is an expression, which currently supports a variety of constants, such as strings and numbers.</p>
<p>Now we add a new statement, the simplified form of defining a local variable:</p>
<pre><code>localName = exp
</code></pre>
<p>This also includes <code>exp</code>. So extract this part as a function <code>load_exp()</code>. Then the syntax analysis code corresponding to the definition of local variables is as follows:</p>
<pre><code class="language-rust  ignore">     Token::Local =&gt; { // local name = exp
         let var = if let Token::Name(var) = lex.next() {
             var // can not add to locals now
         } else {
             panic!(&quot;expected variable&quot;);
         };

         if lex.next() != Token::Assign {
             panic!(&quot;expected `=`&quot;);
         }

         load_exp(&amp;mut byte_codes, &amp;mut constants, lex.next(), locals.len());

         // add to locals after load_exp()
         locals. push(var);
     }</code></pre>
<p>The code is relatively simple and needs no explaination. The <code>load_exp()</code> function refers to the following section.</p>
<p>What needs special attention is that when the variable name <code>var</code> is first parsed, it cannot be directly added to the local variable table <code>locals</code>, but can only be added <em>after</em> the expression is parsed. It can be considered that when <code>var</code> is parsed, there is no complete definition of local variables; it needs to wait until the end of the entire statement to complete the definition and add it to the local variable table. The following subsections explain the specific reasons.</p>
<h2 id="access-local-variables"><a class="header" href="#access-local-variables">Access Local Variables</a></h2>
<p>Now access the local variable, that is, the code <code>print(a)</code>. That is to increase the processing of local variables in <code>exp</code>.</p>
<blockquote>
<p>In fact, in the <code>Name ( exp )</code> format of the function call statement in the previous section, you can add global variables in <code>exp</code>. In this way, Lua code such as <code>print(print)</code> can be supported. It's just that at that time, I only cared about adding other types of constants, and forgot to support global variables. This also reflects the current state, that is, the addition of functional features is all based on feeling, while the completeness or even correctness cannot be guaranteed at all. We will address this issue in subsequent chapters.</p>
</blockquote>
<p>So modify the code of <code>load_exp()</code> (the processing part of the original various constant types is omitted here):</p>
<pre><code class="language-rust  ignore">fn load_exp(byte_codes: &amp;mut Vec&lt;ByteCode&gt;, constants: &amp;mut Vec&lt;Value&gt;,
         locals: &amp;Vec&lt;String&gt;, token: Token, dst: usize) {

     let code = match token {
         ... // other type consts, such as Token::Float()...
         Token::Name(var) =&gt; load_var(constants, locals, dst, var),
         _ =&gt; panic!(&quot;invalid argument&quot;),
     };
     byte_codes. push(code);
}

fn load_var(constants: &amp;mut Vec&lt;Value&gt;, locals: &amp;Vec&lt;String&gt;, dst: usize, name: String) -&gt; ByteCode {
     if let Some(i) = locals.iter().rposition(|v| v == &amp;name) {
         // local variable
         ByteCode::Move(dst as u8, i as u8)
     } else {
         // global variable
         let ic = add_const(constants, Value::String(name));
         ByteCode::GetGlobal(dst as u8, ic as u8)
     }
}</code></pre>
<p>The processing of variables in the <code>load_exp()</code> function is also placed in a separate <code>load_var()</code> function, because the &quot;function&quot; part of the previous function call statement can also call this <code>load_var()</code> function, so that local variables can also be supported as a function.</p>
<p>The processing logic for variables is to search the Name in the local variable table <code>locals</code>,</p>
<ul>
<li>if exist, it is a local variable, then generate the <code>Move</code> bytecode, which is a new bytecode;</li>
<li>otherwise, it is a global variable. The handling process was introduced in the previous chapter, so it is skipped here.</li>
</ul>
<blockquote>
<p>It is foreseeable that after supporting Upvalue, it will also be handled in this function.</p>
</blockquote>
<p>When the <code>load_var()</code> function looks up variables in the variable table, it searches from the back to the front, that is, the <code>.rposition()</code> function is used. This is because we did not check for duplicate names when registering local variables. If there is a duplicate name, it will be registered as usual, that is, it will be pushed at the end of the local variable table. In this case, the reverse search will find the variable registered later, and the variable registered first will never be located. It is equivalent to the variable registered later covering the previous variable. For example, the following code is legal and outputs <code>456</code>:</p>
<pre><code class="language-lua">local a = 123
local a = 456
print(a) -- 456
</code></pre>
<p>I find this approach very ingenious. If you check if a local variable exists every time adding a local variable, it will definitely consume performance. And this kind of repeated definition of local variables is rare (maybe I am ignorant), and it is not worth checking duplication (whether it is error reporting or reuse) for this small probability situation. The current approach (reverse lookup) not only guarantees performance, but also can correctly support this situation of repeated definitions.</p>
<p>There are similar shadow variables in Rust. However, I guess Rust should not be able to ignore it so simply, because when a variable in Rust is invisible (such as being shadowed), it needs to be dropped, so it is still necessary to specially judge this shadow situation and handle it specially.</p>
<p>Another problem is that as mentioned at the end of the previous paragraph <a href="ch02-02.local.html#define-local-variables">Define Local Variables</a>, when the variable name <code>var</code> is parsed, it cannot be directly added to the local variable table <code>locals</code>, but must only be added after parsing the expression. At that time, because there was no &quot;access&quot; to the local variable, the specific reason was not explained. Now it can be explained. For example for the following code:</p>
<pre><code class="language-lua">local print = print
</code></pre>
<p>This kind of statement is relatively common in Lua code, that is, assign a commonly used &quot;global variable&quot; to a &quot;local variable&quot; with the same name, so that it will be the local variable accessed when this name is referenced later. Local variables are much faster than global variables (local variables are accessed through the stack index, while global variables need to look up the global variable table in real time, which is the difference between the two bytecodes of <code>Move</code> and <code>GetGlobal</code>), which will improve performance.</p>
<p>Going back to the question just now, if the variable name <code>print</code> is just added to the local variable table when it is parsed, then when the expression <code>print</code> behind <code>=</code> is parsed, the local variable table will find the newly added <code>print</code>, then it is equivalent to assigning the local variable <code>print</code> to the local variable <code>print</code>, and the cycle is meaningless (if you do this, <code>print</code> will be assigned the value of nil).</p>
<p>To sum up, variables must be added to the local variable table after parsing the expression behind <code>=</code>.</p>
<h2 id="where-the-function-is-called"><a class="header" href="#where-the-function-is-called">Where the Function is Called</a></h2>
<p>Previously, our interpreter only supported function call statements, so the stack is only a place for function calls. When a function call is executed, the function and parameters are fixed at 0 and 1 respectively. Now that local variables are supported, the stack is not just a place for function calls, and the positions of functions and parameters are not fixed, but need to become the first free position on the stack, that is, the next position of local variables. to this end:</p>
<ul>
<li>
<p>During syntax analysis, we can get the number of local variables through <code>locals.len()</code>, that is, the first free position on the stack.</p>
</li>
<li>
<p>When the virtual machine is executing, we need to add a field <code>func_index</code> in <code>ExeState</code>, set this field before the function call to indicate this position, and use it in the function. The corresponding codes are as follows:</p>
</li>
</ul>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, _) =&gt; {
         self.func_index = func as usize; // set func_index
         let func = &amp;self. stack[self. func_index];
         if let Value::Function(f) = func {
             f(self);
         } else {
             panic!(&quot;invalid function: {func:?}&quot;);
         }
     }</code></pre>
<pre><code class="language-rust  ignore">fn lib_print(state: &amp;mut ExeState) -&gt; i32 {
     println!(&quot;{:?}&quot;, state.stack[state.func_index + 1]); // use func_index
     0
}</code></pre>
<h2 id="test-2"><a class="header" href="#test-2">Test</a></h2>
<p>So far, we have realized the definition and access of local variables, and also re-organized the code in the process, making the previous function call statement more powerful. Both the function and the parameter support global variables and local variables. So the 2-line object code at the beginning of this article is too simple. You can try the following code:</p>
<pre><code class="language-lua">local a = &quot;hello, local!&quot; -- define a local by string
local b = a -- define a local by another local
print(b) -- print local variable
print(print) -- print global variable
local print = print --define a local by global variable with same name
print &quot;I'm local-print!&quot; -- call local function
</code></pre>
<p>Results of the:</p>
<pre><code>[src/parse.rs:71] &amp;constants = [
     hello, local!,
     print,
     I'm local-print!,
]
byte_codes:
   LoadConst(0, 0)
   Move(1, 0)
   GetGlobal(2, 1)
   Move(3, 1)
   Call(2, 1)
   GetGlobal(2, 1)
   GetGlobal(3, 1)
   Call(2, 1)
   GetGlobal(2, 1)
   Move(3, 2)
   LoadConst(4, 2)
   Call(3, 1)
hello, local!
function
I'm local-print!
</code></pre>
<p>In line with expectations! The bytecodes are a bit long, you can compare it with the output of <code>luac</code>. We used to be able to analyze and imitate the bytecode sequence compiled by <code>luac</code>, but now we can compile and output bytecode independently. Great progress!</p>
<h2 id="oo-in-syntax-analysis-code"><a class="header" href="#oo-in-syntax-analysis-code">OO in Syntax Analysis Code</a></h2>
<p>The feature has been completed. However, with the increase of features, the code in the syntax analysis part becomes more chaotic. For example, the definition of the above <code>load_exp()</code> function has a bunch of parameters. In order to organize the code, the syntax analysis is also transformed into an object-oriented model, and methods are defined around <code>ParseProto</code>. These methods can get all the information through <code>self</code>, so there is no need to pass many parameters. For specific changes, see <a href="https://github.com/WuBingzheng/build-lua-in-rust/commit/f89d2fd6bca4574d1d18d60f9363731bfd89e4b1">commit f89d2fd</a>.</p>
<p>Bringing together several independent members also presents a small problem, a problem specific to the Rust language. For example, the original code for reading a string constant is as follows, first call <code>load_const()</code> to generate and return the bytecode, and then call <code>byte_codes.push()</code> to save the bytecode. These two function calls can be written together:</p>
<pre><code class="language-rust  ignore">byte_codes.push(load_const(&amp;mut constants, iarg, Value::String(s)));</code></pre>
<p>After changing to object-oriented mode, the code is as follows:</p>
<pre><code class="language-rust  ignore">self.byte_codes.push(self.load_const(iarg, Value::String(s)));</code></pre>
<p>But this cannot be compiled, and the error is as follows:</p>
<pre><code>error[E0499]: cannot borrow `*self` as mutable more than once at a time
  --&gt; src/parse.rs:70:38
   |
70 |                 self.byte_codes.push(self.load_const(iarg, Value::String(s)));
   |                 ---------------------^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^-
   |                 |               |    |
   |                 |               |    second mutable borrow occurs here
   |                 |               first borrow later used by call
   |                 first mutable borrow occurs here
   |
help: try adding a local storing this argument...
  --&gt; src/parse.rs:70:38
   |
70 |                 self.byte_codes.push(self.load_const(iarg, Value::String(s)));
   |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: ...and then using that local as the argument to this call
  --&gt; src/parse.rs:70:17
   |
70 |                 self.byte_codes.push(self.load_const(iarg, Value::String(s)));
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For more information about this error, try `rustc --explain E0499`.
</code></pre>
<p>Although the Rust compiler is very strict, the error message is still very clear, and even gives correct modification method.</p>
<p><code>self</code> is referenced 2 times by mut. Although <code>self.byte_codes</code> is not used in <code>self.load_const()</code>, and there is no conflict in fact, the compiler does not know these details. The compiler only knows that <code>self</code> is referenced twice. This is the consequence of bringing together multiple members. The solution is to introduce a local variable as suggested by Rust, and then split this line of code into two lines:</p>
<pre><code class="language-rust  ignore">let code = self.load_const(iarg, Value::String(s));
self.byte_codes.push(code);</code></pre>
<p>The situation here is simple and easy to fixed, because the returned bytecode <code>code</code> is not related to <code>self.constants</code>, so it has no connection with <code>self</code>, so <code>self.byte_codes</code> can be used normally below. If the content returned by a method is still associated with this data structure, the solution becomes not so simple. This situation will be encountered later when the virtual machine is executed.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="variable-assignment"><a class="header" href="#variable-assignment">Variable Assignment</a></h1>
<p>In the program that prints &quot;hello, world!&quot; at the beginning of Chapter 1, we support global variables, namely the <code>print</code> function. However, it only supports <em>access</em>, but not <em>assignment</em> or <em>creation</em>. Now the only global variable <code>print</code> is manually added to the global variable table when creating a virtual machine. In the previous section, we implemented the definition and access of local variables, but assignment is also not supported. This section will implement <em>assignment</em> of global variables and local variables.</p>
<p>The assignment of simple variables is relatively simple, but the complete assignment statement in Lua is very complicated, such as <code>t[f()] = 123</code>. Here we first realize the variable assignment, and then briefly introduce the difference between the complete assignment statement.</p>
<h2 id="combination-of-assignments"><a class="header" href="#combination-of-assignments">Combination of Assignments</a></h2>
<p>The variable assignment statements to be supported in this section are expressed as follows:</p>
<pre><code>Name = exp
</code></pre>
<p>The left side of the equal sign <code>=</code> (lvalue) currently has two categories, local variables and global variables; the right side is the expression <code>exp</code> in the previous chapter, which can be roughly divided into three categories: constants, local variables, and global variables. So this is a 2*3 combination:</p>
<ul>
<li>
<p><code>local = const</code>, load the constant to the specified location on the stack, corresponding to the bytecode <code>LoadNil</code>, <code>LoadBool</code>, <code>LoadInt</code> and <code>LoadConst</code>, etc.</p>
</li>
<li>
<p><code>local = local</code>, copy the value on the stack, corresponding to the bytecode <code>Move</code>.</p>
</li>
<li>
<p><code>local = global</code>, assign the value on the stack to the global variable, corresponding to the bytecode <code>GetGlobal</code>.</p>
</li>
<li>
<p><code>global = const</code>, to assign a <em>constant</em> to a global variable, you need to add the constant to the constant table first, and then complete the assignment through the bytecode <code>SetGlobalConst</code>.</p>
</li>
<li>
<p><code>global = local</code>, assign <em>local variable</em> to global variable, corresponding to bytecode <code>SetGlobal</code>.</p>
</li>
<li>
<p><code>global = global</code>, assign <em>global variable</em> to global variable, corresponding to bytecode <code>SetGlobalGlobal</code>.</p>
</li>
</ul>
<p>Among these 6 cases, the first 3 are assigned to local variables. The <code>load_exp()</code> function in the previous section has been implemented and will not be introduced here. The latter three are assigned to global variables, and three new bytecodes are added accordingly. The parameter format of these 3 bytecodes is similar, and they all have 2 parameters, which are:</p>
<ol>
<li>The index of the name of the target global variable in the constant table, similar to the second parameter of the previous <code>GetGlobal</code> bytecode. So in these three cases, you need to add the name of the global variable to the constant table first.</li>
<li>Source index, the three bytecodes are: the index in the constant table, the address on the stack, and the index of the name of the global variable in the constant table.</li>
</ol>
<p>The fourth case above, that is <code>global = const</code>, handles all constant types with only one bytecode, not like <a href="./ch02-01.more_types.html#syntax-analysis">previous local variables</a> which set different bytecodes for some types (such as <code>LoadNil</code>, <code>LoadBool</code>, etc.). This is because <em>local variables</em> are located directly through the index on the stack, and the virtual machine executes its assignment very quickly. If the source data can be inlined into the bytecode and reduce the access to the constant table once, it can be significantly proportional performance improvement. However, accessing <em>global variables</em> requires a table lookup, and the execution of the virtual machine is slow. At this time, the performance improvement brought by the inline source data is relatively small, so it is unnecessary. After all, more bytecodes bring more complexity in the parsing and execution stages.</p>
<h2 id="lexical-analysis-1"><a class="header" href="#lexical-analysis-1">Lexical Analysis</a></h2>
<p>Originally, function calls and local variable definitions were supported, but now variable assignment statements are added. as follows:</p>
<pre><code>Name String
Name ( exp )
localName = exp
Name = exp # add new
</code></pre>
<p>There is a problem here. The newly added <em>variable assignment</em> statement also starts with <code>Name</code>, which is the same as <em>function call</em>. Therefore, based on the indistinguishability of the first token at the beginning, it is necessary to &quot;peek&quot; forward at another token: if it is an equal sign <code>=</code>, it is a variable assignment statement, otherwise it is a function call statement. The &quot;peek&quot; here is in quotation marks to emphasize that it is a real <em>peek</em> but not <em>take</em> the token, because the subsequent statement analysis still needs to use this token. To this end, the lexical analysis also adds a <code>peek()</code> method:</p>
<pre><code class="language-rust  ignore">    pub fn next(&amp;mut self) -&gt; Token {
        if self.ahead == Token::Eos {
            self.do_next()
        } else {
            mem::replace(&amp;mut self.ahead, Token::Eos)
        }
    }

    pub fn peek(&amp;mut self) -&gt; &amp;Token {
        if self.ahead == Token::Eos {
            self.ahead = self.do_next();
        }
        &amp;self.ahead
    }</code></pre>
<p>The <code>ahead</code> is a newly added field in the <code>Lex</code> structure, which is used to save the Token that is parsed from the character stream but cannot be returned. According to the convention of Rust language, this <code>ahead</code> should be of type <code>Option&lt;Token&gt;</code>, <code>Some(Token)</code> means that there is a Token read ahead, and <code>None</code> means there is no Token. But for the same reason as <code>next()</code><a href="./ch01-04.lets_do_it.html#lexical-analysis">return value type</a>, the <code>Token</code> type is directly used here, and <code>Token::Eos</code> is used to represent no Read Token in advance.</p>
<p>The original external <code>next()</code> function is changed to <code>do_next()</code> internal function, which is called by the newly added <code>peek()</code> and new <code>next()</code> functions.</p>
<p>The newly added <code>peek()</code> function returns <code>&amp;Token</code> instead of <code>Token</code>, because the owner of the Token is still Lex, and it has not been handed over to the caller. Just &quot;lending&quot; it to the caller to &quot;look&quot;. If the caller not only wants to &quot;see&quot; but also &quot;change&quot;, then <code>&amp;mut Token</code> is needed, but we only need to look, and do not need to change. Now that there is <code>&amp;</code> borrowing, it involves <a href="https://doc.rust-lang.org/stable/book/ch10-03-lifetime-syntax.html">lifetime</a> in Rust. Since this function has only one input lifetime parameter, that is <code>&amp;mut self</code>, according to <a href="https://doc.rust-lang.org/stable/book/ch10-03-lifetime-syntax.html#lifetime-elision">elision rules</a>, which is given to all output lifetime parameters, the annotation of the lifetime can be omitted below. This default lifetime means to the compiler that the legal cycle of the returned reference <code>&amp;Token</code> is less than or equal to the input parameter, namely <code>&amp;mut self</code>, that is, <code>Lex</code> itself.</p>
<blockquote>
<p>I personally think that the owner of variables, borrowing (reference), and variable borrowing are the core concepts of the Rust language. The concept itself is very simple, but it takes a period of in-depth struggle with the compiler to understand it deeply. The concept of lifetime is based on the above-mentioned core concepts, but it is also slightly more complicated and needs to be understood in practice.</p>
</blockquote>
<p>The new <code>next()</code> is a simple wrapper for the original <code>do_next()</code> function, which handles the Token that may be stored in <code>ahead</code> and peeked before: if it exists, it will directly return this Token without calling<code> do_next()</code>. But this &quot;direct return&quot; in Rust is not very straightforward. Since <code>Token</code> type is not <code>Copy</code> (because its <code>String(String)</code> type is not <code>Copy</code>), so <a href="https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html#memory-and-allocation">cannot return directly</a>. The simple solution is to use <code>Clone</code>, but the meaning of Clone is to tell us that there is a price to pay, for example, for string type, we need to copy the string content; and we don't need 2 copies of strings, because the Token is returned. After that, we don't need this Token anymore. So the result we need now is: return the Token in <code>ahead</code>, and <em>simultaneously</em> clean up <code>ahead</code> (here naturally set to represent &quot;no&quot; <code>Token::Eos</code>). This scene is very similar to the gif of &quot;Raiders of the Lost Ark&quot; that is widely circulated on the Internet (search for &quot;Raiders of the Lost Ark gif&quot; on the internet), and the sandbag in the hand &quot;replaces&quot; the treasure on the mechanism. &quot;Replace&quot; here is a keyword, and this requirement can be fulfilled with the <code>std::mem::replace()</code> function in the standard library. This requirement is so common (at least very common in C language projects) that it feels surprised to use such a long-name function to achieve it. But it is precisely because of these restrictions that the security promised by Rust is guaranteed. But if <code>ahead</code> is of <code>Option&lt;Token&gt;</code> type, then you can use the <code>take()</code> method of <code>Option</code>, which looks simpler and has exactly the same function.</p>
<h2 id="syntax-analysis-2"><a class="header" href="#syntax-analysis-2">Syntax Analysis</a></h2>
<p>With the increase of functions, there will be more and more internal codes in the big cycle of syntax analysis, so we first put each statement into an independent function, namely <code>function_call()</code> and <code>local()</code>, and then add variable assignment statement <code>assignment()</code>. The <code>peek()</code> function added in the lexical analysis just now is used here:</p>
<pre><code class="language-rust  ignore">     fn chunk(&amp;mut self) {
         loop {
             match self. lex. next() {
                 Token::Name(name) =&gt; {
                     if self.lex.peek() == &amp;Token::Assign {
                         self. assignment(name);
                     } else {
                         self. function_call(name);
                     }
                 }
                 Token::Local =&gt; self. local(),
                 Token::Eos =&gt; break,
                 t =&gt; panic!(&quot;unexpected token: {t:?}&quot;),
             }
         }
     }</code></pre>
<p>Then look at the <code>assignment()</code> function:</p>
<pre><code class="language-rust  ignore">     fn assignment(&amp;mut self, var: String) {
         self. lex. next(); // `=`

         if let Some(i) = self. get_local(&amp;var) {
             // local variable
             self. load_exp(i);
         } else {
             // global variable
             let dst = self.add_const(var) as u8;

             let code = match self. lex. next() {
                 // from const values
                 Token::Nil =&gt; ByteCode::SetGlobalConst(dst, self.add_const(Value::Nil) as u8),
                 Token::True =&gt; ByteCode::SetGlobalConst(dst, self.add_const(Value::Boolean(true)) as u8),
                 Token::False =&gt; ByteCode::SetGlobalConst(dst, self.add_const(Value::Boolean(false)) as u8),
                 Token::Integer(i) =&gt; ByteCode::SetGlobalConst(dst, self.add_const(Value::Integer(i)) as u8),
                 Token::Float(f) =&gt; ByteCode::SetGlobalConst(dst, self.add_const(Value::Float(f)) as u8),
                 Token::String(s) =&gt; ByteCode::SetGlobalConst(dst, self.add_const(Value::String(s)) as u8),

                 // from variable
                 Token::Name(var) =&gt;
                     if let Some(i) = self. get_local(&amp;var) {
                         // local variable
                         ByteCode::SetGlobal(dst, i as u8)
                     } else {
                         // global variable
                         ByteCode::SetGlobalGlobal(dst, self. add_const(Value::String(var)) as u8)
                     }

                 _ =&gt; panic!(&quot;invalid argument&quot;),
             };
             self.byte_codes.push(code);
         }
     }</code></pre>
<p>For the case where the lvalue is a local variable, call <code>load_exp()</code> to handle it. For the case of global variables, according to the type of the expression on the right, generate <code>SetGlobalConst</code>, <code>SetGlobal</code> and <code>SetGlobalGlobal</code> bytecodes respectively.</p>
<p>Finally, the <code>get_local()</code> definition:</p>
<pre><code class="language-rust  ignore">    fn get_local(&amp;self, name: &amp;str) -&gt; Option&lt;usize&gt; {
        self.locals.iter().rposition(|v| v == name)
    }</code></pre>
<h2 id="test-3"><a class="header" href="#test-3">Test</a></h2>
<p>Use the following code to test the above six variable assignments:</p>
<pre><code class="language-lua">local a = 456
a = 123
print(a)
a = a
print(a)
a = g
print(a)
g = 123
print(g)
g = a
print(g)
g = g2
print(g)
</code></pre>
<p>Execution is as expected. The specific execution results will no longer be posted.</p>
<h2 id="complete-assignment-statement"><a class="header" href="#complete-assignment-statement">Complete Assignment Statement</a></h2>
<p>The function of the above variable assignment is very simple, but the complete assignment statement of Lua is very complicated. Mainly manifested in the following two places:</p>
<p>First of all, the left side of the equal sign <code>=</code> now only supports local variables and global variables, but the assignment of table fields is also supported in the complete assignment statement, such as <code>t.k = 123</code>, or the more complex <code>t[f()+g ()] = 123</code>. The above <code>assignment()</code> function is difficult to add table support. For this reason, it is necessary to add an intermediate expression layer, that is, the <code>ExpDesc</code> structure introduced by the subsequent chapter.</p>
<p>Second, the expression following the equal sign <code>=</code> is now divided into 3 categories, for 3 bytecodes. If we want to introduce other types of expressions later, such as upvalue, table index (such as <code>t.k</code>), or operation results (such as <code>a+b</code>), do we have to add a bytecode to each type? The answer is, no. But this will involve some problems that have not been encountered yet, so it is not easy to explain. If not, what needs to be done? This also involves the <code>ExpDesc</code> mentioned above.</p>
<p>We will implement Lua's complete assignment statement in the future, and the current assignment code will be completely discarded at that time.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="string"><a class="header" href="#string">String</a></h1>
<p>Before moving on to improve our interpreter, this chapter pauses to discuss the string type in Lua in detail. In a high-level language like Lua, strings are easy to use; but in a low-level language like Rust, strings are not so simple. Here is a quote from <a href="https://doc.rust-lang.org/stable/book/ch08-02-strings.html">&quot;Rust Programming Language&quot;</a>:</p>
<blockquote>
<p>New Rustaceans commonly get stuck on strings for a combination of three reasons: Rust’s propensity for exposing possible errors, strings being a more complicated data structure than many programmers give them credit for, and UTF-8. These factors combine in a way that can seem difficult when you’re coming from other programming languages.</p>
</blockquote>
<p>Implementing and optimizing strings in the Lua interpreter is a great opportunity to explore Rust strings.</p>
<p>Based on the definition of string type, this chapter will also make an important decision: <a href="./ch03-05.rc-vs-gc">use <code>Rc</code> to implement garbage collection</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="string-definition"><a class="header" href="#string-definition">String Definition</a></h1>
<p>This section does not add new features for now, but stops to discuss and optimize the string type.</p>
<p><a href="https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html">Ownership</a> section in the book &quot;Rust Programming Language&quot; introduces the heap using strings as an example of stack and heap, and the relationship with ownership; <a href="https://doc.rust-lang.org/stable/book/ch08-02-strings.html">String</a> section says the strings are complex. We will now use strings to explore Rust's allocation of heaps and stacks, and initially experience the complexity of strings.</p>
<h2 id="heap-and-stack"><a class="header" href="#heap-and-stack">Heap and Stack</a></h2>
<p><a href="https://doc.rust-lang.org/stable/book/trpl-zh-cn/ch04-01-what-is-ownership.html">&quot;Rust Programming Language&quot;</a> uses strings as an example to introduce the concept of heap and stack, and the relationship between stack and ownership. Here is a brief recap. Rust's String consists of two parts:</p>
<ol>
<li>Metadata, generally located on the stack, includes 3 fields: a pointer to the memory block, the length of the string, and the capacity of the memory block. The following are represented by <code>buffer</code>, <code>len</code> and <code>cap</code> respectively.</li>
<li>The private memory block used to store the string content is applied on the heap. Owned by the string, so is freed when the string ends. Because of this piece of memory on the heap, String is not <code>Copy</code>, which in turn leads to <code>Value</code> not being <code>Copy</code>. In order to copy <code>Value</code>, it can only be defined as <code>Clone</code>.</li>
</ol>
<p>For example, for a string whose content is &quot;hello, world!&quot;, the memory layout is as follows. On the left is the metadata on the stack, where <code>buffer</code> points to the memory block on the heap, <code>len</code> is the length of the string, which is 13, and <code>cap</code> is the capacity of the memory block, which is likely to be aligned to 16. On the right is the block of memory on the heap that stores the contents of the string.</p>
<pre><code>    stack             heap
    +--------+
    | buffer +-------&gt;+----------------+
    |--------|        |hello, world!   |
    | len=13 |        +----------------+
    |--------|
    | cap=16 |
    +--------+
</code></pre>
<p>What needs to be explained here is that the metadata &quot;generally&quot; located on the stack above is for simple types. But for complex types, such as <code>Vec&lt;String&gt;</code>, the String metadata part is also stored on the heap as the content of the array (similar to the memory block part of String). Below is an array Vec with 2 string members. The metadata of the array itself is on the stack, but the metadata of the string is on the heap.</p>
<pre><code>    stack             heap
    +--------+
    | buffer +-------&gt;+-------------+-------------+----
    |--------|        | buf|len|cap | buf|len|cap | ...
    | len=2  |        +--+----------+--+----------+----
    |--------|           |             V
    | cap=4  |           V             +----------------+
    +--------+        +--------+       |hello, world!   |
                      |print   |       +----------------+
                      +--------+
</code></pre>
<p>In this case, although the metadata array part is on the heap, it still has the characteristics of the stack, including last-in-first-out, fast access through indexes, fixed known size, and no need for management (allocation and free). In fact, the stack of the virtual machine of our Lua interpreter is a similar <code>Vec&lt;Value&gt;</code> type. Similarly, although its data is on the heap, it has the characteristics of a stack. The term &quot;stack&quot; has two meanings here: the stack at the Rust level, and the stack at the Lua virtual machine. The latter is on the heap at the Rust level. The &quot;stack&quot; mentioned below in this article is the latter meaning, that is, the stack of the Lua virtual machine. But it doesn't matter if you understand it as a Rust stack.</p>
<h2 id="use-string"><a class="header" href="#use-string">Use String</a></h2>
<p>Currently the string type of Value uses <code>String</code> in the Rust standard library directly:</p>
<pre><code class="language-rust  ignore">#[derive(Clone)]
struct Value {
     String(String),</code></pre>
<p>The biggest problem with this definition is that if you want to copy the Value of a string, you must deeply copy the string content, that is, Clone. The following diagram represents the memory layout for copying a string:</p>
<pre><code>    stack              heap
    |        |
    +--------+
    |t|      |
    |-+------|
    | buffer +-------&gt;+----------------+
    |--------|        |hello, world!   |
    | len=13 |        +----------------+
    |--------|
    | cap=16 |
    +--------+
    :        :
    :        :
    +--------+
    |t|      |
    |-+------|
    | buffer +-------&gt;+----------------+
    |--------|        |hello, world!   |
    | len=13 |        +----------------+
    |--------|
    | cap=16 |
    +--------+
    |        |
</code></pre>
<p>The left side of the figure is the stack of the Lua virtual machine, and each line represents a word. Since we are developing based on a 64-bit system, a word is 8 bytes.</p>
<p>The <code>t</code> in line 1 represents the tag of <code>enum Value</code>. Since our Value type is less than 256 types, 1 byte can be represented, so t occupies 1 byte. The next 3 lines <code>buffer</code>, <code>len</code> and <code>cap</code> form a Rust standard library String. Each field occupies one word. <code>buffer</code> is 8-byte aligned, so there are 7 bytes empty between <code>t</code> and this part is unusable. These 4 lines (the rectangle surrounded by four <code>+</code> in the figure) constitute a value of string type in total.</p>
<blockquote>
<p>There is no default layout for enums in Rust (although it can be specified). We only list one layout possibility here. This does not affect the discussion in this section.</p>
</blockquote>
<p>To deeply copy the string Value, you need to copy the metadata on the stack and the memory block on the heap, which is a great waste of performance and memory. The most straightforward way to solve this problem in Rust is to use <code>Rc</code>.</p>
<h2 id="use-rcstring"><a class="header" href="#use-rcstring">Use Rc&lt;String&gt;</a></h2>
<p>In order to quickly copy the string String, it is necessary to allow multiple owners of the string at the same time. Rust's <a href="https://doc.rust-lang.org/stable/book/ch15-04-rc.html">Rc</a> provides this feature. Encapsulate <code>Rc</code> outside String, and only need to update the Rc count when copying. It is defined as follows:</p>
<pre><code class="language-rust  ignore">#[derive(Clone)]
struct Value {
     String(Rc&lt;String&gt;),</code></pre>
<p>The memory layout is as follows:</p>
<pre><code>    stack             heap
    |        |
    +--------+
    |t|      |
    |-+------|
    |   Rc   +----+--&gt;+--------+--------+--------+--------+--------+
    +--------+    |   |count=2 | weak=0 | buffer | len=13 | cap=16 |
    :        :    |   +--------+--------+-+------+--------+--------+
    :        :    |                       |
    +--------+    |                       V
    |t|      |    |                       +----------------+
    |-+------|    |                       |hello, world!   |
    |   Rc   +----/                       +----------------+
    +--------+ 
    |        |
</code></pre>
<p>The <code>count</code> and <code>weak</code> on the right side of the figure are the packages of <code>Rc</code>. Since there are currently 2 Values pointing to this string, <code>count</code> is 2.</p>
<p>Using <code>Rc</code> directly causes the interpreter to use reference counting to implement garbage collection. The <a href="./ch03-05.gc_vs_rc.html">subsection below</a> is devoted to this high-impact decision.</p>
<p>Although this solution solves the problem of copying, it also brings a new problem, that is, accessing the content of the string requires 2 pointer jumps. This wastes memory and affects execution performance. Some optimization schemes are introduced below.</p>
<h2 id="use-rcstr"><a class="header" href="#use-rcstr">Use Rc&lt;str&gt;</a></h2>
<p>Strings in Lua have a feature that they are read-only! If you want to process the string, such as truncation, connection, replacement, etc., a new string will be generated. Rust's String is designed for mutable strings, so it is a bit wasteful to represent read-only strings. For example, the <code>cap</code> field in metadata can be removed, and there is no need to reserve memory for possible modifications. For example, in the above example, the length of &quot;hello, world!&quot; is only 13, but a memory block of 16 is allocated for. In Rust, it is more suitable to represent a read-only string is <code>&amp;str</code>, which is the <a href="https://doc.rust-lang.org/stable/book/ch04-03-slices.html">slice</a> of <code>String</code>. But <code>&amp;str</code> is a reference, and does not have ownership of the string, but needs to be attached to a string. However, it has a reference that is not a string (the reference of a string is <code>&amp;String</code>). Intuitively, it should be a reference to <code>str</code>. What is <code>str</code>? It's as if it never appeared alone.</p>
<p>For example. For code like this:</p>
<pre><code class="language-rust  ignore">let s = String::from(&quot;hello, world!&quot;); // String
let r = s[7..12]; // &amp;str</code></pre>
<p>Where <code>r</code> is <code>&amp;str</code> type, and the memory layout is as follows:</p>
<pre><code>    stack             heap
s:  +--------+
    | buffer +-------&gt;+----------------+
    |--------|        |hello, world!   |
    | len=13 |        +-------^--------+
    |--------|                |
    | cap=16 |                |
    +--------+                |
                              |
r:  +--------+                |
    | buffer +----------------/
    |--------|
    | len=5  |
    +--------+
</code></pre>
<p>Then dereferencing <code>&amp;str</code>, what you get is the &quot;world&quot; memory. However, a general reference is an address, but length information is also added here, indicating that <code>str</code> includes length information in addition to memory. The length information is not on the original data like String, but follows the reference together. In fact, <code>str</code> does not exist independently, it must follow a reference (such as <code>&amp;str</code>) or a pointer (such as <code>Box(str)</code>). This is <a href="https://doc.rust-lang.org/stable/book/ch19-04-advanced-types.html#dynamically-sized-types-and-the-sized-trait">dynamic size type</a>.</p>
<p>And <code>Rc</code> is also a pointer, so <code>Rc&lt;str&gt;</code> can be defined. It is defined as follows:</p>
<pre><code class="language-rust  ignore">#[derive(Clone)]
struct Value {
     String(Rc&lt;str&gt;),</code></pre>
<p>The memory layout is as follows:</p>
<pre><code>    stack             heap
    |        |
    +--------+
    |t|      |
    |-+------|
    |   Rc   +----+--&gt;+--------+--------+-------------+
    |--------|    |   |count=2 | weak=0 |hello, world!|
    | len=13 |    |   +--------+--------+-------------+
    +--------+    |
    :        :    |
    :        :    |
    +--------+    |
    |t|      |    |
    |-+------|    |
    |   Rc   +----/
    +--------+
    | len=13 |
    +--------+
    |        |
</code></pre>
<p>Among them, &quot;hello, world!&quot; is the original data, which is encapsulated by Rc. The length information <code>len=13</code> is stored on the stack along with <code>Rc</code>.</p>
<p>This scheme looks very good! Compared with the <code>Rc&lt;String&gt;</code> scheme above, this scheme removes the useless <code>cap</code> field, does not need to reserve memory, and also saves a layer of pointer jumps. But this solution also has 2 problems:</p>
<p>First, the content needs to be copied when creating the string value. The previous solution only needs to copy the metadata part of the string, which is only 3 words long. And this scheme should copy the string content to the newly created Rc package. Imagine creating a 1M long string, this copying affects performance a lot.</p>
<p>Secondly, it occupies 2 words of space on the stack. Although the problem was more serious in the earliest scheme of directly using String to occupy 3 characters, it can be understood that our current standard has been improved. At present, other types in Value only occupy a maximum of 1 word (plus tag, a total of 2 words). What can be spoiled is that the types of tables and UserData to be added in the future also only occupy 1 word, so it is a waste to change the size of Value from 2 to 3 just because of the string type. Not only does it take up more memory, but it's also unfriendly to the CPU cache.</p>
<p>The key to these problems is that <code>len</code> follows <code>Rc</code>, not the data. It would be perfect if we could put <code>len</code> on the heap, say between <code>weak</code> and &quot;hello, world!&quot; in the picture. This is trivial for C, but Rust doesn't support it. The reason is that <code>str</code> is a dynamically sized type. So if you choose a fixed size type, can it be realized? Such as arrays.</p>
<h2 id="use-rcu8-u8-47"><a class="header" href="#use-rcu8-u8-47">Use Rc&lt;(u8, [u8; 47])&gt;</a></h2>
<p>Arrays in Rust have intrinsic size information. For example, the sizes of <code>[u8; 10]</code> and <code>[u8; 20]</code> are 10 and 20 respectively. This size is known at compile time, and there is no need to store it following the pointer. Two arrays with different lengths are different types, such as <code>[u8; 10]</code> and <code>[u8; 20]</code> are different types. Therefore, the array is a fixed-size type, which can solve the problem in the previous section, that is, only one word is needed on the stack.</p>
<p>Since it is a fixed length, it can only store strings smaller than this length, so this solution is incomplete and can only be a supplementary solution for performance optimization. However, most of the strings encountered in Lua are very short, at least in my experience, so this optimization is still very meaningful. To do this, we need to define 2 string types, one is a fixed-length array, which is used to optimize short strings, and the other is the previous <code>Rc&lt;String&gt;</code> scheme, which is used to store long strings. The first byte of the fixed-length array is used to represent the actual length of the string, so the array can be split into two parts. Let's first assume that an array with a total length of 48 is used (1 byte represents the length, and 47 bytes store the string content), then the definition is as follows:</p>
<pre><code class="language-rust  ignore">struct Value {
     FixStr(Rc&lt;(u8, [u8; 47])&gt;), // len&lt;=47
     String(Rc&lt;String&gt;), // len&gt;47</code></pre>
<p>The memory layout for short strings is as follows:</p>
<pre><code>    stack              heap
    |        |
    +--------+
    |t|      |
    |-+------|
    |   Rc   +----+--&gt;+--------+--------+----------------------------+
    +--------+    |   |count=2 | weak=0 |len|hello, world!           |
    :        :    |   +--------+--------+----------------------------+
    :        :    |
    +--------+    |
    |t|      |    |
    |-+------|    |
    |   Rc   +----/
    +--------+
    |        |
</code></pre>
<p>The first byte <code>len</code> at the beginning of the array part on the right in the figure indicates the actual length of the following string. The next 47 bytes can be used to store string content.</p>
<p>This solution is the same as <code>Rc&lt;str&gt;</code> mentioned above, it needs to copy the string content, so it is not suitable for long strings. This is not a big problem. Originally, this solution was designed to optimize short strings. Then even if it is a short string, the selection of the array length is also critical. If it is very long, the space waste is serious for short strings; if it is very short, the coverage ratio is not high. However, this solution can continue to be optimized, using arrays with multi-level lengths, such as 16, 32, 48, 64, etc. However, this also creates some complications.</p>
<p>In addition, the selection of the array length also depends on the memory management library used by Rust. For example, if we choose the length to be 48, plus the two counting fields encapsulated by Rc of 16 bytes, then the length of the memory block on the right heap in the above figure is 64 bytes, which is a very &quot;regular&quot; length. For example, the memory management library jemalloc manages small memory blocks into lengths of 16, 32, 48, 64, and 128, so the above-mentioned memory application with a total length of 64 is not wasted. If we choose the array length to be 40, the total length of the memory block is 56, and it will still be matched to the category of 64, and 64-56=8 bytes will be wasted. Of course, it is very bad behavior to rely on the specific implementation of other libraries to make decisions, but fortunately, the impact is not great.</p>
<p>Here we choose an array length of 48, that is, only strings with lengths from 0 to 47 can be represented.</p>
<p>Then compare it with the <code>Rc&lt;String&gt;</code> scheme to see how the optimization works. First of all, the biggest advantage of this solution is that only one memory allocation is required, and only one pointer jump is required during execution.</p>
<p>Second, compare the allocated memory size. In the <code>Rc&lt;String&gt;</code> scheme, you need to apply for 2 blocks of memory: one is the Rc count and string metadata, fixed 2+3=5 words, 40 bytes, according to the memory strategy of jemalloc, it will occupy 48 bytes of memory ; The second is the string content. The memory size is related to the length of the string, and also depends on the memory management strategy of Rust String and the implementation of the underlying library. For example, a string with a length of 1 may occupy 16 bytes of memory; A character string with a length of 47 may occupy 48 bytes or 64 bytes of memory. The two blocks of memory together occupy 64 to 112 bytes, which is greater than or equal to this fixed-length array solution.</p>
<p>Let's look at the next solution along the line of &quot;optimizing short strings&quot;.</p>
<h2 id="use-inline-arrays"><a class="header" href="#use-inline-arrays">Use Inline Arrays</a></h2>
<p>Compared with <code>Rc&lt;String&gt;</code>, the previous solution reduces one layer of pointer jumps. The following solution goes a step further, directly removing the storage on the heap, and storing the string completely on the stack.</p>
<p>We want the size of the <code>Value</code> type to be 2 words, or 16 bytes. One of them is used for tag, and one is used for string length, so there are 14 bytes remaining, which can be used to store strings with a length less than 14. This scheme is also a supplementary scheme, and it must also be used in conjunction with a long string definition. details as follows:</p>
<pre><code class="language-rust  ignore">// sizeof(Value) - 1(tag) - 1(len)
const INLSTR_MAX: usize = 14;

struct Value {
     InlineStr(u8, [u8; INLSTR_MAX]), // len&lt;=14
     String(Rc&lt;String&gt;), // len&gt;14</code></pre>
<p>The short string <code>InlineStr</code> is associated with two parameters: the string length of the <code>u8</code> type, and the <code>u8</code> array with a length of 14, which also makes full use of the 7 bytes behind <code>t</code> that have been wasted before. hollow. The long string <code>String</code> still uses the <code>Rc&lt;String&gt;</code> scheme.</p>
<p>The memory layout for short strings is as follows:</p>
<pre><code>     stack
    |        |
    +vv------+
    |tlhello,|
    |--------|
    | world! |
    +--------+
    :        :
    :        :
    +vv------+
    |tlhello,|
    |--------|
    | world! |
    +--------+
    |        |
</code></pre>
<p>The <code>t</code> and <code>l</code> pointed to by the arrow <code>v</code> on the grid represent the tag and length of 1 byte, respectively. The actual string content spans 2 words. If you draw the stack horizontally, it looks clearer:</p>
<pre><code>stack:
    --+-+-+--------------+......+-+-+--------------+--
      |t|l|hello, world! |      |t|l|hello, world! |
    --+------------------+......+------------------+--
</code></pre>
<p>This solution has the best performance, but the worst ability, and can only handle strings with a length no greater than 14. There are three usage scenarios of string type in Lua: global variable name, table index, and string value. Most of the first two are not larger than 14 bytes, so it should be able to cover most cases.</p>
<p>It can be further optimized by adding another type to store strings with a length of 15. Since the length is known, one byte originally used to store the length can also be used to store the content of the string. However, the optimization brought by this solution is not obvious and less than the complexity brought, so it is not used. It is defined as follows.</p>
<pre><code class="language-rust  ignore">struct Value {
     InlineStr(u8, [u8; INLSTR_MAX]), // len&lt;=14
     Len15Str([u8; 15]), //len=15
     String(Rc&lt;String&gt;), // len&gt;15</code></pre>
<h2 id="summary-and-choice"><a class="header" href="#summary-and-choice">Summary and Choice</a></h2>
<p>In this section, we used and analyzed <code>String</code>, <code>Rc&lt;String&gt;</code>, <code>Rc&lt;str&gt;</code>, <code>Rc&lt;(u8, [u8; 47])&gt;</code> and inline <code>(u8, [u8; 14])</code> and several other schemes. Each has advantages and disadvantages. A reasonable approach is to treat long and short strings differently, use short strings to optimize, and use long strings to cover the bottom line. 3 options are available:</p>
<ul>
<li>In order to guarantee the length of the <code>Value</code> type as 2 words, only <code>Rc&lt;String&gt;</code> can be used for long strings.</li>
<li>For short strings, the final inlining solution does not use heap memory at all, and the optimization effect is the best.</li>
<li>The penultimate fixed-length array scheme is a compromise between the above two schemes, which is slightly tasteless. However, there is only one disadvantage, which is to introduce greater complexity, and strings need to deal with 3 types. In the next section, generics are used to shield these three types, which solves this shortcoming.</li>
</ul>
<p>The final solution is as follows:</p>
<pre><code class="language-rust  ignore">const SHORT_STR_MAX: usize = 14; // sizeof(Value) - 1(tag) - 1(len)
const MID_STR_MAX: usize = 48 - 1;

struct Value {
     ShortStr(u8, [u8; SHORT_STR_MAX]),
     MidStr(Rc&lt;(u8, [u8; MID_STR_MAX])&gt;),
     LongStr(Rc&lt;Vec&lt;u8&gt;&gt;),</code></pre>
<p>The original <code>InlineStr</code> and <code>FixStr</code> both represent specific implementation solutions, and the characteristics of external performance are long and short, so they are renamed <code>ShortStr</code>, <code>MidStr</code> and <code>LongStr</code>, which are more intuitive.</p>
<p>In this way, most cases (short strings) can be processed quickly, and for a small number of cases (long strings), although slow, they can also be processed correctly, and do not affect the overall situation (for example, <code>Rc&lt;str&gt;</code> takes up 2 word, directly makes <code>Value</code> larger, even if it affects the overall situation), and ultimately improves the overall processing efficiency. This is a very common and effective optimization idea. Our scheme achieves optimization by distinguishing between two sets of definitions, which is a typical example. It would be even more beautiful if this goal can be achieved with only one set of definitions and one set of algorithms without distinguishing definitions. We will encounter such an example later in the syntax analysis of <a href="./ch04-05.table_rw_and_bnf.html">assignment statement</a>.</p>
<p>After distinguishing between long and short strings, it also brings two new problems:</p>
<ol>
<li>
<p>When generating the string type <code>Value</code>, we need to choose <code>ShortStr</code>, <code>MidStr</code> or <code>LongStr</code> according to the length of the string. This choice should be implemented automatically, not by the caller, otherwise it will be troublesome and may make mistakes. For example, the <code>self.add_const(Value::String(var))</code> statement that appears many times in the syntax analysis code needs to be improved.</p>
</li>
<li>
<p>Strings are composed of &quot;characters&quot;, but <code>ShortStr</code> and <code>MidStr</code> are both composed of <code>u8</code>, what is the difference? How does <code>u8</code> express Unicode correctly? How to deal with illegal characters?</p>
</li>
</ol>
<p>The next few sections discuss these two issues.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="type-conversion"><a class="header" href="#type-conversion">Type Conversion</a></h1>
<p>The previous section introduced three string types in the <code>Value</code> type. When creating a string type, different types need to be generated according to the length. This judgment should not be handed over to the caller, but should be done automatically. For example, the existing statement:</p>
<pre><code class="language-rust  ignore">     self. add_const(Value::String(var));</code></pre>
<p>should be changed to:</p>
<pre><code class="language-rust  ignore">     self.add_const(str_to_value(var));</code></pre>
<p>The <code>str_to_value()</code> function converts the string <code>var</code> into the string type corresponding to <code>Value</code>.</p>
<h2 id="from-trait"><a class="header" href="#from-trait"><code>From</code> trait</a></h2>
<p>This function of converting (or generating) from one type to another is very common, so the <code>From</code> and <code>Into</code> traits are defined in the Rust standard library for this. These two operations are opposite to each other, and generally only need to implement <code>From</code>. The following implements the conversion of the string <code>String</code> type to <code>Value</code> type:</p>
<pre><code class="language-rust  ignore">impl From&lt;String&gt; for Value {
     fn from(s: String) -&gt; Self {
         let len = s.len();
         if len &lt;= SHORT_STR_MAX {
             // A string with a length of [0-14]
             let mut buf = [0; SHORT_STR_MAX];
             buf[..len].copy_from_slice(s.as_bytes());
             Value::ShortStr(len as u8, buf)

         } else if len &lt;= MID_STR_MAX {
             // A string with a length of [15-47]
             let mut buf = [0; MID_STR_MAX];
             buf[..len].copy_from_slice(s.as_bytes());
             Value::MidStr(Rc::new((len as u8, buf)))

         } else {
             // Strings with length greater than 47
             Value::LongStr(Rc::new(s))
         }
     }
}</code></pre>
<p>Then, the statement at the beginning of this section can be changed to use the <code>into()</code> function:</p>
<pre><code class="language-rust  ignore">     self.add_const(var.into());</code></pre>
<h2 id="generics"><a class="header" href="#generics">Generics</a></h2>
<p>So far, the requirements at the beginning of this section have been completed. But since strings can do this, so can other types. And other types of transformations are more intuitive. Listed below are only two conversions from numeric types to the <code>Value</code> type:</p>
<pre><code class="language-rust  ignore">impl From&lt;f64&gt; for Value {
    fn from(n: f64) -&gt; Self {
        Value::Float(n)
    }
}

impl From&lt;i64&gt; for Value {
    fn from(n: i64) -&gt; Self {
        Value::Integer(n)
    }
}</code></pre>
<p>Then, adding a numerical type <code>Value</code> to the constant table can also pass the <code>into()</code> function:</p>
<pre><code class="language-rust  ignore">     let n = 1234_i64;
     self.add_const(Value::Integer(n)); // old way
     self.add_const(n.into()); // new way</code></pre>
<p>This may seem like a bit of an overkill. But if you implement <code>From</code> for all types that can be converted to <code>Value</code>, then you can put <code>.into()</code> inside <code>add_const()</code>:</p>
<pre><code class="language-rust  ignore">    fn add_const(&amp;mut self, c: impl Into&lt;Value&gt;) -&gt; usize {
        let c = c.into();</code></pre>
<p>Only the first 2 lines of code of this function are listed here. The following is the original logic of adding constants, which is omitted here.</p>
<p>Look at the second line of code first, put <code>.into()</code> inside the <code>add_const()</code> function, then there is no need for <code>.into()</code> when calling externally. For example, the previous statement of adding strings and integers can be abbreviated as:</p>
<pre><code class="language-rust  ignore">     self. add_const(var);
     self. add_const(n);</code></pre>
<p>Many places in the existing code can be modified in this way, and it will become much clearer, so it is worthwhile to implement the <code>From</code> trait for these types.</p>
<p>However, here comes the problem: in the above 2 lines of code, the types of parameters accepted by the two <code>add_const()</code> function calls are inconsistent! In the function definition, how to write this parameter type? The answer lies in the definition of the <code>add_const()</code> function above: <code>c: impl Into&lt;Value&gt;</code>. Its full writing is as follows:</p>
<pre><code class="language-rust  ignore">     fn add_const&lt;T: Into&lt;Value&gt;&gt;(&amp;mut self, c: T) -&gt; usize {</code></pre>
<p>This definition means: the parameter type is <code>T</code>, and its constraint is <code>Into&lt;Value&gt;</code>, that is, this <code>T</code> needs to be able to be converted into <code>Value</code>, and no arbitrary type or data structure can be added to the constant table inside.</p>
<p>This is <a href="https://doc.rust-lang.org/stable/book/ch10-01-syntax.html">generic</a> in the Rust language! Many books and articles have introduced them very clearly, so we do not introduce generics completely here. In fact, we have used generics very early, such as the definition of the global variable table: <code>HashMap&lt;String, Value&gt;</code>. In most cases, some library <em>defines</em> types and functions with generics, and we just <em>use</em>. And <code>add_const()</code> here is <em>defining</em> a function with generics. The next section will introduce another generic usage example.</p>
<h2 id="reverse-conversion"><a class="header" href="#reverse-conversion">Reverse Conversion</a></h2>
<p>The above is to convert the basic type to <code>Value</code> type. But in some cases, the reverse conversion is required, that is, converting the <code>Value</code> type to the corresponding base type. For example, the global variable table of the virtual machine is indexed by the string type, and the name of the global variable is stored in the <code>Value</code> type constant table, so it is necessary to convert the <code>Value</code> type to a string type to be used as an index use. Among them, the read operation and write operation of the global variable table are different, and the corresponding HashMap APIs are as follows:</p>
<pre><code class="language-rust  ignore">pub fn get&lt;Q: ?Sized&gt;(&amp;self, k: &amp;Q) -&gt; Option&lt;&amp;V&gt; // omit the constraint of K, Q
pub fn insert(&amp;mut self, k: K, v: V) -&gt; Option&lt;V&gt;</code></pre>
<p>The difference between reading and writing is that the parameter <code>k</code> of the read <code>get()</code> function is a reference, while the parameter <code>k</code> of the write <code>insert()</code> function is the index itself. The reason is also simple, just use the index when reading, but add the index to the dictionary when writing, and consume <code>k</code>. So we need to realize the conversion of the <code>Value</code> type to the string type itself and its reference, namely <code>String</code> and <code>&amp;String</code>. But for the latter, we use the <a href="https://doc.rust-lang.org/stable/book/ch04-03-slices.html#string-slices-as-parameters">more generic <code>&amp;str</code></a> instead. (TODO: should use <code>AsRef</code> here)</p>
<pre><code class="language-rust  ignore">impl&lt;'a&gt; From&lt;&amp;'a Value&gt; for &amp;'a str {
     fn from(v: &amp;'a Value) -&gt; Self {
         match v {
             Value::ShortStr(len, buf) =&gt; std::str::from_utf8(&amp;buf[..*len as usize]).unwrap(),
             Value::MidStr(s) =&gt; std::str::from_utf8(&amp;s.1[..s.0 as usize]).unwrap(),
             Value::LongStr(s) =&gt; s,
             _ =&gt; panic!(&quot;invalid string Value&quot;),
         }
     }
}

impl From&lt;&amp;Value&gt; for String {
     fn from(v: &amp;Value) -&gt; Self {
         match v {
             Value::ShortStr(len, buf) =&gt; String::from_utf8_lossy(&amp;buf[..*len as usize]).to_string(),
             Value::MidStr(s) =&gt; String::from_utf8_lossy(&amp;s.1[..s.0 as usize]).to_string(),
             Value::LongStr(s) =&gt; s.as_ref().clone(),
             _ =&gt; panic!(&quot;invalid string Value&quot;),
         }
     }
}</code></pre>
<p>The function names of the two conversion calls here are different, <code>std::str::from_utf8()</code> and <code>String::from_utf8_lossy()</code>. The former does not take <code>_lossy</code> and the latter does. The reason lies in UTF-8, etc., which will be explained in detail when <a href="./ch03-04.unicode_utf8.html">UTF8</a> is introduced later.</p>
<p>In addition, this reverse conversion may fail, such as converting a string <code>Value</code> type to an integer type. But this involves error handling, and we will make modifications after sorting out the error handling in a unified manner. Here still use <code>panic!()</code> to handle possible failures.</p>
<blockquote>
<p>After supporting <a href="./ch09-06.environment.html">Environment</a>, the global variable table will be re-implemented with Lua table type and Upvalue, then the index will be directly of <code>Value</code> type, and the conversion here is no need any more.</p>
</blockquote>
<p>In the code executed by the virtual machine, when reading and writing the global variable table, the conversion of the <code>Value</code> type to a string is completed through <code>into()</code> twice:</p>
<pre><code class="language-rust  ignore">                ByteCode::GetGlobal(dst, name) =&gt; {
                    let name: &amp;str = (&amp;proto.constants[name as usize]).into();
                    let v = self.globals.get(name).unwrap_or(&amp;Value::Nil).clone();
                    self.set_stack(dst.into(), v);
                }
                ByteCode::SetGlobal(name, src) =&gt; {
                    let name = &amp;proto.constants[name as usize];
                    let value = self.stack[src as usize].clone();
                    self.globals.insert(name.into(), value);
                }</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="input-type"><a class="header" href="#input-type">Input Type</a></h1>
<p>In the previous section we defined a function with generics. In fact, we &quot;use&quot; more generic types than &quot;define&quot;. This chapter discusses another &quot;use&quot; example, which is the input type of the entire interpreter, that is, the lexical analysis module reads the source code.</p>
<p>Currently only reading source code from files is supported, and Rust's file type <code>std::fs::File</code> does not even include standard input. The lexical analysis data structure Lex is defined as follows:</p>
<pre><code class="language-rust  ignore">pub struct Lex {
     input: File,
     // omit other members</code></pre>
<p>The method <code>read_char()</code> for reading characters is defined as follows:</p>
<pre><code class="language-rust  ignore">impl Lex {
     fn read_char(&amp;mut self) -&gt; char {
         let mut buf: [u8; 1] = [0];
         self.input.read(&amp;mut buf).unwrap();
         buf[0] as char
     }</code></pre>
<p>Here we only focus on the <code>self.input.read()</code> call.</p>
<h2 id="use-read"><a class="header" href="#use-read">Use <code>Read</code></a></h2>
<p>The official implementation of Lua supports two types of input files (including standard input) and strings as source code. According to the idea of Rust generics, the input we want to support may not be limited to <em>some specific types</em>, but <em>a type that supports certain features (ie traits)</em>. In other words, as long as it is a character stream, you can read characters one by one. This feature is so common that the <a href="https://doc.rust-lang.org/std/io/trait.Read.html"><code>std::io::Read</code> trait</a> is provided in the Rust standard library. So modify the definition of Lex as follows:</p>
<pre><code class="language-rust  ignore">pub struct Lex&lt;R&gt; {
     input: R,</code></pre>
<p>There are two changes here:</p>
<ul>
<li>Changed the original <code>Lex</code> to <code>Lex&lt;R&gt;</code>, indicating that Lex is based on the generic type <code>R</code>,</li>
<li>Change the original field input type <code>File</code> to <code>R</code>.</li>
</ul>
<p>Correspondingly, the implementation part should also be changed:</p>
<pre><code class="language-rust  ignore">impl&lt;R: Read&gt; Lex&lt;R&gt; {</code></pre>
<p>Added <code>&lt;R: Read&gt;</code>, indicating that the constraint of <code>&lt;R&gt;</code> is <code>Read</code>, that is, the type R must support the <code>Read</code> trait. This is because the <code>input.read()</code> function is used in the <code>read_char()</code> method.</p>
<p>The <code>read_char()</code> method itself does not need to be modified, and the <code>input.read()</code> function can still be used normally, but its meaning has changed slightly:</p>
<ul>
<li>When the input used the <code>File</code> type before, the <code>read()</code> function called was a method of the <code>File</code> type that implemented the <code>Read</code> trait;</li>
<li>The <code>read()</code> function is now called on all types that implement the <code>Read</code> trait.</li>
</ul>
<p>The statement here is rather convoluted, so you can ignore it if you don’t understand it.</p>
<p>In addition, generic definitions must be added to other places where Lex is used. For example, the definition of ParseProto is modified as follows:</p>
<pre><code class="language-rust  ignore">pub struct ParseProto&lt;R&gt; {
     lex: Lex&lt;R&gt;,</code></pre>
<p>The parameter of its <code>load()</code> method is also changed from <code>File</code> to <code>R</code>:</p>
<pre><code class="language-rust  ignore">     pub fn load(input: R) -&gt; Self {</code></pre>
<p><code>load()</code> supports <code>R</code> just to create <code>Lex&lt;R&gt;</code>, and <code>ParseProto</code> does not use <code>R</code> directly. But <code>&lt;R&gt;</code> still needs to be added to the definition of <code>ParseProto</code>, which is a bit long-winded. What's more verbose is that if there are other types that need to include <code>ParseProto</code>, then <code>&lt;R&gt;</code> should also be added. This is called generic type propagate. This problem can be circumvented by defining <code>dyn</code>, which will also bring some additional performance overhead. However, here <code>ParseProto</code> is an internal type and will not be exposed to other types, so <code>&lt;R&gt;</code> in <code>Lex</code> is equivalent to only spreading one layer, which is acceptable, and <code>dyn</code> will not be adopted.</p>
<p>Now that <code>Read</code> is supported, types other than files can be used. Next look at using stdin like and string types.</p>
<h2 id="use-standard-input"><a class="header" href="#use-standard-input">Use Standard Input</a></h2>
<p>The standard input <a href="https://doc.rust-lang.org/std/io/struct.Stdin.html"><code>std::io::Stdin</code> type</a> implements the <code>Read</code> trait, so it can be used directly. Modify the <code>main()</code> function to use standard input:</p>
<pre><code class="language-rust  ignore">fn main() {
     let input = std::io::stdin(); // standard input
     let proto = parse::ParseProto::load(input);
     vm::ExeState::new().execute(&amp;proto);
}</code></pre>
<p>Test source code from standard input:</p>
<pre><code class="language-bash">echo 'print &quot;i am from stdin!&quot;' | cargo r
</code></pre>
<h2 id="use-string-1"><a class="header" href="#use-string-1">Use String</a></h2>
<p>The string type does not directly support the <code>Read</code> trait, because the string type itself does not have the function of recording the read position. <code>Read</code> can be realized by encapsulating <a href="https://doc.rust-lang.org/std/io/struct.Cursor.html"><code>std::io::Cursor</code> type</a>, which is used to   encapsulates <code>AsRef&lt;[u8]&gt;</code> to support recording position. Its <a href="https://doc.rust-lang.org/src/std/io/cursor.rs.html#74-77">definition</a> is clear:</p>
<pre><code class="language-rust  ignore">pub struct Cursor&lt;T&gt; {
     inner: T,
     pos: u64,
}</code></pre>
<p>This type naturally implements the <code>Read</code> trait. Modify the <code>main()</code> function to use strings as source code input:</p>
<pre><code class="language-rust  ignore">fn main() {
     let input = std::io::Cursor::new(&quot;print \&quot;i am from string!\&quot;&quot;); // string+Cursor
     let proto = parse::ParseProto::load(input);
     vm::ExeState::new().execute(&amp;proto);
}</code></pre>
<h2 id="use-bufreader"><a class="header" href="#use-bufreader">Use BufReader</a></h2>
<p>Reading and writing files directly is a performance-intensive operation. The above implementation only reads one byte at a time, which is very inefficient for file types. This frequent and small amount of file reading operation requires a layer of cache outside. The <a href="https://doc.rust-lang.org/std/io/struct.BufReader.html"><code>std::io::BufReader</code> type</a> in the Rust standard library provides this functionality. This type naturally also implements the <code>Read</code> trait, and also implements the <code>BufRead</code> trait using the cache, providing more methods.</p>
<p>I originally defined Lex's input field as <code>BufReader&lt;R&gt;</code> type, instead of <code>R</code> type above. But later it was found to be wrong, because when <code>BufReader</code> reads data, it first reads from the source to the internal cache, and then returns. Although it is very practical for file types, while the internal cache is unnecessary for string types, and there is one more unnecessary memory copy. And also found that the standard input <code>std::io::Stdin</code> also has its own cache already, so no need to add another layer. Therefore, <code>BufReader</code> is not used inside Lex, but let the caller add it according to the needs (for example, for <code>File</code> type).</p>
<p>Let’s modify the <code>main()</code> function to encapsulate <code>BufReader</code> outside the original <code>File</code> type:</p>
<pre><code class="language-rust  ignore">fn main() {
     // omit parameter handling
     let file = File::open(&amp;args[1]).unwrap();

     let input = BufReader::new(file); // encapsulate BufReader
     let proto = parse::ParseProto::load(input);
     vm::ExeState::new().execute(&amp;proto);
}</code></pre>
<h2 id="give-up-seek"><a class="header" href="#give-up-seek">Give Up <code>Seek</code></a></h2>
<p>At the beginning of this section, we only require that the input type supports character-by-character reading. In fact, it is not true, we also require that the read position can be modified, that is, the <code>Seek</code> trait. This is what the original <code>putback_char()</code> method requires, using the <code>input.seek()</code> method:</p>
<pre><code class="language-rust  ignore">     fn putback_char(&amp;mut self) {
         self.input.seek(SeekFrom::Current(-1)).unwrap();
     }</code></pre>
<p>The application scenario of this function is that in lexical analysis, sometimes it is necessary to judge the type of the current character according to the next character. For example, after reading the character <code>-</code>, if the next character is still <code>-</code>, it is a comment; otherwise it is Subtraction, at this time the next character will be put back into the input source as the next Token. <a href="./ch02-03.assignment.html">Previously</a> introduced that the same is true for reading Token in syntax analysis, and the current statement type must be judged according to the next Token. At that time, the <code>peek()</code> function was added to Lex, which could &quot;peek&quot; at the next Token without consuming it. The <code>peek()</code> here and the <code>putback_char()</code> above are two ways to deal with this situation. The pseudo codes are as follows:</p>
<pre><code>// Method 1: peek()
if input.peek() == xxx then
     input.next() // Consume the peek just now
     handle(xxx)
end

// Method 2: put_back()
if input.next() == xxx then
     handle(xxx)
else
     input.put_back() // plug it back and read it next time
end
</code></pre>
<p>When using the <code>File</code> type before, because the <code>seek()</code> function is supported, it is easy to support the <code>put_back</code> function later, so the second method is adopted. But now the input has been changed to <code>Read</code> type, if <code>input.seek()</code> is still used, then the input is also required to have <code>std::io::Seek</code> trait constraints. Among the three types we have tested above, the cached file <code>BufReader&lt;File&gt;</code> and the string <code>Cursor&lt;String&gt;</code> both support <code>Seek</code>, but the standard input <code>std::io::Stdin</code> does not support it, and there may be other input types that support <code>Read</code> but not <code>Seek</code> (such as <code>std::net::TcpStream</code>). If we add <code>Seek</code> constraints here, the road will be narrowed.</p>
<p>Since <code>Seek</code> cannot be used, there is no need to use the second method. You can also consider the first method, which is at least consistent with Token's <code>peek()</code> function.</p>
<p>The more straightforward approach is to add an <code>ahead_char: char</code> field in Lex to save the character peeked to, similar to the <code>peek()</code> function and the corresponding <code>ahead: Token</code> field. It's simpler to do this, but there's a more general way of doing it in the Rust standard library, using <code>Peekable</code>. Before introducing Peekable, let's look at the <code>Bytes</code> type it depends on.</p>
<h2 id="use-bytes"><a class="header" href="#use-bytes">Use Bytes</a></h2>
<p>The implementation of the <code>read_char()</code> function listed at the beginning of this section is a bit complicated relative to its purpose (reading a character). I later discovered a more abstract method, the <code>bytes()</code> method of the <code>Read</code> triat, which returns an iterator <code>Bytes</code>, and each call to <code>next()</code> returns a byte. Modify the Lex definition as follows:</p>
<pre><code class="language-rust  ignore">pub struct Lex&lt;R&gt; {
     input: Bytes::&lt;R&gt;,</code></pre>
<p>Modify the constructor and <code>read_char()</code> function accordingly.</p>
<pre><code class="language-rust  ignore">impl&lt;R: Read&gt; Lex&lt;R&gt; {
     pub fn new(input: R) -&gt; Self {Lex {
             input: input.bytes(), // generate iterator Bytes
             ahead: Token::Eos,
         }
     }
     fn read_char(&amp;mut self) -&gt; char {
         match self.input.next() { // just call next(), simpler
             Some(Ok(ch)) =&gt; ch as char,
             Some(_) =&gt; panic!(&quot;lex read error&quot;),
             None =&gt; '\0',
         }
     }</code></pre>
<p>The code for <code>read_char()</code> does not seem to be reduced here. But its main body is just <code>input.next()</code> call, and the rest is the processing of the return value. After the error handling is added later, these judgment processing will be more useful.</p>
<h2 id="use-peekable"><a class="header" href="#use-peekable">Use <code>Peekable</code></a></h2>
<p>The <code>peekable()</code> method in the <code>Bytes</code> document, which returns the <code>Peekable</code> type, is exactly what we need. It based on the iterator, and we can &quot;peek&quot; a piece of data forward. Its <a href="https://doc.rust-lang.org/src/core/iter/adapters/peekable.rs.html#15-19">definition</a> is clear:</p>
<pre><code class="language-rust  ignore">pub struct Peekable&lt;I: Iterator&gt; {
     iter: I,
     /// Remember a peeked value, even if it was None.
     peeked: Option&lt;Option&lt;I::Item&gt;&gt;,
}</code></pre>
<p>To this end, modify the definition of Lex as follows:</p>
<pre><code class="language-rust  ignore">pub struct Lex&lt;R&gt; {
     input: Peekable::&lt;Bytes::&lt;R&gt;&gt;,</code></pre>
<p>Modify the constructor accordingly, and add the <code>peek_char()</code> function:</p>
<pre><code class="language-rust  ignore">impl&lt;R: Read&gt; Lex&lt;R&gt; {
     pub fn new(input: R) -&gt; Self {
         Lex {
             input: input.bytes().peekable(), // generate iterator Bytes
             ahead: Token::Eos,
         }
     }
     fn peek_char(&amp;mut self) -&gt; char {
         match self. input. peek() {
             Some(Ok(ch)) =&gt; *ch as char,
             Some(_) =&gt; panic!(&quot;lex peek error&quot;),
             None =&gt; '\0',
         }
     }</code></pre>
<p>Here <code>input.peek()</code> is basically the same as <code>input.next()</code> above, the difference is that the return type is a reference. This is the same as the reason why the <code>Lex::peek()</code> function returns <code>&amp;Token</code>, because the owner of the returned value is still input, and it does not move out, but just &quot;peek&quot;. But here we are of <code>char</code> type, which is Copy, so directly dereference <code>*ch</code>, and finally return char type.</p>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>So far, we have completed the optimization of the input type. From the beginning, only the <code>File</code> type is supported, and finally the <code>Read</code> trait is supported. There is not much content to sort out, but in the process of realization and exploration at the beginning, it took a lot of effort to bump into things. In this process, I also thoroughly figured out some basic types in the standard library, such as <code>Read</code>, <code>BufRead</code>, <code>BufReader</code>, also discovered and learned the <code>Cursor</code> and <code>Peekable</code> types, and also learned more about the official website documents way of organization. Learning the Rust language by doing is the ultimate goal of this project.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unicode-and-utf-8"><a class="header" href="#unicode-and-utf-8">Unicode and UTF-8</a></h1>
<p>The previous sections of this chapter refine the string-related content, clarifying some issues, but also introducing some confusion. For example, the definitions of the three string types in <code>Value</code>, some are of <code>[u8]</code> type, some are of <code>String</code> type:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     ShortStr(u8, [u8; SHORT_STR_MAX]), // [u8] type
     MidStr(Rc&lt;(u8, [u8; MID_STR_MAX])&gt;), // [u8] type
     LongStr(Rc&lt;String&gt;), // String type</code></pre>
<p>Another example is the mixed use of &quot;byte&quot; and &quot;character&quot; in the previous section. The same is true for the lexical analysis code, which reads bytes of type <code>u8</code> from the input character stream, but converts them to characters of type <code>char</code> via <code>as</code>.</p>
<pre><code class="language-rust  ignore">     fn read_char(&amp;mut self) -&gt; char {
         match self. input. next() {
             Some(Ok(ch)) =&gt; ch as char, // u8 -&gt; char</code></pre>
<p>The reason these confusions haven't caused problems so far is because our test programs only involve ASCII characters. Problems arise if other characters are involved. For example, for the following Lua code:</p>
<pre><code class="language-lua">print &quot;你好&quot;
</code></pre>
<p>The execution result is wrong:</p>
<pre><code class="language-bash">$ cargo r -q --  test_lua/nihao.lua
constants: [print, ä½ å¥½]
byte_codes:
  GetGlobal(0, 0)
  LoadConst(1, 1)
  Call(0, 1)
ä½ å¥½
</code></pre>
<p>The output is not the expected <code>你好</code>, but <code>ä½ å¥½</code>. Let's explain the reason for this &quot;garbled code&quot; and fix this problem.</p>
<h2 id="unicode-and-utf-8-concepts"><a class="header" href="#unicode-and-utf-8-concepts">Unicode and UTF-8 Concepts</a></h2>
<p>These two are very general concepts, and only the most basic introduction is given here.</p>
<p>Unicode uniformly encodes most of the characters in the world. Among them, in order to be compatible with the ASCII code, the encoding of the ASCII character set is consistent. For example, the ASCII and Unicode encodings of the English letter <code>p</code> are both 0x70, and <code>U+0070</code> is written in Unicode. The Unicode encoding of Chinese <code>你</code> is <code>U+4F60</code>.</p>
<p>Unicode just numbers the character, while how the computer stores it is another matter. The easiest way is to store directly according to the Unicode encoding. Since Unicode currently supports more than 140,000 characters (still increasing), it needs at least 3 bytes to represent, so the English letter <code>p</code> is <code>00 00 70</code>, and the Chinese <code>你</code> is <code>00 4F 60</code> . The problem with this method is that 3 bytes are required for the ASCII part, which (for English) is wasteful. So there are other encoding methods, UTF-8 is one of them. UTF-8 is a variable-length encoding. For example, each ASCII character only occupies 1 byte. Here the encoding of the English letter <code>p</code> is still 0x70, and it is written as <code>\x70</code> according to UTF-8; while each Chinese character occupies 3 bytes, for example, the UTF-8 encoding of Chinese <code>你</code> is <code>\xE4\xBD\xA0</code>. The more detailed encoding rules of UTF-8 are omitted here. Here are a few examples:</p>
<pre><code>char | Unicode | UTF-8
-----+---------+---------------
p    |  U+0070 | \x70
r    |  U+0072 | \x72
你   |  U+4F60 | \xE4\xBD\xA0
好   |  U+597D | \xE5\xA5\xBD
</code></pre>
<h2 id="garbled-code"><a class="header" href="#garbled-code">Garbled Code</a></h2>
<p>After introducing the coding concepts, let’s analyze the reasons for the garbled characters in the Lua test code at the beginning of this section. Use hexdump to view source code files:</p>
<pre><code class="language-bash">$ hexdump -C test_lua/nihao.lua
00000000  70 72 69 6e 74 20 22 e4  bd a0 e5 a5 bd 22 0a     |print &quot;......&quot;.|
#         p  r  i  n  t     &quot;  |--你---| |--好---| &quot;
</code></pre>
<p>The last line is the comment I added, indicating each Unicode text. You can see that the encoding of <code>p</code> and <code>你</code> is consistent with the UTF-8 encoding introduced above. Indicates that this file is UTF-8 encoded. How the file is encoded depends on the text editor and operating system used.</p>
<p>Our current lexical analysis reads &quot;bytes&quot; one by one, so for the Chinese <code>你</code>, it is considered by the lexical analysis to be 3 independent bytes, namely <code>e4</code>, <code>bd</code> and <code>a0</code>. Then use <code>as</code> to convert to <code>char</code>. Rust's <code>char</code> is Unicode encoded, so we get 3 Unicode characters. By querying Unicode, we can get these 3 characters are <code>ä</code>, <code>½</code> and <code> </code> (the last one is a blank character), which is the first half of the &quot;garbled characters&quot; we encountered at the beginning. The following <code>好</code> corresponds to the second half of the garbled characters. The 6 characters represented by these 6 bytes are sequentially pushed into <code>Token::String</code> (Rust <code>String</code> type), and finally printed out by <code>println!</code>. Rust's <code>String</code> type is UTF-8 encoded, but this does not affect the output.</p>
<p>Summarize the process of garbled characters:</p>
<ul>
<li>The source file is UTF-8 encoded;</li>
<li>Read byte by byte, at this time UTF-8 encoding has been fragmented;</li>
<li>Each byte is interpreted as Unicode, resulting in garbled characters;</li>
<li>Storage and printing.</li>
</ul>
<p>You can also verify it again through Rust coding:</p>
<pre><pre class="playground"><code class="language-rust  editable"><span class="boring">fn main() {
</span>     let s = String::from(&quot;print hello&quot;); // Rust's String is UTF-8 encoded, so it can simulate Lua source files
     println!(&quot;string: {}&quot;, &amp;s); // normal output
     println!(&quot;bytes in UTF-8: {:x?}&quot;, s.as_bytes()); // View UTF-8 encoding

     print!(&quot;Unicode: &quot;);
     for ch in s.chars() { // Read &quot;characters&quot; one by one, check the Unicode encoding
         print!(&quot;{:x} &quot;, ch as u32);
     }
     println!(&quot;&quot;);

     let mut x = String::new();
     for b in s.as_bytes().iter() { // read &quot;bytes&quot; one by one
         x.push(*b as char); // as char, bytes are interpreted as Unicode, resulting in garbled characters
     }
     println!(&quot;wrong: {}&quot;, x);
<span class="boring">}</span></code></pre></pre>
<p>Click on the upper right corner to run and see the result.</p>
<p>The core of the garbled problem lies in the conversion of &quot;byte&quot; to &quot;char&quot;. So there are 2 workarounds:</p>
<ol>
<li>
<p>When reading the source code, modify it to read &quot;char&quot; one by one. This solution has bigger problems:</p>
<ul>
<li>The input type of Lex we introduced in the previous section is <code>Read</code> trait, which only supports reading by &quot;byte&quot;. If you want to read according to the &quot;character char&quot;, you need to convert it to the <code>String</code> type first, and you need the <code>BufRead</code> trait, which has stricter requirements for input, such as <code>Cursor&lt;T&gt;</code> encapsulated outside the string. not support.</li>
<li>If the source code input is UTF-8 encoding, and finally Rust’s storage is also UTF-8 encoding, if it is read according to the Unicode encoding “character char”, then it needs two meaningless steps from UTF-8 to Unicode and then to UTF-8 conversion.</li>
<li>There is another most important reason, which will be discussed soon, Lua strings can contain arbitrary data, not necessarily legal UTF-8 content, and may not be correctly converted to &quot;character char&quot; .</li>
</ul>
</li>
<li>
<p>When reading the source code, still read byte by byte; when saving, it is no longer converted to &quot;character char&quot;, but directly saved according to &quot;byte&quot;. This makes it impossible to continue to use Rust's <code>String</code> type to save, the specific solution is shown below.</p>
</li>
</ol>
<p>It is obvious (it just seems obvious now. I was confused at the beginning, and tried for a long time) should choose the second option.</p>
<h2 id="string-definition-1"><a class="header" href="#string-definition-1">String Definition</a></h2>
<p>Now let's see the difference between the contents of strings in Lua and Rust languages.</p>
<p><a href="https://www.lua.org/manual/5.4/manual.html#3.1">Lua introduction</a> to strings: We can specify any byte in a short literal string. In other words, Lua strings can represent arbitrary data. Rather than calling it a string, it is better to say that it is a series of continuous data, and does not care about the content of the data.</p>
<p>And the <a href="https://doc.rust-lang.org/std/string/struct.String.html">introduction</a> of the Rust string <code>String</code> type: A UTF-8–encoded, growable string. Easy to understand. Two features: UTF-8 encoding, and growable. Lua's strings are immutable, Rust's are growable, but this distinction is beyond the scope of this discussion. Now the focus is on the former feature, which is UTF-8 encoding, which means that Rust strings cannot store arbitrary data. This can be better observed through the definition of Rust's string:</p>
<pre><code class="language-rust  ignore">pub struct String {
     vec: Vec&lt;u8&gt;,
}</code></pre>
<p>You can see that <code>String</code> is the encapsulation of <code>Vec&lt;u8&gt;</code> type. It is through this encapsulation that the data in <code>vec</code> is guaranteed to be legal UTF-8 encoding, and no arbitrary data will be mixed in. If arbitrary data is allowed, just define the alias <code>type String = Vec&lt;u8&gt;;</code> directly.</p>
<p>To sum up, Rust's string <code>String</code> is only a subset of Lua string; the Rust type corresponding to the Lua string type is not <code>String</code>, but <code>Vec&lt;u8&gt;</code> that can store arbitrary data.</p>
<h2 id="modify-the-code"><a class="header" href="#modify-the-code">Modify the Code</a></h2>
<p>Now that we have figured out the cause of the garbled characters and analyzed the difference between Rust and Lua strings, we can start modifying the interpreter code. The places that need to be modified are as follows:</p>
<ul>
<li>
<p>The type associated with <code>Token::String</code> in lexical analysis is changed from <code>String</code> to <code>Vec&lt;u8&gt;</code> to support arbitrary data, not limited to legal UTF-8 encoded data.</p>
</li>
<li>
<p>Correspondingly, the type associated with <code>Value::LongStr</code> is also changed from <code>String</code> to <code>Vec&lt;u8&gt;</code>. This is consistent with the other two string types ShortStr and MidStr.</p>
</li>
<li>
<p>In lexical analysis, the original reading functions <code>peek_char()</code> and <code>read_char()</code> are changed to <code>peek_byte()</code> and <code>next_byte()</code> respectively, and the return type is changed from &quot;char&quot; to &quot;byte&quot;. It turns out that although the name is <code>char</code>, it actually reads &quot;bytes&quot; one by one, so there is no need to modify the function content this time.</p>
</li>
<li>
<p>In the code, the original matching character constant such as <code>'a'</code> should be changed to a byte constant such as <code>b'a'</code>.</p>
</li>
<li>
<p>If the original <code>read_char()</code> reads to the end, it will return <code>\0</code>, because <code>\0</code> is considered to be a special character at that time. Now Lua's string can contain any value, including <code>\0</code>, so <code>\0</code> cannot be used to indicate the end of reading. At this point, Rust's <code>Option</code> is needed, and the return value type is defined as <code>Option&lt;u8&gt;</code>.</p>
<p>But this makes it inconvenient to call this function, requiring pattern matching (<code>if let Some(b) =</code>) every time to get out the bytes. Fortunately, there are not many places where this function is called. But another function <code>peek_byte()</code> is called in many places. It stands to reason that the return value of this function should also be changed to <code>Option&lt;u8&gt;</code>, but in fact the bytes returned by this function are used to &quot;look at it&quot;, as long as it does not match several possible paths, it can be regarded as No effect. So when this function reads to the end, it can still return <code>\0</code>, because <code>\0</code> will not match any possible path. If you really read to the end, then just leave it to the next <code>next_byte()</code> to process.</p>
<blockquote>
<p>It is the inconvenience brought by <code>Option</code> (it must be matched to get the value) that withdraws its value. In my C language programming experience, the handling of this special case of function return is generallyIt is represented by a special value, such as <code>NULL</code> for the pointer type, and <code>0</code> or <code>-1</code> for the int type. This brings two problems: one is that the caller may not handle this special value, which will directly lead to bugs; the other is that these special values may later become ordinary values (for example, our <code>\0</code> this time is a typical example), then all places that call this function must be modified. Rust's <code>Option</code> perfectly solves these two problems.</p>
</blockquote>
</li>
<li>
<p>In lexical analysis, strings support escape. This part is all boring character processing, and the introduction is omitted here.</p>
</li>
<li>
<p>Add <code>impl From&lt;Vec&lt;u8&gt;&gt; for Value</code> to convert the string constant in <code>Token::String(Vec&lt;u8&gt;)</code> to <code>Value</code> type. This also involves a lot of details of Vec and strings, which is very cumbersome and has little to do with the main line. The following two sections will be devoted to it.</p>
</li>
</ul>
<h2 id="conversion-from-str-string-u8-vec-to-value"><a class="header" href="#conversion-from-str-string-u8-vec-to-value">Conversion from &amp;str, String, &amp;[u8], Vec<u8> to Value</a></h2>
<p>The conversion of <code>String</code> and <code>&amp;str</code> to <code>Value</code> has been implemented before. Now add <code>Vec&lt;u8&gt;</code> and <code>&amp;[u8]</code> to <code>Value</code> conversion. The relationship between these 4 types is as follows:</p>
<pre><code>            slice
   &amp;[u8] &lt;---------&gt; Vec&lt;u8&gt;
                       ^
                       |encapsulate
            slice      |
   &amp;str &lt;---------&gt; String
</code></pre>
<ul>
<li><code>String</code> is an encapsulation of <code>Vec&lt;u8&gt;</code>. The encapsulated <code>Vec&lt;u8&gt;</code> can be returned by <code>into_bytes()</code>.</li>
<li><code>&amp;str</code> is a slice of <code>String</code> (can be considered a reference?).</li>
<li><code>&amp;[u8]</code> is a slice of <code>Vec&lt;u8&gt;</code>.</li>
</ul>
<p>So <code>String</code> and <code>&amp;str</code> can depend on <code>Vec&lt;u8&gt;</code> and <code>&amp;[u8]</code> respectively. And it seems that <code>Vec&lt;u8&gt;</code> and <code>&amp;[u8]</code> can also depend on each other, that is, only one of them can be directly converted to <code>Value</code>. However, this will lose performance. analyse as below:</p>
<ul>
<li>Source type: <code>Vec&lt;u8&gt;</code> is owned, while <code>&amp;[u8]</code> is not.</li>
<li>Destination type: <code>Value::ShortStr/MidStr</code> only needs to copy the string content (into Value and Rc respectively), without taking ownership of the source data. And <code>Value::LongStr</code> needs to take ownership of <code>Vec</code>.</li>
</ul>
<p>2 source types, 2 destination types, 4 conversion combinations are available:</p>
<pre><code>          | Value::ShortStr/MidStr  | Value::LongStr
----------+-------------------------+-----------------------
  &amp;[u8]   | 1. Copy string content  | 2. Create a Vec and allocate memory
  Vec&lt;u8&gt; | 3. Copy string content  | 4. Transfer ownership
</code></pre>
<p>If we directly implement <code>Vec&lt;u8&gt;</code>, and for <code>&amp;[8]</code>, first create <code>Vec&lt;u8&gt;</code> through <code>.to_vec()</code> and then indirectly convert it to <code>Value</code>. So for the first case above, only the content of the string needs to be copied, and the Vec created by <code>.to_vec()</code> is wasted.</p>
<p>If we directly implement <code>&amp;[8]</code>, and for <code>Vec&lt;u8&gt;</code>, it is first converted to <code>&amp;[u8]</code> by reference and then indirectly converted to <code>Value</code>. Then for the fourth case above, it is necessary to convert the reference to <code>&amp;u[8]</code> first, and then create a Vec through <code>.to_vec()</code> to obtain ownership. One more unnecessary creation.</p>
<p>So for the sake of efficiency, it is better to directly implement the conversion of <code>Vec&lt;u8&gt;</code> and <code>&amp;[u8]</code> to <code>Value</code>. However, maybe the compiler will optimize these, and the above considerations are nothing to worry about. However, this can help us understand the two types <code>Vec&lt;u8&gt;</code> and <code>&amp;[u8]</code> more deeply, and the concept of ownership in Rust. The final conversion code is as follows:</p>
<pre><code class="language-rust  ignore">// convert &amp;[u8], Vec&lt;u8&gt;, &amp;str and String into Value
impl From&lt;&amp;[u8]&gt; for Value {
    fn from(v: &amp;[u8]) -&gt; Self {
        vec_to_short_mid_str(v).unwrap_or(Value::LongStr(Rc::new(v.to_vec())))
    }
}
impl From&lt;&amp;str&gt; for Value {
    fn from(s: &amp;str) -&gt; Self {
        s.as_bytes().into() // &amp;[u8]
    }
}

impl From&lt;Vec&lt;u8&gt;&gt; for Value {
    fn from(v: Vec&lt;u8&gt;) -&gt; Self {
        vec_to_short_mid_str(&amp;v).unwrap_or(Value::LongStr(Rc::new(v)))
    }
}
impl From&lt;String&gt; for Value {
    fn from(s: String) -&gt; Self {
        s.into_bytes().into() // Vec&lt;u8&gt;
    }
}

fn vec_to_short_mid_str(v: &amp;[u8]) -&gt; Option&lt;Value&gt; {
    let len = v.len();
    if len &lt;= SHORT_STR_MAX {
        let mut buf = [0; SHORT_STR_MAX];
        buf[..len].copy_from_slice(&amp;v);
        Some(Value::ShortStr(len as u8, buf))

    } else if len &lt;= MID_STR_MAX {
        let mut buf = [0; MID_STR_MAX];
        buf[..len].copy_from_slice(&amp;v);
        Some(Value::MidStr(Rc::new((len as u8, buf))))

    } else {
        None
    }
}</code></pre>
<h2 id="reverse-conversion-1"><a class="header" href="#reverse-conversion-1">Reverse Conversion</a></h2>
<p>The conversion from <code>Value</code> to <code>String</code> and <code>&amp;str</code> has been implemented before. Now to add the conversion to <code>Vec&lt;u8&gt;</code>. First list the code:</p>
<pre><code class="language-rust  ignore">impl&lt;'a&gt; From&lt;&amp;'a Value&gt; for &amp;'a [u8] {
    fn from(v: &amp;'a Value) -&gt; Self {
        match v {
            Value::ShortStr(len, buf) =&gt; &amp;buf[..*len as usize],
            Value::MidStr(s) =&gt; &amp;s.1[..s.0 as usize],
            Value::LongStr(s) =&gt; s,
            _ =&gt; panic!(&quot;invalid string Value&quot;),
        }
    }
}

impl&lt;'a&gt; From&lt;&amp;'a Value&gt; for &amp;'a str {
    fn from(v: &amp;'a Value) -&gt; Self {
        std::str::from_utf8(v.into()).unwrap()
    }
}

impl From&lt;&amp;Value&gt; for String {
    fn from(v: &amp;Value) -&gt; Self {
        String::from_utf8_lossy(v.into()).to_string()
    }
}</code></pre>
<ul>
<li>
<p>Since the three strings of <code>Value</code> are all consecutive <code>u8</code> sequences, it is easy to convert to <code>&amp;[u8]</code>.</p>
</li>
<li>
<p>The conversion to <code>&amp;str</code> needs to be processed by <code>std::str::from_utf8()</code> to handle the <code>&amp;[u8]</code> type just obtained. This function does not involve new memory allocation, but only verifies the validity of the UTF-8 encoding. If it is illegal, it will fail, and here we panic directly through <code>unwrap()</code>.</p>
</li>
<li>
<p>Conversion to <code>String</code>, through <code>String::from_utf8_lossy()</code> to process the <code>&amp;[u8]</code> type just obtained. This function also verifies the legality of UTF-8 encoding, but if the verification fails, a special character <code>u+FFFD</code> will be used to replace the illegal data. But the original data cannot be modified directly, so a new string will be created. If the verification is successful, there is no need to create new data, just return the index of the original data. The return type <code>Cow</code> of this function is also worth learning.</p>
</li>
</ul>
<p>The different processing methods of the above two functions are because <code>&amp;str</code> has no ownership, so new data cannot be created, but an error can only be reported. It can be seen that ownership is very critical in the Rust language.</p>
<p>The conversion from <code>Value</code> to <code>String</code>, the current requirement is only used when the global variable table needs to be set. You can see that this conversion always calls <code>.to_string()</code> to create a new string. This makes the optimization of strings in our chapter (mainly <a href="./ch03-01.string_type.html">Section 1</a>) meaningless. Later, after introducing the Lua table structure, the index type of the global variable table will be changed from <code>String</code> to <code>Value</code>, and then the operation of the global variable table will not need this conversion. However, this conversion is still used in other places.</p>
<h2 id="test-4"><a class="header" href="#test-4">Test</a></h2>
<p>So far, the function of Lua string is more complete. The test code at the beginning of this section can also be output normally. More methods can be handled by escape, and verified with the following test code:</p>
<pre><code class="language-lua">print &quot;tab:\thi&quot; -- tab
print &quot;\xE4\xBD\xA0\xE5\xA5\xBD&quot; -- 你好
print &quot;\xE4\xBD&quot; -- invalid UTF-8
print &quot;\72\101\108\108\111&quot; -- Hello
print &quot;null: \0.&quot; -- '\0'
</code></pre>
<h2 id="summarize"><a class="header" href="#summarize">Summarize</a></h2>
<p>This chapter has learned the Rust string type, which involves ownership, memory allocation, Unicode and UTF-8 encoding, etc., and deeply understands what is said in &quot;Rust Programming Language&quot;: Rust strings are complex because the string itself is complex of. Through these learnings, Lua's string type is optimized, and generics and <code>From</code> traits are also involved. Although it did not add new features to our Lua interpreter, it also gained a lot.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="garbage-collection-and-rc"><a class="header" href="#garbage-collection-and-rc">Garbage Collection and Rc</a></h1>
<p>In the above section <a href="./ch03-01.string_type.html">String Definition</a>, we used <code>Rc</code> to define the string type in Lua, which involves an important topic: garbage collection(GC). Garbage collection is a very general and in-depth topic. Here we only introduce the parts related to our interpreter implementation.</p>
<h2 id="gc-vs-rc"><a class="header" href="#gc-vs-rc">GC vs RC</a></h2>
<p>The Lua language manages memory automatically, meaning it releases unused memory automatically through garbage collection. There are two main ways to implement garbage collection: mark-and-sweep and reference counting (RC). Sometimes RC is not considered GC, so the narrow GC refers to the former, that is, the mark-clear scheme. The GC mentioned below in this section is its narrow meaning.</p>
<p>In comparison, RC has two disadvantages:</p>
<ul>
<li>
<p>It is impossible to judge circular references, which can lead to memory leaks. This is fatal. In fact, <a href="https://doc.rust-lang.org/stable/book/ch15-06-reference-cycles.html"><code>Rc</code> in Rust also has this problem</a>. Rust's strategy for this is: it's up to the programmer to avoid circular references.</p>
</li>
<li>
<p>Performance is worse than GC. This is not absolute, but it seems to be the mainstream view. The main reason is that each clone or drop operation needs to update the reference counter, which in turn affects the CPU cache.</p>
</li>
</ul>
<p>Based on the above reasons, the mainstream languages will not adopt the RC scheme, but chose the GC scheme, including the official implementation version of Lua. However, we still chose to use <code>Rc</code> in the definition of strings in this chapter, that is, to adopt the RC scheme, because of two shortcomings of GC:</p>
<ul>
<li>
<p>Implement complex. Although it may be relatively simple to implement a simple GC solution, it is very difficult to pursue performance. Many languages (such as Python, Go, Lua) also continuously improve their GC during versions. It's hard to get there in one step.</p>
</li>
<li>
<p>More complex in Rust. Originally, the biggest feature of the Rust language is automatic memory management. The manual memory management function of the GC scheme is contrary to this feature of Rust, <a href="https://zackoverflow.dev/writing/unsafe-rust-vs-zig/">will make it more complicated</a>. There are many discussions and projects on the Internet about implementing GC with Rust (such as <a href="https://manishearth.github.io/blog/2015/09/01/designing-a-gc-in-rust/">1</a>, <a href="https://crates.io/crates/gc">2</a>, <a href="https://manishearth.github.io/blog/2021/04/05/a-tour-of-safe-tracing-gc-designs-in-rust/">3</a>, <a href="https://coredumped.dev/2022/04/11/implementing-a-safe-garbage-collector-in-rust/">4</a>, etc.), obviously beyond Rust beginners range of capabilities.</p>
</li>
</ul>
<p>In contrast, if you adopt the RC scheme, you only need to use <code>Rc</code> in Rust, and no additional memory management is required. That is, the garbage collection part can be avoided entirely.</p>
<p>Countermeasures for the two shortcomings of the above-mentioned RC scheme: one is circular references, which can only be handed over to Lua programmers to avoid circular references, but in common cases, such as a table setting itself as a metatable, we can handle it specially to avoid memory leaks. The second is performance, and we can only give up the pursuit of this aspect.</p>
<p>It is a difficult decision to adopt the RC scheme to realize garbage collection. Because the goal of this project from the beginning is to fully comply with the Lua manual and be fully compatible with the official implementation version. After adopting the RC scheme, the scenario of circular reference cannot be handled, which destroys this goal. Due to my limited ability, I have to do this for the time being. However, GC solutions may also be tried in the future. Alternative GC schemes have very little impact on the rest of our interpreter. Interested readers can try it out by themselves first.</p>
<h2 id="rc-in-rust"><a class="header" href="#rc-in-rust">Rc in Rust</a></h2>
<p>Ok, now let's leave the topic of garbage collection and discuss <code>Rc</code> in Rust simply.</p>
<p>In many articles introducing Rust, it is mentioned that <code>Rc</code> should be avoided as much as possible, because the unique ownership mechanism of Rust language not only provides automatic memory management at compile time, but also optimizes program design. Other languages that support pointers (such as C, C++) can use pointers to point at will, and each object may be pointed to by many other objects, and the entire program can easily form a chaotic &quot;Object Sea&quot;. However, Rust's ownership mechanism forces Rust programmers to have only one owner for each object when designing a program, and the entire program forms a clear &quot;Object Tree&quot;. In most scenarios, the latter (Object Tree) is obviously a better design. However, <code>Rc</code> breaks this specification, and the whole program becomes a chaotic &quot;Object Sea&quot; again. So try to avoid using <code>Rc</code>.</p>
<p>I agree with this point of view very much. In the process of implementing this Lua interpreter project, in order to follow Rust's ownership mechanism, I had to adjust the previous C language design ideas, and the adjusted results were often indeed clearer.</p>
<p>From a certain point of view, the Lua interpreter project can be divided into two parts:</p>
<ul>
<li>The interpreter itself, mainly lexical analysis and syntax analysis;</li>
<li>The Lua code to be interpreted and executed, including the value, stack, and preset execution flow corresponding to the bytecode, which is the virtual machine part.</li>
</ul>
<p>For the former part, we fully follow the design requirements of Object Tree and strive for a clear program structure. For the latter, since we cannot limit the Lua code written by Lua programmers (for example, Lua code can easily realize the data structure of the graph, which obviously does not conform to Object Tree), so we will not go into this part pursue Object Tree. Even if GC is used to achieve garbage collection, it will inevitably involve a lot of unsafe code, which is more contrary to the design intent of Rust than <code>Rc</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table"><a class="header" href="#table">Table</a></h1>
<p>This chapter implements the only data structure in Lua: the table. The definition, construction, and reading and writing of tables are completed in sequence.</p>
<p>In order to realize the write operation, that is, the assignment of table members, the key data structure <code>ExpDesc</code> is introduced in the syntax analysis stage.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table-definition"><a class="header" href="#table-definition">Table Definition</a></h1>
<p>Lua's table is externally represented as a unified hash table, and its index can be a number, a string, or all other Value types except <code>nil</code> and <code>Nan</code>. However, for performance considerations, there is a special treatment for numeric types, that is, an array is used to store items indexed by consecutive numbers. So in the implementation, the table is actually composed of two parts: an array and a hash table. For this we define the table:</p>
<pre><code class="language-rust  ignore">pub struct Table {
    pub array: Vec&lt;Value&gt;,
    pub map: HashMap&lt;Value, Value&gt;,
}</code></pre>
<p>In order to support the characteristics of the meta table, other fields will be added in the future, which will be ignored here.</p>
<p>The table (and thread, UserData, etc. introduced later) type in the Lua language does not represent the object data itself, but <a href="https://www.lua.org/manual/5.4/manual.html#2.1">just a reference to the object data</a>, all operations on table types are references to operations. For example, the assignment of a table only copies the reference of the table, rather than &quot;deep copying&quot; the data of the entire table. So the table type defined in <code>Value</code> cannot be <code>Table</code>, but must be a reference or a pointer. When the <a href="./ch03-01.string_type.html">string type</a> was defined in the previous chapter, <code>Rc</code> was introduced and references and pointers were discussed. For the same reason, the pointer <code>Rc</code> is also used to encapsulate <code>Table</code> this time. In addition, <code>RefCell</code> needs to be introduced here to provide <a href="https://doc.rust-lang.org/stable/book/ch15-05-interior-mutability.html">internal mutability</a>. In summary, the table type is defined as follows:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     Table(Rc&lt;RefCell&lt;Table&gt;&gt;),</code></pre>
<p>The definition of the hash table part in <code>Table</code> is <code>HashMap&lt;Value, Value&gt;</code>, that is, the type of index and value are <code>Value</code> both. The index type of <a href="https://doc.rust-lang.org/std/collections/struct.HashMap.html"><code>HashMap</code></a> is required to implement the two traits <code>Eq</code> and <code>Hash</code>. This is also easy to understand. The working principle of the hash table is to quickly locate by calculating the hash value (<code>Hash</code>) of the index when inserting and searching, and to handle hash conflicts by comparing the index (<code>Eq</code>). Next, implement these two traits.</p>
<h2 id="eq-trait"><a class="header" href="#eq-trait"><code>Eq</code> trait</a></h2>
<p>We have implemented the <code>PartialEq</code> trait for <code>Value</code> before, which compares whether two Values are equal, or we can use the <code>==</code> operator on the Value type. The requirement of <code>Eq</code> is higher, which requires reflexivity on the basis of <code>PartialEq</code>, that is, it is required to satisfy <code>x==x</code> for any value <code>x</code> of this type. In most cases, it is reflexive, but there are also counterexamples. For example, in floating-point numbers, <code>Nan != Nan</code>, so although the floating-point type implements <code>PartialEq</code>, it does not implement <code>Eq</code>. Although our <code>Value</code> type includes floating-point numbers, since the Lua language prohibits the use of <code>Nan</code> as an index (specifically, we will judge whether the index is Nan when the virtual machine performs a table insertion operation), it can be considered that <code>Value</code> type satisfies reflexivity. For types that satisfy reflexivity, we just tell Rust that it does, no special implementation is required:</p>
<pre><code class="language-rust  ignore">impl Eq for Value {}</code></pre>
<h2 id="hash-trait"><a class="header" href="#hash-trait"><code>Hash</code> trait</a></h2>
<p>Most of the basic types in Rust have already implemented the <code>Hash</code> trait, and we only need to call <code>.hash()</code> for each type according to the semantics.</p>
<p>The code to implement the <code>Hash</code> trait is as follows:</p>
<pre><code class="language-rust  ignore">impl Hash for Value {
    fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) {
        match self {
            Value::Nil =&gt; (),
            Value::Boolean(b) =&gt; b.hash(state),
            Value::Integer(i) =&gt; i.hash(state),
            Value::Float(f) =&gt; // TODO try to convert to integer
                unsafe {
                    mem::transmute::&lt;f64, i64&gt;(*f).hash(state)
                }
            Value::ShortStr(len, buf) =&gt; buf[..*len as usize].hash(state),
            Value::MidStr(s) =&gt; s.1[..s.0 as usize].hash(state),
            Value::LongStr(s) =&gt; s.hash(state),
            Value::Table(t) =&gt; Rc::as_ptr(t).hash(state),
            Value::Function(f) =&gt; (*f as *const usize).hash(state),
        }
    }
}</code></pre>
<p>Many types, such as <code>bool</code>, <code>Rc</code> pointers, etc., have already implemented the hash method, but the floating-point type <code>f64</code> does not. The reason is also because of <code>Nan</code>. Here is a detailed [discussion](https: //internals.rust-lang.org/t/f32-f64-should-implement-hash/5436/2). It has been stated in the <code>Eq</code> trait section that Lua prohibits the use of Nan as an index, we can ignore Nan and the default floating-point type can be hashed. One way is to treat the floating-point number as a piece of memory for hashing. Here we choose to convert to the simpler integer <code>i64</code> for hashing.</p>
<p>This conversion uses the <code>mem::transmute()</code> function of the standard library, and this function is <code>unsafe</code>. We can clearly know that this conversion is safe (really?), so we can use this <code>unsafe</code> with confidence.</p>
<blockquote>
<p>When I first learned the Rust language, I saw that the description of some libraries clearly stated that &quot;unsafe code is not included&quot;, and I felt that this is a very proud feature. So when I started this project, I also hoped not to have any unsafe code. But now it seems that unsafe is not a scourge. It may be similar to <code>goto</code> in C language. As long as it is used reasonably, it can bring great convenience.</p>
</blockquote>
<p>For the string type, the hash needs to be calculated for the string content. For the table type, only the hash of the pointer needs to be calculated, and the contents of the table are ignored. This is because string comparisons are content comparisons, and table comparisons are <a href="https://www.lua.org/manual/5.4/manual.html#3.4.4">comparisons of table references</a>.</p>
<h2 id="debug-and-display-traits"><a class="header" href="#debug-and-display-traits"><code>Debug</code> and <code>Display</code> traits</a></h2>
<p>Because Rust's <a href="https://doc.rust-lang.org/stable/book/ch06-02-match.html#matches-are-exhaustive">matches are exhaustive</a>, so the compiler will remind us to add the Table type in the <code>Debug</code> trait:</p>
<pre><code class="language-rust  ignore">     Value::Table(t) =&gt; {
         let t = t.borrow();
         write!(f, &quot;table:{}:{}&quot;, t.array.len(), t.map.len())
     }</code></pre>
<p>There are 2 lines in the code block. Line 1 uses <code>borrow()</code>, which is a dynamic reference to <code>RefCell</code> type, to ensure that there are no other variable references. This dynamic reference introduces additional runtime overhead relative to most compile-time checks in Rust.</p>
<p>In the official implementation of Lua, the output format of the table type is the address of the table, which can be used for simple debugging. We have increased the length of the array and hash table parts of the table here, which is more convenient for debugging. In addition, we implement the <code>Display</code> trait for Value, which is used for the official output of <code>print</code>:</p>
<pre><code class="language-rust  ignore">impl fmt::Display for Value {
     fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; Result&lt;(), fmt::Error&gt; {
         match self {
             Value::Table(t) =&gt; write!(f, &quot;table: {:?}&quot;, Rc::as_ptr(t)),</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table-construction"><a class="header" href="#table-construction">Table Construction</a></h1>
<p>This section describes the construction of tables. The construction supports 3 types: list type, record type, and general type. See the following sample codes respectively:</p>
<pre><code class="language-lua">local key = &quot;kkk&quot;
print { 100, 200, 300; -- list style
        x=&quot;hello&quot;, y=&quot;world&quot;; -- record style
        [key]=&quot;vvv&quot;; -- general style
}
</code></pre>
<p>Let's first look at how the official implementation of Lua handles the construction of tables. The output of luac is as follows:</p>
<pre><code class="language-shell">$ luac -l test_lua/table.lua

main &lt;test_lua/table.lua:0,0&gt; (14 instructions at 0x600001820080)
0+ params, 6 slots, 1 upvalue, 1 local, 7 constants, 0 functions
    1	[1]	VARARGPREP	0
    2	[1]	LOADK    	0 0	; &quot;kkk&quot;
    3	[2]	GETTABUP 	1 0 1	; _ENV &quot;print&quot;
    4	[2]	NEWTABLE 	2 3 3	; 3
    5	[2]	EXTRAARG 	0
    6	[2]	LOADI    	3 100
    7	[2]	LOADI    	4 200
    8	[2]	LOADI    	5 300
    9	[3]	SETFIELD 	2 2 3k	; &quot;x&quot; &quot;hello&quot;
    10	[3]	SETFIELD 	2 4 5k	; &quot;y&quot; &quot;world&quot;
    11	[4]	SETTABLE 	2 0 6k	; &quot;vvv&quot;
    12	[5]	SETLIST  	2 3 0
    13	[2]	CALL     	1 2 1	; 1 in 0 out
    14	[5]	RETURN   	1 1 1	; 0 out
</code></pre>
<p>The bytecodes related to the construction of the table are lines 4 to 12:</p>
<ul>
<li>Line 4, NEWTABLE, is used to create a table. There are 3 parameters in total, which are the position of the new table on the stack, the length of the array part, and the part length of the hash table.</li>
<li>Line 5, I don't understand it, ignore it for now.</li>
<li>Lines 6, 7, and 8, three LOADIs, respectively load the values 100, 200, and 300 of the array part to the stack for later use.</li>
<li>Lines 9 and 10, bytecode SETFIELD, insert <code>x</code> and <code>y</code> into the hash table part respectively.</li>
<li>Line 11, bytecode SETTABLE, inserts the key into the hash table.</li>
<li>Line 12, SETLIST, loads the data loaded on the stack in lines 6-8 above, and inserts it into the array at one time.</li>
</ul>
<p>The stack situation corresponding to the execution of each bytecode is as follows:</p>
<pre><code>           |       |        /&lt;--- 9.SETFILED
           +-------+        |&lt;---10.SETFILED
4.NEWTABLE |  { }  |&lt;----+--+&lt;---11.SETTABLE
           +-------+     |
   6.LOADI |  100  |----&gt;|
           +-------+     |12.SETLIST
   7.LOADI |  200  |----&gt;|
           +-------+     |
   8.LOADI |  300  |----&gt;/
           +-------+
           |       |
</code></pre>
<p>First of all, it can be seen that the table is constructed in real time by inserting members one by one during the execution of the virtual machine. This is a bit beyond my expectation (although I didn't think about the process before). I have previously written code similar to the following:</p>
<pre><code class="language-lua">local function day_of_week(day)
     local days = {
         &quot;Sunday&quot;=0, &quot;Monday&quot;=1, &quot;Tuesday&quot;=2,
         &quot;Wednesday&quot;=3, &quot;Thursday&quot;=4, &quot;Friday&quot;=5,
         &quot;Saturday&quot;=6,
     }
     return days[day]
end
</code></pre>
<p>It is natural to put <code>days</code> inside the <code>day_of_week()</code> function, because this variable is only used inside this function. However, according to the realization of the above table structure, every time this function is called, the table will be constructed in real time, that is, the 7 dates will be inserted into the table. This cost is a bit high (8 string hashes and 1 string are required In comparison, at least 9 bytecodes are required, and there is more than one memory allocation brought about by creating a table). It feels not even as fast as comparing week by week names (an average of 4 string comparisons are required, and 2 bytecodes are compared for a total of 8). A better way is to put the <code>days</code> variable outside the function (that is <a href="./ch09-01.upvalue.html">UpValue</a> introduced later), and there is no need to construct a table every time you enter the function, but in this way it is not a good programming practice to put variables inside a function outside. Another approach (not supported by Lua's official implementation) is to construct a table composed of all constants in the parsing stage, and then just quote it later, but this will bring some complexity. No energy to finish by now.</p>
<p>Back to the construction of the table, the processing methods for the array part and the hash table part are different:</p>
<ul>
<li>The array part is to first load the values onto the stack in sequence, and finally insert them into the array at one time;</li>
<li>The hash table part is directly inserted into the hash table each time.</li>
</ul>
<p>One is batch and one is sequential. The reasons for the different methods are speculated as follows:</p>
<ul>
<li>
<p>If the array part is also inserted one by one, then inserting certain types of expressions requires 2 bytecodes. For example, for global variables, you need to use <code>GetGlobal</code> bytecode to load it on the stack first, and then use a bytecode similar to <code>AppendTable</code> to insert into the array, then inserting N values requires at most 2N bytecodes . If you insert in batches, only N+1 bytecodes are needed for N values. So bulk insert is better for the array part.</p>
</li>
<li>
<p>As for the hash table part, each piece of data has two values of key and value. If the batch method is also used, 2 bytecodes are required to load both values onto the stack. And if it is inserted one by one, only one bytecode is needed in many cases. For example, the last three items in the above sample code only correspond to one bytecode. In this way, the batch method requires more bytecodes, so inserting one by one is more suitable for the hash table part.</p>
</li>
</ul>
<p>In this section, according to the official Lua implementation method, the following 4 bytecodes are correspondingly added:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     NewTable(u8, u8, u8),
     SetTable(u8, u8, u8), // key is on the stack
     SetField(u8, u8, u8), // key is a string constant
     SetList(u8, u8),</code></pre>
<p>However, the two bytecodes in the middle do not support the case where the value is a constant, only the index on the stack is supported. We'll add optimizations to constants in a later section.</p>
<h2 id="syntax-analysis-3"><a class="header" href="#syntax-analysis-3">Syntax Analysis</a></h2>
<p>After introducing the principle of table construction, let's look at the specific implementation. Look at the syntax analysis section first. The code is very long, but it is just according to the above introduction, the logic is very simple. The code is posted here for reference only, readers who are not interested can skip here.</p>
<pre><code class="language-rust  ignore">fn table_constructor(&amp;mut self, dst: usize) {
     let table = dst as u8;
     let inew = self.byte_codes.len();
     self.byte_codes.push(ByteCode::NewTable(table, 0, 0)); // Create a new table

     let mut narray = 0;
     let mut nmap = 0;
     let mut sp = dst + 1;
     loop {
         match self. lex. peek() {
             Token::CurlyR =&gt; { // `}`
                 self. lex. next();
                 break;
             }
             Token::SqurL =&gt; { // `[` exp `]` `=` exp, general formula
                 nmap += 1;
                 self. lex. next();

                 self.load_exp(sp); // key
                 self.lex.expect(Token::SqurR); // `]`
                 self.lex.expect(Token::Assign); // `=`
                 self. load_exp(sp + 1); // value

                 self.byte_codes.push(ByteCode::SetTable(table, sp as u8, sp as u8 + 1));
             },
             Token::Name(_) =&gt; { // Name `=` exp | Name
                 nmap += 1;
                 let key = if let Token::Name(key) = self. lex. next() {
                     self. add_const(key)
                 };
                 if self.lex.peek() == &amp;Token::Assign { // Name `=` exp, recorded
                     self. lex. next();
                     self. load_exp(sp); // value
                     self.byte_codes.push(ByteCode::SetField(table, key as u8, sp as u8));
                 } else {
                     narray += 1;
                     self.load_exp_with_ahead(sp, Token::Name(key)); // exp, list

                     sp += 1;
                     if sp - (dst + 1) &gt; 50 { // too many, reset it
                         self.byte_codes.push(ByteCode::SetList(table, (sp - (dst + 1)) as u8));
                         sp = dst + 1;
                     }
                 }
             },
             _ =&gt; { // exp, list
                 narray += 1;
                 self. load_exp(sp);

                 sp += 1;
                 if sp - (dst + 1) &gt; 50 { // too many, reset it
                     self.byte_codes.push(ByteCode::SetList(table, (sp - (dst + 1)) as u8));
                     sp = dst + 1;
                 }
             },
         }

         match self. lex. next() {Token::SemiColon | Token::Comma =&gt; (),
             Token::CurlyR =&gt; break,
             t =&gt; panic!(&quot;invalid table {t:?}&quot;),
         }
     }

     if sp &gt; dst + 1 {
         self.byte_codes.push(ByteCode::SetList(table, (sp - (dst + 1)) as u8));
     }

     // reset narray and nmap
     self.byte_codes[inew] = ByteCode::NewTable(table, narray, nmap);
}</code></pre>
<p>The <code>NewTable</code> bytecode is generated at the beginning of the function, but since the number of members of the array and the hash table is not yet known, the latter two parameters are temporarily filled with 0. And write down the position of this bytecode, and modify the parameters at the end of the function.</p>
<p>The intermediate loop is to traverse all members of the table. There are 3 syntax types in total:</p>
<ul>
<li>
<p>General type, <code>[ exp ] = exp</code>, key and value are both expressions, respectively loaded to the sp and sp+1 positions of the stack through the <code>load_exp()</code> function, and then generate <code>SetTable</code> bytecode;</p>
</li>
<li>
<p>Record type, <code>Name = exp</code>, key is Name, which is a string constant, added to the constant table, value is an expression, and finally generates <code>SetField</code> bytecode. There is a place here that is related to Rust's ownership mechanism, that is, the <code>key</code> obtained by matching the pattern branch <code>Token::Name(key)</code> of <code>match self.lex.peek()</code> cannot be directly passed through <code>add_const(* key)</code> added to the constant table. This is because <code>peek()</code> returns not <code>Token</code> itself, but a reference to <code>Token</code>, which is returned by <code>self.lex.peek()</code>, so the associated <code>self.lex</code> and <code>self </code> are also in the referenced state; calling <code>self.add_const()</code> is also a mut reference to <code>self</code>, which violates the reference rules. The correct way is to abandon the return value of <code>peek()</code>, but call <code>self.lex.next()</code> to return Token and re-match. At this time, Rust's inspection is too strict, because the Token reference returned by <code>self.lex.peek()</code> does not affect <code>self.add_const()</code>. It should be that Rust has no ability to determine that there is no influence between the two.</p>
</li>
<li>
<p>List type, <code>exp</code>, is loaded to the <code>sp</code> position of the stack, and <code>sp</code> is updated, waiting for the last <code>SetList</code> to perform insertion. But you can't load data on the stack infinitely, because this will cause the stack to reallocate memory all the time, so if the current data on the stack exceeds 50, generate a <code>SetList</code> bytecode to clean up the stack.</p>
</li>
</ul>
<p>What needs to be explained here is that when the <code>Name</code> is parsed, it may be either a record type or a list type. We need to peek the next Token to distinguish between the two: if the next Token is <code>=</code>, it is a record type , otherwise it is tabular. The problem here is that <code>Name</code> is already peeked, and the lexical analysis only supports peek one Token because of [using <code>Peekable</code>](./ch03-03.read_input.md#use peekable), so it can only Modify the expression parsing function <code>load_exp()</code> to support a Token read in advance, and add <code>load_exp_with_ahead()</code> function for this purpose. In the entire Lua grammar, there is only one place that needs to look forward to two Tokens.</p>
<blockquote>
<p>This kind of behavior that needs to look forward to two Tokens to determine the expression, I wonder if it is called <a href="https://en.wikipedia.org/wiki/LL_parser">LL(2)</a>?</p>
</blockquote>
<h2 id="virtual-machine-execution-1"><a class="header" href="#virtual-machine-execution-1">Virtual Machine Execution</a></h2>
<p>The following is the virtual machine execution code of the newly added 4 bytecodes, which is also very simple and can be skipped:</p>
<pre><code class="language-rust  ignore">     ByteCode::NewTable(dst, narray, nmap) =&gt; {
         let table = Table::new(narray as usize, nmap as usize);
         self.set_stack(dst, Value::Table(Rc::new(RefCell::new(table))));
     }
     ByteCode::SetTable(table, key, value) =&gt; {
         let key = self.stack[key as usize].clone();
         let value = self.stack[value as usize].clone();
         if let Value::Table(table) = &amp;self. stack[table as usize] {
             table.borrow_mut().map.insert(key, value);
         } else {
             panic!(&quot;not table&quot;);
         }
     }
     ByteCode::SetField(table, key, value) =&gt; {
         let key = proto.constants[key as usize].clone();
         let value = self.stack[value as usize].clone();
         if let Value::Table(table) = &amp;self. stack[table as usize] {
             table.borrow_mut().map.insert(key, value);
         } else {
             panic!(&quot;not table&quot;);
         }
     }
     ByteCode::SetList(table, n) =&gt; {
         let ivalue = table as usize + 1;
         if let Value::Table(table) = self.stack[table as usize].clone() {
             let values = self. stack. drain(ivalue .. ivalue + n as usize);
             table.borrow_mut().array.extend(values);
         } else {
             panic!(&quot;not table&quot;);
         }
     }</code></pre>
<p>The first bytecode <code>NewTable</code> is very simple and will not be introduced. The latter two bytecodes <code>SetTable</code> and <code>SetField</code> are similar, and both need to get the mut reference of the table through <code>borrow_mut()</code>. The final bytecode <code>SetList</code> encounters Rust’s ownership problem again, and needs to explicitly call the <code>clone()</code> function on the list on the stack to create a pointer to an independent list. If <code>clone()</code> is not called, then the <code>table</code> variable obtained by the first line <code>if let</code> statement matching is a reference to the member on the stack, that is, a reference to the stack, and this reference needs to continue until the third line, so it cannot be released in advance; the second line calling <code>stack.drain()</code> needs to obtain the variable reference of the stack, which conflicts with the reference obtained by the <code>table</code> variable in the first line. Therefore, <code>clone()</code> needs to generate a pointer to an independent table, so that the <code>table</code> variable matched in the first line is only a reference to the table, and is separated from the reference to the stack, thereby avoiding conflicts.</p>
<p>The mandatory <code>clone()</code> here increases performance consumption, but also avoids potential bugs. For example, the stack location where the table is located may be included in the subsequent <code>stack.drain()</code>, so the address becomes invalid, and then the operation of inserting data into the table in the third subsequent line will be abnormal. Of course, in the scenario of <code>SetList</code>, the syntax analysis will ensure that the stack location cleaned by <code>stack.drain()</code> does not include the table, but the Rust compiler does not know, and there is no guarantee that it will not be included in the future. So <code>clone()</code> here completely eliminates this hidden danger, and it is worthwhile.</p>
<p>So far, we have completed the construction of the table, and the following sections will introduce the reading and writing of the table.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="expdesc-concept"><a class="header" href="#expdesc-concept">ExpDesc Concept</a></h1>
<p>Before introducing the reading and writing of tables, this section first introduces <code>ExpDesc</code>, the core data structure of syntax analysis.</p>
<h2 id="problems-with-table-construction"><a class="header" href="#problems-with-table-construction">Problems with Table Construction</a></h2>
<p>There is a performance issue with the construction of the table implemented in the previous section. For example, for the general type <code>[ exp ] = exp</code>, the expression corresponding to the key and value will be loaded to the top of the stack through the <code>load_exp()</code> function in turn as a temporary variable; then <code>SetTable</code> bytecode will be generated, including The indices of the two temporary variables on top of the stack. code show as below:</p>
<pre><code class="language-rust  ignore">     Token::SqurL =&gt; { // `[` exp `]` `=` exp
         nmap += 1;
         self. lex. next();

         self.load_exp(sp); // load key to the top of the stack
         self.lex.expect(Token::SqurR); // `]`
         self.lex.expect(Token::Assign); // `=`
         self.load_exp(sp + 1); // load value to the top of the stack

         self.byte_codes.push(ByteCode::SetTable(table, sp as u8, sp as u8 + 1));
     },</code></pre>
<p>This is wasteful because certain expression types, such as local variables, temporary variables, and constants, can be referenced directly without being loaded on the stack. For example, the following Lua code:</p>
<pre><code class="language-lua">local k = 'kkk'
local v = 'vvv'
local t = { [k] = v }
</code></pre>
<p>According to the current implementation, the runtime stack and bytecode sequence are as follows:</p>
<pre><code>    +---------+
  0 |  &quot;kkk&quot;  |---\[1] Move 3 0
    +---------+   |
  1 |  &quot;vvv&quot;  |---|-\[2] Move 4 1
    +---------+   | |
  2 |   { }   |&lt;--|-|---------\
    +---------+   | |         |
  3 |  &quot;kkk&quot;  |&lt;--/ |   --\   |
    +---------+     |      &gt;--/[3] SetTable 2 3 4
  4 |  &quot;vvv&quot;  |&lt;----/   --/
    +---------+
    |         |
</code></pre>
<p>In fact, neither of these two temporary variables is needed, but only one bytecode is needed: <code>SetTable 2 0 1</code>, where the three parameters are the indexes of the table, key, and value on the stack. This is also the way Lua is officially implemented, that is, to directly refer to the index as much as possible, and avoid unnecessary temporary variables. The runtime stack and bytecode sequences are as follows:</p>
<pre><code>    +---------+
  0 |  &quot;kkk&quot;  |---\
    +---------+    &gt;--\[1] SetTable 2 0 1
  1 |  &quot;vvv&quot;  |---/   |
    +---------+       |
  2 |   { }   |&lt;------/
    +---------+
    |         |
</code></pre>
<p>These two methods (whether to introduce temporary variables) correspond to two types of virtual machines: stack-based and register-based.</p>
<h2 id="stack-based-and-register-based"><a class="header" href="#stack-based-and-register-based">Stack-based and Register-based</a></h2>
<p>First list the bytecode of the current implementation in the above example:</p>
<pre><code>Move 3 0    # Load k to position 3. Now 3 is the top of the stack
Move 4 1    # Load v to position 4. Now 4 is the top of the stack
SetTable 2 3 4
</code></pre>
<p>In the current implementation, we can be sure that the key and value are to be loaded to the top of the stack, so the first parameter (that is, the target address) in the two <code>Move</code> bytecodes can be omitted; in addition, we can also be sure when setting the table, the key and value must be at the top of the stack, so the last two parameters of <code>SetTable</code> bytecode can also be omitted. So the bytecode sequence can be simplified as follows:</p>
<pre><code>Push 0     # load k to the top of the stack
Push 1     # load v to the top of the stack
SetTable 2 # Use the two values at the top of the stack as key and value,
           # and set them to the table at position 2
</code></pre>
<p>This method of operating parameters through the top of the stack is called a <em>stack-based</em> virtual machine. The virtual machines of many scripting languages such as Java and Python are based on stacks. The method of directly indexing parameters in the bytecode (such as <code>SetTable 2 0 1</code>) is called <em>register-based</em> virtual machine. The &quot;register&quot; here is not a register in the computer CPU, but a virtual concept. For example, in our Lua interpreter, it is a register implemented by a stack and a constant table. Lua was the first (official virtual machine) register-based mainstream language.</p>
<p>The above is the write statement through the table as an example. Let's introduce another example that is easier to understand, the addition statement (although we have not implemented addition yet, it is indeed easier to understand). For the following Lua code:</p>
<pre><code class="language-lua">local
local a = 1
local b = 2
r = a + b
</code></pre>
<p>The bytecode generated by a stack-based virtual machine might look like this:</p>
<pre><code>Push 1    # load a to the top of the stack
Push 2    # load b to the top of the stack
Add       # Pop and add the 2 numbers at the top of the stack, and push the result to the top of the stack
Pop 0     # Pop the result at the top of the stack and assign it to r
</code></pre>
<p>The bytecode generated by a register-based virtual machine might look like this:</p>
<pre><code>Add 0 1 2
</code></pre>
<p>It can be seen intuitively that the number of bytecode sequences based on the register virtual machine is small, but each bytecode is longer. It is generally believed that the performance of register-based bytecode is slightly better, but the implementation is more complicated. A more detailed description and comparison of these two types is beyond the scope of this article, and I have no ability to introduce them. The reason why I chose register-based in this project is simply because that's what the official Lua implementation does. I didn't know these two ways until I even wrote part of the project. Next, just continue to follow the register-based method instead of entangled with the stack-based method.</p>
<p>One thing to note is that the register-based method is just <em>trying</em> to avoid using the temporary variable on the top of the stack. It is also needed when necessary. How to choose a register or a temporary variable will be described in detail later.</p>
<h2 id="intermediary-expdesc"><a class="header" href="#intermediary-expdesc">Intermediary ExpDesc</a></h2>
<p>Since we want to follow the register-based method, why do we need to load both key and value to the top of the stack and use the stack-based method in the construction of the table in the previous section? It's because we can't implement a register-based approach yet. Now <code>load_exp()</code> function directly generates bytecode and loads it to the specified position of the stack after encountering Token. code show as below:</p>
<pre><code class="language-rust  ignore">     fn load_exp(&amp;mut self, dst: usize) {
         let code = match self. lex. next() {
             Token::Nil =&gt; ByteCode::LoadNil(dst as u8),
             Token::True =&gt; ByteCode::LoadBool(dst as u8, true),
             Token::False =&gt; ByteCode::LoadBool(dst as u8, false),
             Token::Float(f) =&gt; self. load_const(dst, f),
             Token::String(s) =&gt; self. load_const(dst, s),
             // omit other tokens
         };
         self.byte_codes.push(code);
     }</code></pre>
<p>Therefore, when parsing the general-purpose writing statement of the above table, when the expression of key and value is encountered, it is immediately loaded to the top of the stack, and it becomes a stack-based method.</p>
<p>And if we want to realize the register-based method to generate bytecodes such as <code>SetTable 2 0 1</code>, when encountering key or value expressions, we cannot generate bytecodes immediately, but need to save them temporarily and wait for the opportunity When it is mature, deal with it according to the situation. Or use the Lua code at the beginning of this section as an example:</p>
<pre><code class="language-lua">local k = 'kkk'
local v = 'vvv'
local t = { [k] = v }
</code></pre>
<p>The table construction statement in line 3 is parsed as follows:</p>
<ul>
<li><code>[</code>, determined as a general formula;</li>
<li><code>k</code>, as a Name, first determine that it is a local variable, the index is 0, and then save it as a key;</li>
<li><code>]</code> and <code>=</code>, as expected;</li>
<li><code>v</code>, as a Name, is also determined to be a local variable, the index is 1, and then saved as a value;</li>
<li>At this point, an initialization statement is completed, and the indexes of the key and value saved before are 0 and 1 respectively, so the bytecode <code>SetTable 2 0 1</code> can be generated.</li>
</ul>
<p>The key here is &quot;save the key/value&quot;. We are going to add this staging mechanism now. A solution is to directly save the read Token. For example, in this example, the key and value are saved as <code>Token::Name(&quot;k&quot;)</code> and <code>Token::Name(&quot;v&quot;)</code> respectively. But doing so has several problems:</p>
<ul>
<li>A small problem is that Name may be a local variable or a global variable. We will see later that the handling of these two variables is different, and <code>Token::Name</code> cannot distinguish between these two types.</li>
<li>The slightly bigger problem is that some expressions are more complex and contain more than one Token, such as <code>t.k</code>, <code>a+1</code>, <code>foo()</code>, etc., which cannot be represented by a Token. To support tables in this chapter, we must support expression statements such as <code>t.k</code> or even <code>t.k.x.y</code>.</li>
<li>The bigger problem is that table reads <code>t.k</code> can at least be implemented in a stack-based way, but table writes cannot. For example, <code>t.k = 1</code> is the left part of the assignment statement. When parsing, it must be saved first, then parse the rvalue expression, and finally execute the assignment. To support the write statement of the table, it is necessary to add this temporary storage mechanism first. This is why this section must be inserted before supporting the read and write functions of the table.</li>
</ul>
<p>So, we need a new type to hold intermediate results. To this end we introduce <code>ExpDesc</code> (the name comes from the official Lua implementation code):</p>
<pre><code class="language-rust  ignore">#[derive(Debug, PartialEq)]
enum ExpDesc {
     Nil,
     Boolean(bool),
     Integer(i64),
     Float(f64),
     String(Vec&lt;u8&gt;),
     Local(usize), // on stack, including local and temporary variables
     Global(usize), // global variable
}</code></pre>
<p>Now it seems that its type is the type currently supported by the expression, but <code>Token::Name</code> is split into <code>Local</code> and <code>Global</code>, so introducing this type is a bit of a fuss. But in the next section to support the reading and writing of tables, as well as subsequent statements such as calculation expressions and conditional jumps, ExpDesc will show its talents!</p>
<p>The original parsing process is to directly generate bytecode from Token:</p>
<pre><code>     Token::Integer -&gt; ByteCode::LoadInt
     Token::String -&gt; ByteCode::LoadConst
     Token::Name -&gt; ByteCode::Move | ByteCode::GetGlobal
     ...
</code></pre>
<p>Now that the ExpDesc layer is added in the middle, the parsing process becomes:</p>
<pre><code>     Token::Integer -&gt; ExpDesc::Integer -&gt; ByteCode::LoadInt
     Token::String -&gt; ExpDesc::String -&gt; ByteCode::LoadConst
     Token::Name -&gt; ExpDesc::Local -&gt; ByteCode::Move
     Token::Name -&gt; ExpDesc::Global -&gt; ByteCode::GetGlobal
     ...
</code></pre>
<h2 id="syntax-analysis-and-expdesc"><a class="header" href="#syntax-analysis-and-expdesc">Syntax Analysis and ExpDesc</a></h2>
<p>ExpDesc is very important, and I will introduce it from another angle here.</p>
<p><a href="./ch01-01.principles.html">Section 1.1</a> The general compilation process is introduced in the basic compilation principle:</p>
<pre><code>              Lexical Analysis      Syntax Analysis      Semantic Analysis
Character Stream --------&gt; Token Stream --------&gt; Syntax Tree --------&gt; Intermediate Code ...
</code></pre>
<p>We still use the above addition code as an example:</p>
<pre><code class="language-lua">local
local a = 1
local b = 2
r = a + b
</code></pre>
<p>According to the above general compilation process, for the addition statement in the last line, the syntax analysis will get the syntax tree:</p>
<pre><code>     |
     V
     +
    / \
   a   b
</code></pre>
<p>Then during semantic analysis, first see <code>+</code>, and know that this is an addition statement, so you can directly generate bytecode: <code>Add ? 1 2</code>. Among them, <code>?</code> is the target address of the addition, which is handled by the assignment statement and is ignored here; <code>1</code> and <code>2</code> are the stack indexes of the two addends respectively.</p>
<p>But our current approach, which is also the official implementation of Lua, omits the &quot;semantic analysis&quot; step, directly generates intermediate code from syntax analysis, and generates code while analyzing. Then when syntactic analysis, you can't have a global perspective like the above-mentioned semantic analysis. For example, for the addition statement <code>a+b</code>, when <code>a</code> is read, it is not known that it is an addition statement, so it can only be saved first. When <code>+</code> is read, it is determined that it is an addition statement, and then the second addend is read, and then bytecode is generated. We introduce an intermediate layer <code>ExpDesc</code> for this purpose. So ExpDesc is equivalent to the role of the &quot;syntax tree&quot; in the general process. It's just that the syntax tree is global, and ExpDesc is local, and it is the smallest granularity.</p>
<pre><code>             Lexical Analysis            Syntax Analysis
Character stream --------&gt; Token stream ----(ExpDesc)---&gt; intermediate code ...
</code></pre>
<p>It can be seen intuitively that this method of Lua omits the semantic analysis step, and the speed should be slightly faster, but because there is no global perspective, the implementation is relatively complicated. A more detailed description and comparison of these two approaches is beyond the scope of this article. We choose to follow Lua's official implementation method and choose the method of syntactic analysis to directly generate bytecode.</p>
<h2 id="summary-2"><a class="header" href="#summary-2">Summary</a></h2>
<p>This section introduces the concept of ExpDesc and describes its role. In the next section, the existing code will be modified based on ExpDesc.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="expdesc-rewrite"><a class="header" href="#expdesc-rewrite">ExpDesc Rewrite</a></h1>
<p>The previous section introduced the concept of ExpDesc and introduced its function and role. This section is based on ExpDesc to modify the existing code. This transformation does not support new features, but only lays the foundation for the reading and writing functions of the next table and more features to follow.</p>
<p>First of all, the most important thing is the function <code>load_exp()</code> for parsing expressions. This function originally generated bytecode directly from Token. Now it needs to be split into two steps: Token to ExpDesc, and generating bytecode from ExpDesc. Then, on this basis, transform the table constructor and variable assignment statement.</p>
<h2 id="exp"><a class="header" href="#exp">exp()</a></h2>
<p>Transform the <code>load_exp()</code> function step 1, Token to ExpDesc, create a new <code>exp()</code> function, the code is as follows:</p>
<pre><code class="language-rust  ignore">     fn exp(&amp;mut self) -&gt; ExpDesc {
         match self. lex. next() {
             Token::Nil =&gt; ExpDesc::Nil,
             Token::True =&gt; ExpDesc::Boolean(true),
             Token::False =&gt; ExpDesc::Boolean(false),
             Token::Integer(i) =&gt; ExpDesc::Integer(i),
             Token::Float(f) =&gt; ExpDesc::Float(f),
             Token::String(s) =&gt; ExpDesc::String(s),
             Token::Name(var) =&gt; self. simple_name(var),
             Token::CurlyL =&gt; self. table_constructor(),
             t =&gt; panic!(&quot;invalid exp: {:?}&quot;, t),
         }
     }

     fn simple_name(&amp;mut self, name: String) -&gt; ExpDesc {
         // search reversely, so new variable covers old one with same name
         if let Some(ilocal) = self.locals.iter().rposition(|v| v == &amp;name) {
             ExpDesc::Local(ilocal)
         } else {
             ExpDesc::Global(self. add_const(name))
         }
     }</code></pre>
<p>It is relatively simple, similar to the main structure of the previous <code>load_exp()</code> function, or even simpler, that is, several Token types supported by the expression statement are converted into the corresponding ExpDesc. Among them, Name and table construction need further processing. Name is to be distinguished from a local variable or a global variable by the <code>simple_name()</code> function. The processing of the table construction branch becomes a lot more reasonable, [before] (./ch04-02.table_constructor.md#other scenes) need to add an ugly <code>return</code> in this branch, now because this function does not generate bytes code, so this branch can also end naturally. However, although bytecode is no longer needed, ExpDesc is required, so the table constructor <code>table_constructor()</code> needs to return an ExpDesc. Because the newly created table is finally put on the stack, it returns <code>ExpDesc::Local(i)</code>. Note that the <code>ExpDesc::Local</code> type does not just represent &quot;local variables&quot;, but &quot;variables on the stack&quot;. The name &quot;Local&quot; is used to be consistent with the official Lua code.</p>
<p>In addition to not generating bytecode, this function has another change compared with <code>load_exp()</code>, that is, there is no <code>dst</code> parameter. In most cases, it is fine, but there is a problem with the constructor of the table. Because the table construction process is to create a table on the stack first, the bytecode generated by the subsequent initialization statement needs to bring the index of the table on the stack as a parameter. For example <code>SetTable 3 4 5</code>, the first parameter is the index of the table on the stack. So the original <code>table_constructor()</code> function needs a <code>dst</code> parameter. Now there is no such parameter, what should I do? We can assume that all table constructions create new tables at the top of the stack. So it is necessary to maintain the current top position of the stack.</p>
<h2 id="stack-top-sp"><a class="header" href="#stack-top-sp">Stack Top <code>sp</code></a></h2>
<p>To maintain the current stack top position, first add <code>sp</code> indicating the current stack top in <code>ParseProto</code>. In the past, the current position of the top of the stack was calculated in real time wherever it was needed, but now it is changed to a global variable, and many places are suddenly coupled. Later, as the characteristics increase, this coupling will become larger and larger, and it will become more and more out of control. But it is too cumbersome to pass the top position of the stack through parameters. In comparison, it is more convenient to maintain a global stack top delegate, but be careful.</p>
<p>The stack has three functions: function calls, local variables, and temporary variables. The first two have specific statements (function call statements and local variable definition statements) for specific processing. The last one, temporary variables, are used in many places, such as the table construction statement mentioned above, so they need to be carefully managed when they are used, and they cannot affect each other. In addition, because local variables also occupy the stack space, before parsing a statement each time, the value of sp on the top of the stack is initialized to the number of current local variables, which is where temporary variables are allowed to be used.</p>
<p>Let's look at the use of the <code>sp</code> in the table constructor <code>table_constructor()</code>:</p>
<pre><code class="language-rust  ignore">     fn table_constructor(&amp;mut self) -&gt; ExpDesc {
         let table = self.sp; // Create a new table at the top of the stack
         self.sp += 1; // update sp, if subsequent statements need temporary variables, use the stack position behind the table

         // omit intermediate construction code

         self.sp = table + 1; // Before returning, set the sp on the top of the stack, keep only the newly created table, and clean up other temporary variables that may be used during construction
         ExpDesc::Local(table) // return the type of the table (temporary variable on the stack) and the position on the stack
      }</code></pre>
<p>Use the <code>sp</code> at the beginning of the function to replace the <code>dst</code> parameter passed in the previous version as the location of the new table. Before the function ends, reset the top position of the stack. In the following subsections, we will continue to introduce the use of the <code>sp</code> of the stack when this function actually builds the table.</p>
<h2 id="discharge"><a class="header" href="#discharge">discharge()</a></h2>
<p>The second step of transforming the <code>load_exp()</code> function is from ExpDesc to bytecode. In fact, it is more accurate to say that ExpDesc is loaded onto the stack. We use the function name discharge in the official Lua code to represent &quot;loading&quot;.</p>
<pre><code class="language-rust  ignore">     // discharge @desc into @dst, and set self.sp=dst+1
     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             ExpDesc::Nil =&gt; ByteCode::LoadNil(dst as u8),
             ExpDesc::Boolean(b) =&gt; ByteCode::LoadBool(dst as u8, b),
             ExpDesc::Integer(i) =&gt;
                 if let Ok(i) = i16::try_from(i) {
                     ByteCode::LoadInt(dst as u8, i)
                 } else {
                     self. load_const(dst, i)
                 }
             ExpDesc::Float(f) =&gt; self. load_const(dst, f),
             ExpDesc::String(s) =&gt; self. load_const(dst, s),
             ExpDesc::Local(src) =&gt;
                 if dst != src {
                     ByteCode::Move(dst as u8, src as u8)
                 } else {
                     return;
                 }
             ExpDesc::Global(iname) =&gt; ByteCode::GetGlobal(dst as u8, iname as u8),
         };
         self.byte_codes.push(code);
         self.sp = dst + 1;
     }</code></pre>
<p>This function is also very simple. Generate the corresponding bytecode according to ExpDesc, and discharge the expression statement represented by ExpDesc onto the stack. Note that the last line of this function updates the top position of the stack to the next position of dst. In most cases, it is as expected. If it is not as expected, the caller needs to update the top position of the stack after the function returns.</p>
<p>In addition to this most basic function, there are several helper functions. The <code>discharge()</code> function is to force the expression discharge to the dst position of the stack. But sometimes you just want to discharge the expression on the stack. If the expression is already on the stack, such as <code>ExpDesc::Local</code> type, then you don’t need to discharge it. A new function <code>discharge_if_need()</code> is introduced for this purpose. In most cases, it doesn't even care where it is loaded, so create a new function <code>discharge_top()</code>, using the top position of the stack. The two function codes are as follows:</p>
<pre><code class="language-rust  ignore">    // discharge @desc into the top of stack, if need
    fn discharge_top(&amp;mut self, desc: ExpDesc) -&gt; usize {
        self.discharge_if_need(self.sp, desc)
    }

    // discharge @desc into @dst, if need
    fn discharge_if_need(&amp;mut self, dst: usize, desc: ExpDesc) -&gt; usize {
        if let ExpDesc::Local(i) = desc {
            i // no need
        } else {
            self.discharge(dst, desc);
            dst
        }
    }</code></pre>
<p>In addition, the <code>discharge_const()</code> function is added, and several constant types are added to the constant table, and other types are discharged as needed. This function will be used in the construction and assignment statements of the following tables:</p>
<pre><code class="language-rust  ignore">    // for constant types, add @desc to constants;
    // otherwise, discharge @desc into the top of stack
    fn discharge_const(&amp;mut self, desc: ExpDesc) -&gt; ConstStack {
        match desc {
            // add const
            ExpDesc::Nil =&gt; ConstStack::Const(self.add_const(())),
            ExpDesc::Boolean(b) =&gt; ConstStack::Const(self.add_const(b)),
            ExpDesc::Integer(i) =&gt; ConstStack::Const(self.add_const(i)),
            ExpDesc::Float(f) =&gt; ConstStack::Const(self.add_const(f)),
            ExpDesc::String(s) =&gt; ConstStack::Const(self.add_const(s)),

            // discharge to stack
            _ =&gt; ConstStack::Stack(self.discharge_top(desc)),
        }
    }</code></pre>
<p>After completing the <code>exp()</code> and <code>discharge()</code> functions, the previous <code>load_exp()</code> function can be combined with these two new functions:</p>
<pre><code class="language-rust  ignore">     fn load_exp(&amp;mut self) {
         let sp0 = self.sp;
         let desc = self. exp();
         self. discharge(sp0, desc);
     }</code></pre>
<p>At the end of this chapter, the parsing of expressions in the parsing process will directly call a series of functions of <code>exp()</code> and discharge, instead of calling the <code>load_exp()</code> function.</p>
<h2 id="table_constructor"><a class="header" href="#table_constructor">table_constructor()</a></h2>
<p>After splitting the <code>load_exp()</code> function into <code>exp()</code> and <code>discharge()</code>, the constructor of the table can be transformed. Or take general-purpose initialization as an example, in <a href="./ch04-02.table_constructor.html#syntax-analysis">previous version</a>, the key and value are directly loaded onto the stack, no matter what type. We can now call <code>exp()</code> to read the key and value, and then do different processing according to the type. The specific processing method can refer to the official implementation of Lua. There are three bytecodes <code>SETTABLE</code>, <code>SETFIELD</code> and <code>SETI</code>, corresponding to the three types of key variables on the stack, string constants, and small integer constants. In addition, these 3 bytecodes have 1 bit to mark whether the value is a variable or a constant on the stack. There are 3 key types and 2 value types, a total of 3*2=6 situation. Although we can also distinguish between variables and constants on the stack by reserving a bit in value, this will result in only 7bit address space. So we still distinguish variables and constants on the stack by adding bytecode types. It ends up as follows:</p>
<pre><code>    value\key | variable      | string constant | small integer constant
   -----------+---------------+-----------------+---------------
    variable  | SetTable      | SetField        | SetInt
   -----------+---------------+-----------------+---------------
    constant  | SetTableConst | SetFieldConst   | SetIntConst
</code></pre>
<p>Another rule is that <code>nil</code> and <code>Nan</code> of floating-point numbers are not allowed to be used as keys. The parsing code for the key is as follows:</p>
<pre><code class="language-rust  ignore">     let entry = match self. lex. peek() {
         Token::SqurL =&gt; { // `[` exp `]` `=` exp
             self. lex. next();

             let key = self.exp(); // read key
             self.lex.expect(Token::SqurR); // `]`
             self.lex.expect(Token::Assign); // `=`

             TableEntry::Map(match key {
                 ExpDesc::Local(i) =&gt; // variables on the stack
                     (ByteCode::SetTable, ByteCode::SetTableConst, i),
                 ExpDesc::String(s) =&gt; // string constant
                     (ByteCode::SetField, ByteCode::SetFieldConst, self. add_const(s)),
                 ExpDesc::Integer(i) if u8::try_from(i).is_ok() =&gt; // small integer
                     (ByteCode::SetInt, ByteCode::SetIntConst, i as usize),
                 ExpDesc::Nil =&gt;
                     panic!(&quot;nil can not be table key&quot;),
                 ExpDesc::Float(f) if f.is_nan() =&gt;
                     panic!(&quot;NaN can not be table key&quot;),
                 _ =&gt; // For other types, discharge them onto the stack uniformly and turn them into variables on the stack
                     (ByteCode::SetTable, ByteCode::SetTableConst, self.discharge_top(key)),
             })
         }</code></pre>
<p>The above code handles three types of keys: local variables, string constants, and small integers. In addition, nil and floating-point numbers Nan are prohibited. For other types, they are uniformly discharged to the top of the stack and converted to variables on the stack.</p>
<p>Then parse the value to distinguish between variables and constants on the stack. code show as below:</p>
<pre><code class="language-rust  ignore">     match entry {
         TableEntry::Map((op, opk, key)) =&gt; {
             let value = self.exp(); // read value
             let code = match self. discharge_const(value) {
                 // value is a constant, use opk, such as `ByteCode::SetTableConst`
                 ConstStack::Const(i) =&gt; opk(table as u8, key as u8, i as u8),

                 // value is not a constant, then discharge to the stack, and use op, such as `ByteCode::SetTable`
                 ConstStack::Stack(i) =&gt; op(table as u8, key as u8, i as u8),
             };
             self.byte_codes.push(code);

             nmap += 1;
             self.sp = sp0;
         }</code></pre>
<p>The logic of the above two pieces of code itself is very clear, but the parameter types associated with <code>TableEntry::Map</code> are somewhat special. The first piece of code deals with the type of the key, and determines the type of 2 bytecodes, or the tag of <code>ByteCode</code>. This tag is to be used as an associated parameter of <code>TableEntry::Map</code>. Then what type is that? It must not be <code>ByteCode</code>, because the enum type includes not only the tag, but also the associated value. If it is a <code>ByteCode</code> type, then it is not <code>ByteCode::SetTable</code> but a complete <code>ByteCode::SetTable(table,key,0)</code>, that is, first generate a complete bytecode, and then read Modify the bytecode when the value is reached. That would be too complicated.</p>
<p><a href="https://doc.rust-lang.org/stable/book/ch19-05-advanced-functions-and-closures.html#function-pointers">《Rust Programming Language》</a> introduces these enums with <code>()</code> as initialization syntax, looks like a function call, they are indeed implemented as functions returning an instance constructed from parameters. That is to say <code>ByteCode::SetTable</code> can be regarded as a function, and its parameter type is <code>fn(u8,u8,u8)-&gt;ByteCode</code>. When I read this book for the first time, I was confused by the countless new concepts in it, so I had no impression of reading this sentence at all, and even if I saw it, I couldn’t understand it or remember it. When I wrote this project for more than half, I read this book completely again. This time, I understood most of the concepts in it very smoothly, and I can also notice the introduction of function pointers. And it just happened to work, what a find!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table-readwrite-and-bnf"><a class="header" href="#table-readwrite-and-bnf">Table Read/Write and BNF</a></h1>
<p>After introducing ExpDesc and modifying the existing syntax analysis in the previous two sections, this section implements table reading and writing.</p>
<p>The index of the table in Lua supports two methods, examples are as follows: <code>t[&quot;k&quot;]</code> and <code>t.k</code>, where the latter is a special form of the former. All table read and write operations need to use the table index. Need to add the type of table index in ExpDesc.</p>
<p>The read and write operations of the table itself are not complicated, but it will make other statements suddenly become complicated:</p>
<ul>
<li>
<p>The read operation of the table may have multiple consecutive levels, such as <code>t.x.y</code>, so when parsing the expression, the end cannot be judged immediately, but the next Token needs to be peeked to judge.</p>
</li>
<li>
<p>The write operation of the table, that is, the assignment statement. The current assignment statement only supports the assignment of &quot;variables&quot;, that is, the lvalue only supports one Token::Name. To add support for table indexes, the handling of lvalues needs to be reimplemented. It is not enough to parse only one Token, but to parse an lvalue. So how is it considered a complete lvalue? For example, not all expressions can be used as lvalues, such as function calls or table constructions.</p>
</li>
<li>
<p>Previously, the assignment statement and function call statement were distinguished based on the second Token. If it is an equal sign <code>=</code>, it is an assignment statement. Now to support the write operation of the table, such as <code>t.k = 123</code>, then the second Token is a dot <code>.</code> instead of the equal sign <code>=</code>, but it is still an assignment statement. The previous judgment method is invalid. So is there any new way to distinguish between assignment statements and function call statements?</p>
</li>
</ul>
<p>The first read operation problem is easy to solve. The next two questions related to write operations are very difficult. We cannot answer them accurately now, but can only guess the answers. This leads to a bigger problem, that is, the previous syntax analysis is based on guesswork! For example, the format of the definition statement of local variables, etc., are guessed based on the experience of using the Lua language, and cannot guarantee its accuracy and completeness. But it was relatively simple before, so you can make a guess. In addition, in order not to interrupt the rhythm of the entire project, I did not delve into this issue. Now to introduce the reading and writing of the table, the statement becomes complicated, and it is impossible to continue to mix it up by guessing. It is necessary to introduce a formal grammatical description.</p>
<h2 id="bnf"><a class="header" href="#bnf">BNF</a></h2>
<p>The last chapter of the Lua manual is called: <a href="https://www.lua.org/manual/5.4/manual.html#9">The Complete Syntax of Lua</a>, the content is mainly a set of BNF descriptions. We don't need to know the meaning of the term &quot;BNF&quot;, we just need to know that this is a formal grammar description method, where the Lua grammar can be described completely and accurately. The grammatical rules of BNF itself are also very simple, and most of them are clear at a glance. Here are only two:</p>
<ul>
<li><code>{A}</code> represents 0 or more A</li>
<li><code>[A]</code> represents optional 1 A</li>
</ul>
<p>The code segment of Lua is called <code>chunk</code>, so the definition of <code>chunk</code> is used as the entry, and several descriptions are listed:</p>
<pre><code>chunk ::= block

block ::= {stat} [retstat]

stat ::=  ‘;’ | 
     varlist ‘=’ explist | 
     functioncall | 
     label | 
     break | 
     goto Name | 
     do block end | 
     while exp do block end | 
     repeat block until exp | 
     if exp then block {elseif exp then block} [else block] end | 
     for Name ‘=’ exp ‘,’ exp [‘,’ exp] do block end | 
     for namelist in explist do block end | 
     function funcname funcbody | 
     local function Name funcbody | 
     local attnamelist [‘=’ explist] 
</code></pre>
<p>It can be obtained from these rules: a <code>chunk</code> contains a <code>block</code>. A <code>block</code> contains zero or more <code>stat</code>s and an optional <code>retstat</code>. A <code>stat</code> has many types of statements. Among them, we have implemented the two statements <code>functioncall</code> and <code>local</code>, and then implemented the remaining types one by one to complete the entire grammar of Lua (although it is still far from the complete Lua language).</p>
<blockquote>
<p>I don't quite understand what is the difference between <code>chunk</code> and <code>block</code> here? Why list two separately?</p>
</blockquote>
<p>That is to say, we will implement the interpreter according to this set of specifications in the future, and we no longer need to rely on guesswork! Pick a few and compare them with our previous ones, such as local variable definition statements, and you can find that it should support multiple variables and multiple initializations expression, even without an initialization expression. This shows that our previous statement analysis is very imperfect. Later in this section, we will improve the sentences we already support based on BNF. Now find out the rules related to the table index:</p>
<pre><code>var ::= Name | prefixexp '[' exp ']' | prefixexp '.' Name

exp ::= nil | false | true | Numeral | LiteralString | '...' | functiondef |
prefixexp | tableconstructor | exp binop exp | unop exp

prefixexp ::= var | functioncall | '(' exp ')'

functioncall ::= prefixexp args | prefixexp ':' Name args
</code></pre>
<p>At first glance it looks a bit complicated. Take <code>var</code> as an example for analysis. Here <code>var</code> deduces three cases, the first <code>Name</code> is a simple variable, and the latter two are table indexes, which are grammar sugar for general methods and string indexes. It involves <code>prefixexp</code> and <code>exp</code>. Among them, <code>exp</code> is very similar to the <code>exp()</code> function we currently implement, but we still lack some situations, which also need to be added later. In addition, <code>Name</code> is directly in the <code>exp()</code> function, and now it has to be moved to <code>var</code>.</p>
<h2 id="eliminate-left-recursion"><a class="header" href="#eliminate-left-recursion">Eliminate Left Recursion</a></h2>
<p>There is a big problem here, the above 3 rules are recursively referenced. for example:</p>
<ul>
<li><code>var</code> refers to <code>prefixexp</code> which refers to <code>var</code>;</li>
<li><code>exp</code> refers to <code>prefixexp</code> which refers to <code>exp</code>.</li>
</ul>
<p>But these two examples are fundamentally different.</p>
<p>For the first example, after bringing in <code>var</code> and expanding it, it is</p>
<pre><code>prefixexp ::= Name | prefixexp '[' exp ']' | prefixexp '.' Name | prefixexp args | prefixexp ':' Name args | '(' exp ')'
</code></pre>
<p>The problem is that the 2nd and 3rd items of the derivation rule start with <code>prefixexp</code> both. Then during syntax analysis, for example, if you read a Name, you can match item 1, or items 2 and 3, so it is impossible to judge which rule should be selected. This was a headache. I spent two days on this problem, and tried various solutions but couldn't solve it. Later, I searched the Internet and found the concept of &quot;eliminating left recursion&quot;, and I vaguely recalled that this was a compulsory topic in the course of compiling principles. And there is a standard method for elimination: For rules that contain left recursion, they can be expressed as follows:</p>
<pre><code>A := Aα | β
</code></pre>
<p>Then it can be rewritten as follows:</p>
<pre><code>A := βA'
A’ := αA’ | ε
</code></pre>
<p>where <code>ε</code> is not matched. This eliminates left recursion. Take the above <code>prefixexp</code> as an example, first apply the above standard form, you can get:</p>
<pre><code>α = '[' exp ']' | '.' Name | args | ':' Name args
β = Name | '(' exp ')'
</code></pre>
<p>Then bring in the above rewritten formula to get:</p>
<pre><code>prefixexp := ( Name | '(' exp ')' ) A'
A' := ( '[' exp ']' | '.' Name | args | ':' Name args ) A' | ε
</code></pre>
<p>This way we get rules without left recursion.</p>
<p>And the second example at the beginning of this section, about <code>exp</code>, although there are recursive references, but it is not &quot;left&quot; recursion, so there is no such problem.</p>
<h2 id="read-table-and-prefixexp"><a class="header" href="#read-table-and-prefixexp">Read Table and <code>prefixexp</code></a></h2>
<p>The advantage of using BNF rules is that you don't need to think about Lua's grammar, just follow the rules to implement.</p>
<p>After obtaining the above BNF rules, the analysis of prefixexp can be completed:</p>
<pre><code class="language-rust  ignore">    fn prefixexp(&amp;mut self, ahead: Token) -&gt; ExpDesc {
        let sp0 = self.sp;

        // beta
        let mut desc = match ahead {
            Token::Name(name) =&gt; self.simple_name(name),
            Token::ParL =&gt; { // `(` exp `)`
                let desc = self.exp();
                self.lex.expect(Token::ParR);
                desc
            }
            t =&gt; panic!(&quot;invalid prefixexp {t:?}&quot;),
        };

        // A' = alpha A'
        loop {
            match self.lex.peek() {
                Token::SqurL =&gt; { // `[` exp `]`
                    self.lex.next();
                    let itable = self.discharge_if_need(sp0, desc);
                    desc = match self.exp() {
                        ExpDesc::String(s) =&gt; ExpDesc::IndexField(itable, self.add_const(s)),
                        ExpDesc::Integer(i) if u8::try_from(i).is_ok() =&gt; ExpDesc::IndexInt(itable, u8::try_from(i).unwrap()),
                        key =&gt; ExpDesc::Index(itable, self.discharge_top(key)),
                    };

                    self.lex.expect(Token::SqurR);
                }
                Token::Dot =&gt; { // .Name
                    self.lex.next();
                    let name = self.read_name();
                    let itable = self.discharge_if_need(sp0, desc);
                    desc = ExpDesc::IndexField(itable, self.add_const(name));
                }
                Token::Colon =&gt; todo!(&quot;args&quot;), // :Name args
                Token::ParL | Token::CurlyL | Token::String(_) =&gt; { // args
                    self.discharge(sp0, desc);
                    desc = self.args();
                }
                _ =&gt; { // Epsilon
                    return desc;
                }
            }
        }
    }</code></pre>
<p>The first paragraph of code corresponds to <code>β</code> mentioned above, namely <code>Name | '(' exp ')'</code>.</p>
<p>The loop in the second paragraph corresponds to the above <code>A' := αA' | ε</code>, if it matches the <code>α</code> part, it is <code>'[' exp ']' | '.' Name | args | ':' Name args</code>, then the loop continues after parsing; if there is no match, it corresponds to <code>ε</code>, and the loop exits. Here this loop supports many continuous operations, such as <code>t.f()</code>, which is a table index followed by a function call. Or more sequential operations like <code>t.t.t.k</code> and <code>f()()()</code>. If you follow the native method in the previous chapters and make a function as soon as you think of it, it will be difficult to support this kind of continuous operation, it is difficult to realize and it is difficult to think of it. But according to BNF, it can be realized correctly and completely.</p>
<p>Corresponding to the three types of bytecodes in the construction of the table, that is, the key is a variable on the stack, a string constant and a small integer. There are also three types of ExpDesc here, namely <code>Index</code>, <code>IndexField</code> and <code>IndexInt</code> . When discharging, add 3 corresponding bytecodes, <code>GetTable</code>, <code>GetField</code> and <code>GetInt</code>. This naturally solves the first problem at the beginning of this section, that is, the reading operation of the table is realized, and it is implemented correctly and completely!</p>
<p>Another feature of encoding according to the BNF rule is that you can only understand the processing logic inside each matching branch, but not the overall relationship between each branch. This is like solving a physics application problem. First, analyze the physical principles and list the equations, each of which has a corresponding physical meaning; but when solving the equations, the specific solution steps have been completely separated from the physical correspondence, which is a math tools.</p>
<p>The <code>prefixexp()</code> function is listed above, and the implementation of the <code>exp()</code> function is similar, which is omitted here.</p>
<h2 id="write-table-and-assignment-statement"><a class="header" href="#write-table-and-assignment-statement">Write Table and Assignment Statement</a></h2>
<p>After implementing <code>prefixexp</code> and <code>exp</code> according to BNF, the problem about table write operation at the beginning of this section can be solved. The problem can be solved by reimplementing the assignment statement according to BNF. What we want to achieve this time is &quot;complete assignment statement&quot;, and finally there is no need to emphasize &quot;variable assignment statement&quot;.</p>
<p>Although the assignment statement looks similar to the local variable definition statement, it is actually completely different and much more complicated. The assignment statement in BNF is defined as follows:</p>
<pre><code>varlist '=' explist
varlist ::= var {‘,’ var}
var ::= Name | prefixexp '[' exp ']' | prefixexp '.' Name
</code></pre>
<p>The left side of the assignment operator <code>=</code> is the <code>var</code> list. <code>var</code> expands to 3 kinds. The first <code>Name</code> is a variable, currently supports local variables and global variables, and will support upvalue after the introduction of closures. The latter two are table indexes. It can be seen from this that only these types of assignment are supported, while other types such as function calls do not support assignment. Look at the right side of <code>=</code>, which is a list of expressions, which can be parsed directly using the completed <code>exp()</code> function.</p>
<p>After reading the BNF grammatical rules of the assignment statement, there are three semantic rules.</p>
<p>First, compare the number of variables on the left of <code>=</code> and the number of expressions on the right side:</p>
<ul>
<li>If equal, assign values one by one;</li>
<li>If the number of variables is less than the number of expressions, the variable list and the corresponding expression list are assigned one by one, and the extra expressions are ignored;</li>
<li>If the number of variables is greater than the number of expressions, the expression list and the corresponding variable list are assigned one by one, and the extra variables are assigned to <code>nil</code>.</li>
</ul>
<p>Second, if the last expression on the right side of <code>=</code> has multiple values (such as function calls and variable parameters), it will be expanded as much as possible. However, we don't support these two types yet, so ignore this case for now.</p>
<p>Finally, all expressions to the right of <code>=</code> are evaluated <em>before</em> assignment. Instead of evaluating and assigning values simultaneously. For example, in the following Lua statement, the two expressions <code>b</code> and <code>a</code> on the right should be evaluated first to obtain <code>2</code> and <code>1</code>, and then assigned to <code>a</code> and <code>b</code> on the left respectively. This exchanges the two variables. But if we assign a value while evaluating, we first evaluate <code>b</code> on the right, get <code>2</code>, and assign it to <code>a</code>. Then evaluate <code>a</code> on the right to get the <code>2</code> that was just assigned, and then assign it to <code>b</code>. The end result is that both variables will be <code>2</code>.</p>
<pre><code class="language-lua">local a, b = 1, 2
a, b = b, a --swap 2 variables!!!
</code></pre>
<p>The diagram below depicts the execution process of <em>Error</em>:</p>
<pre><code>            +-------+
    /--(1)--|   a   |&lt;------\
    |       +-------+       |
    \------&gt;|   b   |--(2)--/
            +-------+
            |       |
</code></pre>
<p>Since all values must be evaluated first, the obtained value must be stored in one place first, which is naturally the top of the stack as a temporary variable. The diagram below describes the <em>correct</em> execution process:</p>
<pre><code>             +-------+
    /---(1)--|   a   |&lt;-------\
    |        +-------+        |
    |  /-(2)-|   b   |&lt;----\  |
    |  |     +-------+     |  |
    \-------&gt;|  tmp1 |-(3)-/  |
       |     +-------+        |
       \----&gt;|  tmp2 |--(4)---/
             +-------+
             |       |            
</code></pre>
<p>In the figure, (1) and (2) are to evaluate the expression and put it in the temporary position on the top of the stack; (3) and (4) are to assign the value of the temporary position on the top of the stack to the variable.</p>
<p>The functionality of this approach is correct, but the performance is relatively poor. Because each assignment requires 2 operations, first evaluating and then assigning, it requires 2 bytecodes. But in most cases, only one operation is required. For example, assigning a local variable to another local variable requires only one <code>Move</code> bytecode. In particular, the most common assignment statement in a program is the assignment of a single variable. The order of a single variable does not matter, and there is no need to evaluate a temporary variable first. Therefore, the above method of first evaluating to the top of the stack and then assigning a value is <em>for the correctness of a few cases, while sacrificing the performance of most cases</em>. This situation is relatively common in programming. The general solution is to add a quick path to <em>most cases</em>. For example, the following logic can be used in our current situation:</p>
<pre><code>if single variable then
     var = exp // direct assignment, quick path
else // multiple variables
     tmp_vars = exp_list // evaluate all to temporary variables first
     var_list = tmp_vars // assign values uniformly
</code></pre>
<p>There is a more elegant solution to this specific problem, though. The key here is that in the case of multiple assignments, the assignment of the last variable does not depend on the assignment of other variables, and it can be assigned directly without first evaluating to a temporary variable. So the new solution is: special treatment (direct assignment) is made to the last variable, and other variables are still evaluated first and then assigned. In this way, for the assignment statement of a single variable (the single variable is naturally the last variable), it degenerates into a direct assignment. In this way, the correctness of multiple variables is guaranteed, and the performance of most cases (single variable) is also guaranteed. Pretty!</p>
<p>The following figure describes this scheme: for the previous variable <code>a</code>, first evaluate to the temporary variable on the top of the stack, and assign the last variable <code>b</code> directly, and then assign the temporary variable on the top of the stack to the corresponding variable in turn.</p>
<pre><code>             +-------+
    /---(1)--|   a   |&lt;------\
    |        +-------+       |
    |        |   b   |--(2)--/
    |        +-------+ &lt;-------\
    \-------&gt;|  tmp1 |--(3)----/
             +-------+
             |       |
</code></pre>
<p>Since we execute the last expression first, thenthe previous expressions are also assigned in reverse order. In this way, all expressions are assigned in reverse order.</p>
<p>So far, the syntax and semantic rules of assignment statements have been introduced. The next step is to rewrite the <code>assignment()</code> function. The logic of the function body is as follows:</p>
<ol>
<li>Call <code>prefixexp()</code> to read the lvalue list and save it as ExpDesc;</li>
<li>Call <code>exp()</code> to read the rvalue expression list, the last expression retains ExpDesc, and the remaining expressions are discharged to the top of the stack;</li>
<li>Align the number of lvalues and rvalues;</li>
<li>Assignment, first assign the last expression to the last lvalue, and then assign the temporary variable on the top of the stack to the corresponding lvalue in turn.</li>
</ol>
<p>The specific code is omitted here. Only step 4, assignment, will be described in detail below.</p>
<h2 id="execute-the-assignment"><a class="header" href="#execute-the-assignment">Execute the Assignment</a></h2>
<p>Assignment statements consist of lvalues and rvalues:</p>
<ul>
<li>
<p>Each lvalue is read by the <code>prefixexp()</code> function, returning an ExpDesc type. However, it can be seen from BNF that the assignment statement only supports variables and table indexes. The variables include local variables and global variables, corresponding to the two ExpDesc types <code>Local</code> and <code>Global</code> respectively, and the table indexes include <code>Index</code>, <code>IndexField</code> and <code>IndexInt</code>. So there are up to a total of five types.</p>
</li>
<li>
<p>Each rvalue is read by the <code>exp()</code> function, which also returns an ExpDesc type, and supports arbitrary ExpDesc types.</p>
</li>
</ul>
<p>To sum up, there are 5 types on the left and N types on the right (N is the number of all types of ExpDesc), and there are a total of 5*N combinations. A bit much, need to sort out.</p>
<p>First of all, for the case where the lvalue is a local variable, the assignment is equivalent to discharging the expression to the stack location of the local variable. Just call the <code>discharge()</code> function. This function already handles all N types of ExpDesc.</p>
<p>The remaining four lvalue types are a bit more complicated, but these four cases are similar. The following uses the global variable <code>Global</code> type as an example to introduce.</p>
<p>Several combinations of assignments were introduced in the previous <a href="./ch02-03.assignment.html#combination-of-assignments">Assignment</a> section. For the case where the lvalue is a global variable, the rvalue supports three types of expressions: constant, local variable, and global variable. At that time, for the sake of simplicity, the three expressions <code>SetGlobalConst</code>, <code>SetGlobal</code>, and <code>SetGlobalGlobal</code> were directly generated. Now it can be foreseen that there will be more types of expressions in the future, such as the reading of tables added in this section (such as <code>t.k</code>), and subsequent additions such as UpValue and operations (such as <code>a+b</code>). If a new bytecode is added for each new type, it will become very complicated.</p>
<p>Moreover, expressions such as table indexing and operations require 2 parameters to represent, and the assignment bytecode of this series of global variables cannot be filled with 2 parameters to represent the source expression of the assignment (one bytecode supports up to 3 <code>u8</code> Type parameter, this series of bytecodes needs 1 parameter to represent the destination address, and it seems that 2 parameters can be used to represent the source expression. But through the output of luac, you can see Lua's official global variable assignment bytecode <code>SETTABUP</code> has 3 parameters. In addition to the 2 parameters representing the source and destination addresses, there is an additional parameter. Although it is not clear what the function of the extra parameter is, let’s assume that we will use it later That parameter, so our series of bytecodes leaves only one parameter position for the source expression). So how to deal with such complex expressions? The answer is to first evaluate these complex expressions to the top of the stack as temporary variables, which are of <code>Local</code> type, and then use <code>SetGlobal</code> to complete the assignment.</p>
<p>Here are two extremes:</p>
<ul>
<li>The previous practice was to define a bytecode for each source expression type;</li>
<li>The solution just discussed is to discharge all types on the stack first, and then only use one <code>SetGlobal</code> bytecode.</li>
</ul>
<p>Between these two extremes, we refer to the choice of Lua's official implementation, which is to define a bytecode for the constant type (ExpDesc's <code>String</code>, <code>Float</code>, etc.), while other types are first discharged to the stack and converted to <code>Local</code> type. Although the constant type is actually not a specific type (including multiple types such as <code>String</code>, <code>Float</code>), but the processing method is the same, through the <code>add_const()</code> function to add to the constant table, and use the constant table Index to represent, so when dealing with assignment statements, it can be seen as a type. Thus, our rvalue expressions are simplified to two types: constants and <code>Local</code> variables on the stack! In the official implementation of Lua, the <code>SETTABUP</code> bytecode of global variable assignment uses 1 bit to indicate whether the source expression is a constant or a variable on the stack. The generation of our bytecode is inconvenient to precisely manipulate bits, so a new bytecode <code>SetGlobalConst</code> is added to represent constants.</p>
<p>Why does the official Lua implementation treat constants specially, but not optimize other types (such as global variables, UpValue, table indexes, etc.)? There are two reasons for my personal guess:</p>
<ul>
<li>
<p>If a global variable or UpValue or table index is accessed so frequently that it is necessary to optimize, then you can simply create a local variable to optimize, such as <code>local print = print</code>. For constants, it is inappropriate to assign values to local variables in many cases. For example, changing an assignment statement <code>g = 100</code> to <code>local h = 100; g = a</code> seems awkward and unnecessary.</p>
</li>
<li>
<p>Accessing global variables is based on the variable name table lookup, which is a relatively time-consuming operation, and the cost of adding a bytecode is not obvious in comparison. Access to other types is similar. The access constant is directly referenced through the index, and the cost of adding a bytecode is relatively high.</p>
</li>
</ul>
<p>So far, the assignment of global variables has been introduced, and the assignment of table indexes (that is, the write operation of the table) is similar. For the three types <code>Index</code>, <code>IndexField</code> and <code>IndexInt</code>, we define <code>SetTable</code>, <code>SetField</code>, <code>SetInt</code>, <code>SetTableConst</code>, <code>SetFieldConst</code>, <code>SetIntConst</code> 6 bytecodes.</p>
<p>Finally, the code for assignment is as follows:</p>
<pre><code class="language-rust  ignore">    // process assignment: var = value
    fn assign_var(&amp;mut self, var: ExpDesc, value: ExpDesc) {
        if let ExpDesc::Local(i) = var {
            // self.sp will be set to i+1 in self.discharge(), which is
            // NOT expected, but it's ok because self.sp will not be used
            // before next statement.
            self.discharge(i, value);
        } else {
            match self.discharge_const(value) {
                ConstStack::Const(i) =&gt; self.assign_from_const(var, i),
                ConstStack::Stack(i) =&gt; self.assign_from_stack(var, i),
            }
        }
    }

    fn assign_from_stack(&amp;mut self, var: ExpDesc, value: usize) {
        let code = match var {
            ExpDesc::Local(i) =&gt; ByteCode::Move(i as u8, value as u8),
            ExpDesc::Global(name) =&gt; ByteCode::SetGlobal(name as u8, value as u8),
            ExpDesc::Index(t, key) =&gt; ByteCode::SetTable(t as u8, key as u8, value as u8),
            ExpDesc::IndexField(t, key) =&gt; ByteCode::SetField(t as u8, key as u8, value as u8),
            ExpDesc::IndexInt(t, key) =&gt; ByteCode::SetInt(t as u8, key, value as u8),
            _ =&gt; panic!(&quot;assign from stack&quot;),
        };
        self.byte_codes.push(code);
    }

    fn assign_from_const(&amp;mut self, var: ExpDesc, value: usize) {
        let code = match var {
            ExpDesc::Global(name) =&gt; ByteCode::SetGlobalConst(name as u8, value as u8),
            ExpDesc::Index(t, key) =&gt; ByteCode::SetTableConst(t as u8, key as u8, value as u8),
            ExpDesc::IndexField(t, key) =&gt; ByteCode::SetFieldConst(t as u8, key as u8, value as u8),
            ExpDesc::IndexInt(t, key) =&gt; ByteCode::SetIntConst(t as u8, key, value as u8),
            _ =&gt; panic!(&quot;assign from const&quot;),
        };
        self.byte_codes.push(code);
    }</code></pre>
<p>So far, according to the BNF re-assignment statement, it naturally supports the read and write operations of the table.</p>
<h2 id="assignment-and-function-call-statement"><a class="header" href="#assignment-and-function-call-statement">Assignment and Function Call statement</a></h2>
<p>Now look back at the last of the three questions raised at the beginning of this section, that is, how to distinguish between assignment statements and function call statements during syntax analysis.</p>
<p>Let’s start with the BNF representation of the assignment statement:</p>
<pre><code>varlist '=' explist
varlist ::= var {‘,’ var}
var ::= Name | prefixexp '[' exp ']' | prefixexp '.' Name
</code></pre>
<p>The beginning of the statement is <code>varlist</code>, after expansion is the variable <code>var</code>, and then it is <code>Name</code> and <code>prefixexp</code>. <code>Name</code> corresponds to <code>Token::Name</code>, but <code>prefixexp</code> still needs to be expanded. Here is its definition:</p>
<pre><code>prefixexp ::= var | functioncall | '(' exp ')'
functioncall ::= prefixexp args | prefixexp ':' Name args
</code></pre>
<p>Among them, the first <code>var</code> returns to the beginning of the assignment statement just now, and the circular reference is ignored. The last one starts with <code>(</code>, which is also very simple. After the <code>functioncall</code> in the middle is expanded, it also starts with <code>prefixexp</code>, which is also a circular reference, but this time it cannot be ignored, because <code>functioncall</code> itself is also a complete statement, that is, if a A statement starts with <code>prefixexp</code>, which may be an assignment statement or a function call statement. How to distinguish between these two statements? As explained in the previous section, the left value of an assignment statement can only be a variable or a table index. types, and function calls cannot be used as lvalues. This is the key to the distinction!</p>
<p>In summary, the final parsing logic is: if it starts with <code>Name</code> or <code>(</code>, parse it according to <code>prefixexp</code>, and judge the parsing result:</p>
<ul>
<li>If it is a function call, it is considered a complete <code>functioncall</code> statement;</li>
<li>Otherwise, it is considered as an assignment statement, and the result of this parsing is only the first <code>var</code> of the assignment statement.</li>
</ul>
<p>To do this, add a function call type <code>Call</code> in ExpDesc and let the function call statement <code>args()</code> return. In the <code>load()</code> function, this part of the code is as follows:</p>
<pre><code class="language-rust  ignore">            match self.lex.next() {
                Token::SemiColon =&gt; (),
                t@Token::Name(_) | t@Token::ParL =&gt; {
                    // functioncall and var-assignment both begin with
                    // `prefixexp` which begins with `Name` or `(`.
                    let desc = self.prefixexp(t);
                    if desc == ExpDesc::Call {
                        // prefixexp() matches the whole functioncall
                        // statement, so nothing more to do
                    } else {
                        // prefixexp() matches only the first variable, so we
                        // continue the statement
                        self.assignment(desc);
                    }
                }</code></pre>
<h2 id="summary-3"><a class="header" href="#summary-3">Summary</a></h2>
<p>In this section, the parsing of the assignment statement is re-analyzed through BNF, and finally the read and write operations of the table are realized. In addition, the statement of local variable definition also needs to be rewritten according to BNF, which is relatively simple, and the introduction is omitted here.</p>
<p>So far, this chapter has completed the basic operations of table definition, construction, reading and writing; and introduce the very important ExpDesc concept and BNF rules.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="arithmetic-operations"><a class="header" href="#arithmetic-operations">Arithmetic Operations</a></h1>
<p>Supported operations are described in the <a href="https://www.lua.org/manual/5.4/manual.html#3.4.1">Lua Manual</a>. This chapter mainly discusses and implements arithmetic operations and bit operations, and also implements string concatenation operations and length operations by the way. These operations are handled in the same way. As for relational operations and logical operations, special processing needs to be done after conditional statements are introduced.</p>
<p>Simple unary operations are introduced first, then binary operations. Finally we discuss the floating-point conversions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unary-operation"><a class="header" href="#unary-operation">Unary Operation</a></h1>
<p>The syntax of unary operations in Lua:</p>
<pre><code>exp ::= nil | false | true | Numeral | LiteralString | '...' | functiondef |
prefixexp | tableconstructor | exp binop exp | unop exp
</code></pre>
<p>The unary operation is in the last term: <code>exp ::= unop exp</code>. That is, in the expression <code>exp</code>, unary operators can be preceded.</p>
<p>Lua supports 4 unary operators:</p>
<ul>
<li><code>-</code>, take the negative. This token is also a binary operator: subtraction.</li>
<li><code>not</code>, logical negation.</li>
<li><code>~</code>, bitwise inversion. This Token is also a binary operator: bitwise xor.</li>
<li><code>#</code>, take the length, used for strings and tables, etc.</li>
</ul>
<p>In the syntax analysis code, just add these 4 unary operators:</p>
<pre><code class="language-rust  ignore">     fn exp(&amp;mut self) -&gt; ExpDesc {
         match self. lex. next() {
             Token::Sub =&gt; self. unop_neg(),
             Token::Not =&gt; self. unop_not(),
             Token::BitNot =&gt; self. unop_bitnot(),
             Token::Len =&gt; self. unop_len(),
             // omit other exp branches</code></pre>
<p>The following takes negative <code>-</code> as an example, and the others are similar.</p>
<h2 id="negative"><a class="header" href="#negative">Negative</a></h2>
<p>It can be seen from the above BNF that the operand of the negation operation is also the expression <code>exp</code>, and the expression is represented by ExpDesc, so several types of ExpDesc are considered:</p>
<ul>
<li>
<p>Integers and floating-point numbers are directly negated, for example, <code>ExpDesc::Integer(10)</code> is directly converted to <code>ExpDesc::Integer(-10)</code>. That is to say, for <code>-10</code> in the source code, two tokens <code>Sub</code> and <code>Integer(10)</code> will be generated during the lexical analysis stage, and then converted into <code>-10</code> by the syntax analysis. There is no need to directly support negative numbers in lexical analysis, because there can also be the following situation <code>- -10</code>, that is, multiple consecutive negative operations. For this case, grammatical analysis is more suitable than lexical analysis.</p>
</li>
<li>
<p>Other constant types, such as strings, do not support negation, so a panic is reported.</p>
</li>
<li>
<p>Other types are evaluated when the virtual machine is running. Generate a new bytecode <code>Neg(u8, u8)</code>, and the two parameters are the destination and source operand addresses on the stack. Only 1 bytecode is added here. In contrast, the <a href="./ch02-00.variables.html">Read Global Variables</a> and <a href="./ch04-05.table_rw_and_bnf.html">Table Read</a> operations introduced in the previous chapters both set 3 for optimization Bytecode, three types of parameters are processed separately: variables on the stack, constants, and small integers. But for the negative operation here, the last two types (constants and small integers) have been processed in the above two cases, so we only need to add the bytecode <code>Neg(u8, u8)</code> to handle the first type type (variables on the stack). However, the binary operation in the next section cannot fully handle the constant type, so it is necessary to add 3 bytecodes for each operator like the table reading operation.</p>
</li>
</ul>
<p>According to the previous chapter <a href="./ch04-04.expdesc_rewrite.html">Introduction to ExpDesc</a>, for the last case, two steps are required to generate the bytecode: first, the <code>exp()</code> function returns the ExpDesc type, and then <code>discharge()</code> function generates bytecode based on ExpDesc. Currently, the existing type of ExpDesc cannot express a unary operation statement, and a new type UnaryOp is required. How is this new type defined?</p>
<p>From an execution point of view, unary operations are very similar to assignments between local variables. The latter is to copy a value on the stack to another location; the former is also, but an operation conversion is added during the copying process. Therefore, the ExpDesc type returned by the unary operation statement can refer to the local variable. For local variables, the expression <code>exp()</code> function returns the <code>ExpDesc::Local(usize)</code> type, and the associated usize type parameter is the position of the local variable on the stack. For the unary operation, the <code>ExpDesc::UnaryOp(fn(u8,u8)-&gt;ByteCode, usize)</code> type is added. Compared with the <code>ExpDesc::Local</code> type, an associated parameter is added, which is done during the copying process, operation. The parameter type of this operation is <code>fn(u8,u8)-&gt;ByteCode</code>. This method of passing the enum tag through the function type is described in <a href="./ch04-04.expdesc_rewrite.html#table_constructor">Use ExpDesc to rewrite the table structure</a>, and will not be repeated here. Also take the negative operation as an example to generate <code>ExpDesc::UnaryOp(ByteCode::Neg, i)</code>, where <code>i</code> is the stack address of the operand.</p>
<p>The specific parsing code is as follows:</p>
<pre><code class="language-rust  ignore">    fn unop_neg(&amp;mut self) -&gt; ExpDesc {
        match self.exp_unop() {
            ExpDesc::Integer(i) =&gt; ExpDesc::Integer(-i),
            ExpDesc::Float(f) =&gt; ExpDesc::Float(-f),
            ExpDesc::Nil | ExpDesc::Boolean(_) | ExpDesc::String(_) =&gt; panic!(&quot;invalid - operator&quot;),
            desc =&gt; ExpDesc::UnaryOp(ByteCode::Neg, self.discharge_top(desc))
        }
    }</code></pre>
<p>After generating the <code>ExpDesc::UnaryOp</code> type, generating bytecode from this type is simple:</p>
<pre><code class="language-rust  ignore">     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             ExpDesc::UnaryOp(op, i) =&gt; op(dst as u8, i as u8),</code></pre>
<p>So far, we have completed the unary operation of negation, and the other three unary operations are similar and omitted here.</p>
<p>In addition, since the unary operation statement is defined as: <code>exp ::= unop exp</code>, the operand is also an expression statement, here is a recursive reference, so it naturally supports multiple consecutive unary operations, such as <code>not - ~123</code> statement .</p>
<p>The above is the syntax analysis part; and the virtual machine execution part needs to add the processing of these 4 new bytecodes. It is also very simple and omitted here.</p>
<p>The next section introduces binary operations, which are much more complicated.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="binary-operations"><a class="header" href="#binary-operations">Binary operations</a></h1>
<p>Compared with the unary operation in the previous section, although the binary operation only has one more operand, it introduces many problems, mainly including BNF left recursion, priority, operand type, and evaluation order, etc.</p>
<h2 id="bnf-left-recursive"><a class="header" href="#bnf-left-recursive">BNF Left Recursive</a></h2>
<p>The complete syntax of the binary operation statement in Lua is as follows:</p>
<pre><code>exp ::= nil | false | true | Numeral | LiteralString | '...' | functiondef |
prefixexp | tableconstructor | exp binop exp | unop exp
</code></pre>
<p>For simplicity, the other parts are simplified to <code>OTHERS</code>, then we get:</p>
<pre><code>exp ::= exp binop exp | OTHERS
</code></pre>
<p>It is a left recursion rule, we need to <a href="./ch04-05.table_rw_and_bnf.html#eliminate-left-recursion">eliminate left recursion</a> according to the method introduced before, and get:</p>
<pre><code>exp ::= OTHERS A'
A' := binop exp A' | Epsilon
</code></pre>
<p>The previous <code>exp()</code> function only implemented the <code>OTHERS</code> part of the first line above, and now we need to add the <code>A'</code> part of the second line, which is also a recursive reference, which is implemented using a loop. Modify the <code>exp()</code> function structure as follows:</p>
<pre><code class="language-rust  ignore">     fn exp(&amp;mut self) -&gt; ExpDesc {
         // OTHERS
         let mut desc = match self. lex. next() {
             // The original various OTHERS type processing is omitted here
         };

         // A' := binop exp A' | Epsilon
         while is_binop(self. lex. peek()) {
             let binop = self.lex.next(); // operator
             let right_desc = self.exp(); // second operand
             desc = self. process_binop(binop, desc, right_desc);
         }
         desc
     }</code></pre>
<p>Among them, the second operand right_desc is also recursively called <code>exp()</code> function to read, which leads to a problem: priority.</p>
<h2 id="priority"><a class="header" href="#priority">Priority</a></h2>
<p>In the unary operation statement in the previous section, the <code>exp()</code> function is also called recursively to read the operand, but because there is only one operand, so no need for priority. Or we can say that all unary operators have the same priority. And unary operators are right associative. For example, the following two examples of consecutive unary operations are executed in order from right to left, regardless of the specific operator:</p>
<ul>
<li><code>~ -10</code>, take negative first, then invert bit by bit,</li>
<li><code>- ~10</code>, first bitwise invert, then negative.</li>
</ul>
<p>But for the binary operation statement, it is necessary to consider the priority. For example, the following two statements:</p>
<ul>
<li><code>a + b - c</code>, perform the previous addition first, and then perform the subsequent subtraction,</li>
<li><code>a + b * c</code>, perform the subsequent multiplication first, and then perform the previous addition.</li>
</ul>
<p>Corresponding to the <code>exp()</code> function code above, the <code>OTHERS</code> part at the beginning reads the first operand <code>a</code>; then reads the operator <code>+</code> in the <code>while</code> loop; and then calls the <code>exp()</code> function recursively to read the right operand, so it needs to be calculated at this time. Also take the above two sentences as an example:</p>
<ul>
<li><code>a + b - c</code>, end after reading <code>b</code> and use it as the right operand; then perform addition <code>a + b</code>; and then loop through the following <code>- c</code> part again;</li>
<li><code>a + b * c</code>, after reading <code>b</code>, continue down, read and execute the entire <code>b * c</code> and use the execution result as the right operand; then perform addition; and end the loop.</li>
</ul>
<pre><code>     -             +
   /   \         /   \
  +     c       a     *
/   \               /   \
a   b               b   c
</code></pre>
<p>So in syntax analysis, how to judge which of the above situations is the case? After reading <code>b</code>, should we stop parsing and calculate addition first, or continue parsing? It depends on the <em>priorities</em> of the next operator and the current operator:</p>
<ul>
<li>When the priority of the next operator is <em>not greater than</em> the current operator, it is the first case, stop parsing and complete the current operation first;</li>
<li>When the priority of the next operator is <em>greater than</em> the current operator, it is the second case and needs to continue parsing.</li>
</ul>
<p>For this, refer to the list of all <a href="https://www.lua.org/manual/5.4/manual.html#3.4.8">operator precedence</a> in the Lua language:</p>
<pre><code>or
and
&lt;     &gt;     &lt;=    &gt;=    ~=    ==
|
~
&amp;
&lt;&lt;    &gt;&gt;
..
+     -
*     /     //    %
unary operators (not   #     -     ~)
^
</code></pre>
<p>From top to bottom, the priority becomes higher. The connectors <code>..</code> and exponentiation <code>^</code> are right associative, and other operators are left associative. In the judging rules listed above, parsing is stopped (instead of continuing parsing) for cases of equal priority, so the default is left associative. Therefore, special treatment is required for two right-associated operators, that is, different priorities are defined for them to the left and to the right, and the one to the left is higher, which will become a right-association.</p>
<p>In summary, define the priority function:</p>
<pre><code class="language-rust  ignore">fn binop_pri(binop: &amp;Token) -&gt; (i32, i32) {
    match binop {
        Token::Pow =&gt; (14, 13), // right associative
        Token::Mul | Token::Mod | Token::Div | Token::Idiv =&gt; (11, 11),
        Token::Add | Token::Sub =&gt; (10, 10),
        Token::Concat =&gt; (9, 8), // right associative
        Token::ShiftL | Token::ShiftR =&gt; (7, 7),
        Token::BitAnd =&gt; (6, 6),
        Token::BitNot =&gt; (5, 5),
        Token::BitOr =&gt; (4, 4),
        Token::Equal | Token::NotEq | Token::Less | Token::Greater | Token::LesEq | Token::GreEq =&gt; (3, 3),
        Token::And =&gt; (2, 2),
        Token::Or =&gt; (1, 1),
        _ =&gt; (-1, -1)
    }
}</code></pre>
<p>For Tokens that are not binary operators, <code>-1</code> is returned, which is the lowest priority, and parsing can be stopped no matter what the current operator is. According to Rust's customary practice, this function should return <code>Option&lt;(i32, i32)&gt;</code> type, and then return <code>None</code> for tokens that are not binary operators. But it is simpler to return <code>-1</code> at the calling place, and there is no need to process Option one more time.</p>
<p>This function appears to be a property of the <code>Token</code> type, so it seems to be a suitable method defined as <code>Token</code>. But <code>Token</code> type is defined in <code>lex.rs</code>; while priority is a concept of syntax, it should be implemented in <code>parse.rs</code>. The Rust language does not allow methods to be added to a type's non-defining file. So the above function is defined as an ordinary function in the <code>parse.rs</code> file (rather than the method of <code>ParseProto</code> like other functions).</p>
<p>Now, according to the priority, modify the <code>exp()</code> function again:</p>
<pre><code class="language-rust  ignore">     fn exp(&amp;mut self) -&gt; ExpDesc {
         self.exp_limit(0)
     }
     fn exp_limit(&amp;mut self, limit: i32) -&gt; ExpDesc {
         // OTHERS
         let mut desc = match self. lex. next() {
             // The original various OTHERS type processing is omitted here
         };

         // A' := binop exp A' | Epsilon
         loop {
             let (left_pri, right_pri) = binop_pri(self. lex. peek());
             if left_pri &lt;= limit {
                 return desc; // stop parsing
             }

             // continue parsing
             let binop = self. lex. next();
             let right_desc = self.exp_limit(right_pri);
             desc = self. process_binop(binop, desc, right_desc);
         }
     }</code></pre>
<p>First, add a <code>limit</code> parameter to <code>exp()</code>, as the priority of the current operator, and limit the subsequent parsing range. However, this parameter belongs to the internal concept of the statement, and the caller of this function does not need to know this parameter; therefore, the actual processing function <code>exp_limit()</code> is added, and <code>exp()</code> is turned into an outer encapsulation function, using <code>limit=0</code> to call the former. The reason why the initial call uses <code>limit=0</code> is that <code>0</code> is less than any binary operator priority defined in the <code>binop_pri()</code> function, so the first operator will continue to be parsed (rather than return to exit the loop ); but <code>0</code> is greater than the priority <code>-1</code> of the non-operator, so if it is followed by the non-operator, it will also exit normally.</p>
<p>The above parsing code combines loops and recursive calls, which is very difficult for those who are not familiar with the algorithm (like me), and it is difficult to write the complete code directly. However, according to the BNF specification after eliminating left recursion, the loop and recursion can be completed, and then the function can be easily completed according to the priority and conditional exit.</p>
<p>In addition, it should be noted that unary operators are also listed in the operator precedence table above, so when parsing unary operation statements in the previous section, the <code>exp()</code> function cannot be used when reading the operand expression (initial Priority 0), instead specify an initial priority of 12:</p>
<pre><code class="language-rust  ignore">    fn exp_unop(&amp;mut self) -&gt; ExpDesc {
        self.exp_limit(12) // 12 is all unary operators' priority
    }</code></pre>
<p>The priority of the exponentiation operation <code>^</code> is actually higher than that of the unary operator, so the execution order of the statement <code>-a^10</code> is: first exponentiation, and then negation.</p>
<h2 id="evaluation-order"><a class="header" href="#evaluation-order">Evaluation Order</a></h2>
<p>There is a very subtle bug in the parsing code above, which concerns the order in which the operands are evaluated.</p>
<p>The processing of each operand requires 2 steps: first call the <code>exp()</code> function to read the operand and return ExpDesc, and then call the <code>discharge()</code> function to discharge the operand to the stack for bytecode operation. The binary operation has 2 operands, so a total of 4 steps are required. Now discuss the sequence of these 4 steps.</p>
<p>According to the processing logic of the binary operation in the <code>exp()</code> function of the current version:</p>
<ul>
<li>read the first operand first, <code>desc</code>;</li>
<li>After judging that it is a binary operation, call <code>exp_limit()</code> recursively, and read the second operand, <code>right_desc</code>;</li>
<li>Then discharge the ExpDesc of the above two operands to the stack in the <code>process_binop()</code> function.</li>
</ul>
<p>Simplified is:</p>
<ul>
<li>parse the first operand;</li>
<li>parse the second operand;</li>
<li>discharge the first operand;</li>
<li>discharge the second operand.</li>
</ul>
<p>During the parsing and discharge stages, bytecode may be generated. So in this order, the bytecodes related to the two operands may be interspersed. Like the following example:</p>
<pre><code class="language-lua">local a = -g1 + -g2
</code></pre>
<p>Ignoring the previous local variable definition, and ignoring the operation of undefined global variables will throw an exception. Here, the focus is only on the subsequent addition statement. Generates the following bytecode sequence with the current version of the interpreter:</p>
<pre><code>constants: ['g1', 'g2']
byte_codes:
   GetGlobal(0, 0) # parse the first operand
   GetGlobal(1, 1) # parse the second operand
   Neg(2, 0)       # discharge the first operand
   Neg(3, 1)       # discharge the second operand
   Add(0, 2, 3)
</code></pre>
<p>It can be seen that the bytecodes related to the two operands are interspersed here. In this example, interleaving is fine. But in some cases, parsing the second operand will affect the evaluation of the first operand, and interleaving will cause problems at this time. Like the following example:</p>
<pre><code class="language-lua">local t = { k = 1 }
local function f(t) t.k = 100; return 2 end -- modify the value of t.k
local r = t.k + f(t)*3
</code></pre>
<p>For the last sentence, we expected <code>1 + 2*3</code>, but if we follow the current order of evaluation:</p>
<ol>
<li>First parse the left operand <code>t.k</code> to generate <code>ExpDesc::IndexField</code>, but not discharge;</li>
<li>Then parse the right operand <code>f(t)*2</code>, and execute f(t) during the parsing process, thus modifying the value of <code>t.k</code> to <code>100</code>;</li>
<li>Then discharge the left operationNumber, generate <code>GetField</code> bytecode, but at this time <code>t.k</code> has been modified by the previous step! Here comes the error. What is actually executed is <code>100 + 2*3</code>.</li>
</ol>
<p>In summary, we need to ensure that the bytecodes of the two operands cannot be interspersed! Then modify the <code>exp_limit()</code> function as follows:</p>
<pre><code class="language-rust  ignore">     fn exp_limit(&amp;mut self, limit: i32) -&gt; ExpDesc {
         // The original various OTHERS type processing is omitted here

         loop {
             // Omit the processing of judging the priority

             // discharge the first operand! ! !
             if !matches!(desc, ExpDesc::Integer(_) | ExpDesc::Float(_) | ExpDesc::String(_)) {
                 desc = ExpDesc::Local(self. discharge_top(desc));
             }

             // continue parsing
             let binop = self. lex. next();
             let right_desc = self.exp_limit(right_pri); // parse the second operand
             desc = self. process_binop(binop, desc, right_desc);
         }
     }</code></pre>
<p>Discharge the first operand onto the stack before parsing the second operand. However, this is not necessary for constant types, because:</p>
<ul>
<li>the constant will not be affected by the second operand as in the above example;</li>
<li>Constants are also to be directly folded in subsequent attempts.</li>
</ul>
<p>So far, the transformation of <code>exp_limit()</code> function for binary operation syntax analysis has been completed. As for the specific processing <code>process_binop()</code> function of the binary operation, it is introduced below.</p>
<h2 id="bytecode-1"><a class="header" href="#bytecode-1">Bytecode</a></h2>
<p>The unary operation introduced in the previous section has only one operand, which can be divided into two cases: constants and variables. Constants are evaluated directly, and variables generate bytecodes. So each unary operation has only one bytecode. Binary operations are more complicated because they involve 2 operands.</p>
<p>First of all, although binary operators are mostly numerical calculations, because Lua's metatable is similar to operator overloading, other types of constants (such as strings, bools, etc.) may be legal operands. When parsing unary operations, these types of constants will directly report an error, but for binary operations, it needs to be executed at the execution stage to determine whether it is legal.</p>
<p>Secondly, if both operands are constants of numeric type (integer and floating point), then the result can be directly calculated during syntax analysis, which is called constant folding.</p>
<p>Otherwise, bytecode is generated and executed by the virtual machine. Similar to <a href="./ch02-00.variables.html">Read Global Variables</a> and <a href="./ch04-05.table_rw_and_bnf.html">Read Table</a> operations that have been supported before, each binary operator is also set to 3 types of right operands: variables on the stack, constants, and small integers.</p>
<p>The left operand is uniformly discharged to the stack, because it is rare for the left operand to be a constant. If we also add corresponding bytecodes for constants and small integer types, such as <code>10-a</code>, then there are too many bytecode types.</p>
<p>Finally, for addition and multiplication that satisfy the commutative law, if the left operation is a constant, then it can be exchanged. For example, <code>10+a</code> can be converted to <code>a+10</code> first. Since the right operand <code>10</code> is a small integer, it can be use <code>AddInt</code> bytecode then.</p>
<h2 id="expdesc"><a class="header" href="#expdesc">ExpDesc</a></h2>
<p>Similar to the new ExpDesc type introduced by the unary operation introduced in the previous section, the binary operation also needs a new type because it has one more operand:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     UnaryOp(fn(u8,u8)-&gt;ByteCode, usize), // (opcode, operand)
     BinaryOp(fn(u8,u8,u8)-&gt;ByteCode, usize, usize), // (opcode, left-operand, right-operand)</code></pre>
<h2 id="syntax-analysis-4"><a class="header" href="#syntax-analysis-4">Syntax analysis</a></h2>
<p>So far, the basic requirements of the binary operation statement have been introduced. Let's look at the code implementation, that is, the <code>process_binop()</code> function called in the <code>exp()</code> function:</p>
<pre><code class="language-rust  ignore">     fn process_binop(&amp;mut self, binop: Token, left: ExpDesc, right: ExpDesc) -&gt; ExpDesc {
         if let Some(r) = fold_const(&amp;binop, &amp;left, &amp;right) { // constant fold
             return r;
         }

         match binop {
             Token::Add =&gt; self.do_binop(left, right, ByteCode::Add, ByteCode::AddInt, ByteCode::AddConst),
             Token::Sub =&gt; self.do_binop(left, right, ByteCode::Sub, ByteCode::SubInt, ByteCode::SubConst),
             Token::Mul =&gt; self.do_binop(left, right, ByteCode::Mul, ByteCode::MulInt, ByteCode::MulConst),
             // omit more types
         }
     }</code></pre>
<p>Try constant folding first. This part of the function is introduced in the next section because it involves the processing of integer and floating point types. Because the two operands are not necessarily constants, they may not be able to be folded. If the fold is not successful, then the operator and the two operands will be used later, so the <code>fold_const()</code> function here can only pass in references.</p>
<p>If it is not a constant and cannot be folded, then call the <code>do_binop()</code> function to return ExpDesc. Here, the enum tag is used as a function, which has been introduced <a href="./ch04-04.expdesc_rewrite.html#table_constructor">before</a>, and will not be introduced here.</p>
<p>Let's look at the <code>do_binop()</code> function:</p>
<pre><code class="language-rust  ignore">    fn do_binop(&amp;mut self, mut left: ExpDesc, mut right: ExpDesc, opr: fn(u8,u8,u8)-&gt;ByteCode,
            opi: fn(u8,u8,u8)-&gt;ByteCode, opk: fn(u8,u8,u8)-&gt;ByteCode) -&gt; ExpDesc {

        if opr == ByteCode::Add || opr == ByteCode::Mul { // commutative
            if matches!(left, ExpDesc::Integer(_) | ExpDesc::Float(_)) {
                // swap the left-const-operand to right, in order to use opi/opk
                (left, right) = (right, left);
            }
        }

        let left = self.discharge_top(left);

        let (op, right) = match right {
            ExpDesc::Integer(i) =&gt;
                if let Ok(i) = u8::try_from(i) {
                    (opi, i as usize)
                } else {
                    (opk, self.add_const(i))
                }
            ExpDesc::Float(f) =&gt; (opk, self.add_const(f)),
            _ =&gt; (opr, self.discharge_top(right)),
        };

        ExpDesc::BinaryOp(op, left, right)
    }</code></pre>
<p>First, judge if it is addition or multiplication, and the left operand is a numeric constant, then exchange the two operands, so that the bytecode of <code>xxCoust</code> or <code>xxInt</code> can be generated later.</p>
<p>Then, discharge the left operand onto the stack;</p>
<p>Then, judge whether the type of the right operand is a numeric constant, or discharge it to the stack.</p>
<p>Finally, <code>ExpDesc::BinaryOp</code> is generated.</p>
<p>So far, the grammatical analysis of the binary operation statement is basically completed.</p>
<h2 id="integer-and-float"><a class="header" href="#integer-and-float">Integer and Float</a></h2>
<p>So far, we have introduced the general analysis process of binary operations, but there is still a detail, that is, the different processing rules for integer and floating point types. Since there is a lot of content in this aspect, and it is relatively independent from the above-mentioned main analysis process, it will be introduced separately in the next section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="integer-and-float-1"><a class="header" href="#integer-and-float-1">Integer and Float</a></h1>
<p>In versions before Lua 5.3, only one type of number is supported, which is floating-point by default. You can use integers by modifying the source code of the Lua interpreter. I understand that this is because Lua was originally used as a configuration language, and most of its users are not programmers, and it does not distinguish between integers and floating-point numbers. For example, <code>5</code> and <code>5.0</code> are two identical numbers. Later, as the use of Lua expanded, and the need to support integers became stronger (such as bit operations), finally in Lua version 5.3, integers and floating-point numbers were distinguished. This also brings some complexity. The main binary operators are divided into the following three types of <a href="https://www.lua.org/manual/5.4/manual.html#3.4.1">processing rules</a> kind:</p>
<ul>
<li>Supports integer and floating point numbers, including <code>+</code>, <code>-</code>, <code>*</code>, <code>//</code> and <code>%</code>. If both operands are integers, the result is also an integer; otherwise (both operands have at least one floating-point number) the result is a floating-point number.</li>
<li>Only floats are supported, including <code>/</code> and <code>^</code>. Regardless of the type of the operands, the result is a floating point number. For example <code>5/2</code>, although both operands are integers, they will be converted to floating point numbers, and then the result is <code>2.5</code>.</li>
<li>Only integers are supported, including 5 bit operations. The operands must be integers, and the result is also an integer.</li>
</ul>
<p>The processing of the above three types will be reflected in the constant folding <code>fold_const()</code> function of syntax analysis and when the virtual machine executes. The code is cumbersome and omitted here.</p>
<h2 id="type-conversion-1"><a class="header" href="#type-conversion-1">Type Conversion</a></h2>
<p>Lua also defines the above <a href="https://www.lua.org/manual/5.4/manual.html#3.4.3">rules of type conversion</a> (mainly the rules in the case of incomplete conversion):</p>
<ul>
<li>Integer to Float: If the full conversion is not possible, the closest floating point number is used. i.e. the conversion will not fail, only precision will be lost.</li>
<li>Float to integer: If the conversion cannot be completed, an exception will be thrown.</li>
</ul>
<p>In the Rust language, the rules for converting integers to floating-points are the same, but converting floating-points to integers is <a href="https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/book/first-edition/casting-between-types.html#numeric-casts">different</a>. This is considered <a href="https://github.com/rust-lang/rust/issues/10184">a bug and will be fixed</a>. Before the fix, we can only do this integrity check ourselves, that is, throw an exception if the conversion fails. For this we implement the <code>ftoi()</code> function:</p>
<pre><code class="language-rust  ignore">pub fn ftoi(f: f64) -&gt; Option&lt;i64&gt; {
     let i = f as i64;
     if i as f64 != f {
         none
     } else {
         Some(i)
     }
}</code></pre>
<p>You can directly use <code>as</code> when converting an integer to a floating-point type, and you need to use this function when converting a floating-point type to an integer.</p>
<p>This conversion will be involved in the syntax analysis and virtual machine execution stages, so create a new <code>utils.rs</code> file to put these general functions.</p>
<h2 id="compare"><a class="header" href="#compare">Compare</a></h2>
<p>In the Lua language, in most cases, the distinction between integers and floating-point numbers is avoided as much as possible. The most direct example is that the result of the statement <code>5 == 5.0</code> is true, so <code>Value::Integer(5)</code> and <code>Value::Float(5.0)</code> are equal in the Lua language. Another point is that if these two values are used as the key of the table, they are also considered to be the same key. To this end, we have to modify the two trait implementations of Value before.</p>
<p>The first is the <code>PartialEq</code> trait that compares for equality:</p>
<pre><code class="language-rust  ignore">impl PartialEq for Value {
     fn eq(&amp;self, other: &amp;Self) -&gt; bool {
         match (self, other) {
             (Value::Integer(i), Value::Float(f)) |
             (Value::Float(f), Value::Integer(i)) =&gt; *i as f64 == *f &amp;&amp; *i == *f as i64,</code></pre>
<p>Then there is the <code>Hash</code> trait:</p>
<pre><code class="language-rust  ignore">impl Hash for Value {
     fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) {
         match self {
             Value::Float(f) =&gt;
                 if let Some(i) = ftoi(*f) {
                     i.hash(state)
                 } else {
                     unsafe {
                         mem::transmute::&lt;f64, i64&gt;(*f).hash(state)
                     }
                 }</code></pre>
<p>However, there is still one place where the type needs to be distinguished, that is, when adding a constant to the constant table during syntax analysis, when querying whether the constant already exists. To do this, implement a type-sensitive comparison method:</p>
<pre><code class="language-rust  ignore">impl Value {
     pub fn same(&amp;self, other: &amp;Self) -&gt; bool {
         // eliminate Integer and Float with same number value
         mem::discriminant(self) == mem::discriminant(other) &amp;&amp; self == other
     }
}</code></pre>
<h2 id="test-5"><a class="header" href="#test-5">Test</a></h2>
<p>At this point, the syntax analysis of the binary operation statement is finally completed. The virtual machine execution part is very simple and is skipped here. You can test the Lua code as follows:</p>
<pre><code class="language-lua">g = 10
local a,b,c = 1.1, 2.0, 100

print(100+g) -- commutative, AddInt
print(a-1)
print(100/c) -- result is float
print(100&gt;&gt;b) -- 2.0 will be convert to int 2
print(100&gt;&gt;a) -- panic
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="control-structure"><a class="header" href="#control-structure">Control Structure</a></h1>
<p>This chapter introduces the control structure. The most obvious change is that since now, the virtual machine no longer only executes sequentially, but jumps. And because the parsing of the syntax block is called recursively during syntax analysis, the local variable scope needs to be dealt with, which makes the meaning and boundary of the block clearer.</p>
<p>Several control structures in Lua language are very common, similar to other languages, nothing special. Next, the first section introduces the if branch of the simplest <code>if</code> statement, and introduces conditional jumps and block processing. Then introduce other control structures in turn, most of which are implemented through conditional jumps (Test bytecode) and unconditional jumps (Jump bytecode). Except that the numeric-for statement uses 2 special bytecodes for performance considerations due to its complex semantics. The generic-for statement needs to use functions, so it will be introduced after introducing functions in subsequent chapters.</p>
<p>In addition, this chapter also discusses and attempts to introduce the continue statement that does not exist in Lua, and guarantees backward compatibility.</p>
<p>In addition, although this chapter fully implements each control structure functionally, the implementation here will be optimized after the introduction of relational and logical operations in the next chapter.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="if-statement"><a class="header" href="#if-statement"><code>if</code> statement</a></h1>
<p>The biggest difference between the conditional judgment statement and the previously implemented statement is that the bytecode is no longer executed sequentially, and jumps may occur. To this end, we add a new bytecode <code>Test</code>, associated with 2 parameters:</p>
<ul>
<li>The first parameter, <code>u8</code> type, determines the location of the condition on the stack;</li>
<li>The second parameter, <code>u16</code> type, the number of bytecodes to jump forward.</li>
</ul>
<p>The semantics of this bytecode is: if the statement represented by the first parameter is false, then jump forward to the bytecode of the number specified by the second parameter. The control structure diagram is as follows:</p>
<pre><code>+-------------------+
| if condition then |---\ skip the block if $condition is false
+-------------------+   |
                        |
    block               |
                        |
+-----+                 |
| end |                 |
+-----+                 |
&lt;-----------------------/
</code></pre>
<p>The definition of Test bytecode is as follows:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     // condition structures
     Test(u8, u16),</code></pre>
<p>The second parameter is the number of bytecodes to jump to, that is, the relative position. If absolute positions are used, the code to parse and execute is slightly simpler, but less expressive. The range of 16bit is 65536. If absolute position is used, the code beyond 65536 in a function cannot use jump bytecode. And if you use the relative position, then it supports jumping within the range of 65536 of the bytecode itself, and you can support very long functions. So we use relative positions. This also introduces a problem that has been ignored, which is the range of parameters in the bytecode. For example, the stack index parameters are all of the <code>u8</code> type, so if there are more than 256 local variables in a function, it will overflow and cause bugs. In the follow-up, the range of parameters needs to be specially dealt with.</p>
<p>According to the above control structure diagram, the syntax analysis code for completing the if statement is as follows:</p>
<pre><code class="language-rust  ignore">     fn if_stat(&amp;mut self) {
         let icond = self.exp_discharge_top(); // read condition statement
         self.lex.expect(Token::Then); // `then` keyword

         // generate `Test` placeholder, and the 2 parameters will be added later
         self.byte_codes.push(ByteCode::Test(0, 0));
         let itest = self.byte_codes.len() - 1;

         // parse the block! And it is expected to return the `end` keyword,
         // does not support `elseif` and `else` branches temporarily.
         assert_eq!(self. block(), Token::End);

         // Fix Test bytecode parameter.
         // `iend` is the current position of the bytecode sequence,
         // `itest` is the position of the Test bytecode, and the difference
         // between the two is the number of bytecodes that need to be jumped.
         let iend = self.byte_codes.len() - 1;
         self.byte_codes[itest] = ByteCode::Test(icond as u8, (iend - itest) as u16);
     }</code></pre>
<p>The code flow has been explained line by line in the comments. What needs to be explained in detail here is the <code>block()</code> function called recursively.</p>
<h2 id="end-of-block"><a class="header" href="#end-of-block">End of Block</a></h2>
<p>The original <code>block()</code> function is actually the entry point of the entire syntax analysis, which is executed only once (without recursive calls), and reads to the end of the source code <code>Token::Eos</code> as the end:</p>
<pre><code class="language-rust  ignore">     fn block(&amp;mut self) {
         loop {
             match self. lex. next() {
                 // Other statement parsing is omitted here
                 Token::Eos =&gt; break, // Eos exits
             }
         }
     }</code></pre>
<p>The expected end of the code block in the <code>if</code> statement to be supported is the keyword <code>end</code>; other keywords such as <code>elseif</code> and <code>else</code> will be included in the future. The end of the code block is not just <code>Token::Eos</code>, we need to modify the <code>block()</code> function, and consider the Token that is not the beginning of a legal statement (such as <code>Eos</code>, keyword <code>end</code>, etc.) as a block End, and it is up to the caller to determine whether it is the expected end. There are 2 ways to modify the specific code:</p>
<ul>
<li>
<p>Use <code>lex.peek()</code> instead of <code>lex.next()</code> in the above code. If the Token you see is not the beginning of a legal statement, exit the loop. At this time, the Token has not been read by consumption. The external caller then calls <code>lex.next()</code> to read the Token for judgment. If this is done, then all the current statement processing codes must add a <code>lex.next()</code> at the very beginning to skip the seen Token, which is more verbose. For example, in the <code>if_stat()</code> function in the previous paragraph, it is necessary to use <code>lex.next()</code> to skip the keyword <code>if</code>.</p>
</li>
<li>
<p>Still use <code>lex.next()</code>, for the Token that is not read at the beginning of a legal statement, it will be returned to the caller as the function return value. We adopt this method, the code is as follows:</p>
</li>
</ul>
<pre><code class="language-rust  ignore">     fn block(&amp;mut self) -&gt; Token {
         loop {
             match self. lex. next() {
                 // Other statement parsing is omitted here
                 t =&gt; break t, // return t
             }
         }
     }</code></pre>
<p>So in the <code>if_stat()</code> function above, it is necessary to judge the return value of <code>block()</code> as <code>Token::End</code>:</p>
<pre><code class="language-rust  ignore">         // parse syntax block! And it is expected to return the end keyword, temporarily does not support elseif and else branches
         assert_eq!(self. block(), Token::End);</code></pre>
<p>The original syntax analysis entry function <code>chunk()</code> also needs to increase the judgment of the return value of <code>block()</code>:</p>
<pre><code class="language-rust  ignore">     fn chunk(&amp;mut self) {
         assert_eq!(self. block(), Token::Eos);
     }</code></pre>
<h2 id="variable-scope-in-block"><a class="header" href="#variable-scope-in-block">Variable Scope in Block</a></h2>
<p>Another area of the <code>block()</code> function that needs to be changed is the scope of local variables. That is, local variables defined inside the block are not visible outside.</p>
<p>This feature is very core! But the implementation is very simple. Just record the number of current local variables at the entry of <code>block()</code>, and then clear the newly added local variables before exiting. code show as below:</p>
<pre><code class="language-rust  ignore">     fn block(&amp;mut self) -&gt; Token {
         let nvar = self.locals.len(); // record the original number of local variables
         loop {
             match self. lex. next() {
                 // Other statement parsing is omitted here
                 t =&gt; {
                     self.locals.truncate(nvar); // invalidate local variables defined inside the block
                     break t;
                 }
             }
         }
     }</code></pre>
<p>After the Upvalue is introduced later, other processing is required.</p>
<h2 id="do-statement"><a class="header" href="#do-statement"><code>do</code> Statement</a></h2>
<p>The above two subsections deal with the problem of blocks. The simplest statement to create a block is the <code>do</code> statement. Because it is too simple, we introduce it here by the way. The syntax analysis code is as follows:</p>
<pre><code class="language-rust  ignore">     // BNF:
     // do block end
     fn do_stat(&amp;mut self) {
         assert_eq!(self. block(), Token::End);
     }</code></pre>
<h2 id="virtual-machine-execution-2"><a class="header" href="#virtual-machine-execution-2">Virtual Machine Execution</a></h2>
<p>The previous virtual machine execution was to execute bytecodes sequentially, and use Rust's for statement to loop through:</p>
<pre><code class="language-rust  ignore">     pub fn execute&lt;R: Read&gt;(&amp;mut self, proto: &amp;ParseProto&lt;R&gt;) {
         for code in proto.byte_codes.iter() {
             match *code {
                 // All bytecode pre-defined logic is omitted here
             }
         }
     }</code></pre>
<p>Now to support the jump of the <code>Test</code> bytecode, it is necessary to be able to modify the position of the next traversal during the loop traversal of the bytecode sequence. Rust's <code>for</code> statement <a href="https://stackoverflow.com/a/70283398/4794937">does not supported</a> modifies the traversal position during the loop, so we need to manually control the loop:</p>
<pre><code class="language-rust  ignore">     pub fn execute&lt;R: Read&gt;(&amp;mut self, proto: &amp;ParseProto&lt;R&gt;) {
         let mut pc = 0; // bytecode index
         while pc &lt; proto.byte_codes.len() {
             match proto.byte_codes[pc] {
                 // The pre-defined logic of other bytecodes is omitted here

                 // condition structures
                 ByteCode::Test(icond, jmp) =&gt; {
                     let cond = &amp;self. stack[icond as usize];
                     if matches!(cond, Value::Nil | Value::Boolean(false)) {
                         pc += jmp as usize; // jump if false
                     }
                 }
             }

             pc += 1; // next bytecode
         }
     }</code></pre>
<p>Loop execution is controlled by the bytecode location <code>pc</code>. After all bytecodes are executed, <code>pc</code> will be incremented by 1, pointing to the next bytecode; for the jump bytecode <code>Test</code>, <code>pc</code> will be modified additionally. Since <code>Test</code> bytecode will also execute <code>pc</code> auto-increment at the end, so its jump position is actually the target address minus 1. In fact, you can add a <code>continue;</code> statement here to skip the last auto-increment of <code>pc</code>. I don't know which of these two approaches is better.</p>
<p>As can be seen from the judgment of the above code, there are only two false values in the Lua language: <code>nil</code> and <code>false</code>. Other values, such as 0, empty table, etc., are all true values.</p>
<h2 id="test-6"><a class="header" href="#test-6">Test</a></h2>
<p>So far we have implemented the simplest <code>if</code> statement.</p>
<p>Since we do not yet support relational operations, the judgment condition after <code>if</code> can only use other statements. The test code is as follows:</p>
<pre><code class="language-lua">if a then
    print &quot;skip this&quot;
end
if print then
    local a = &quot;I am true&quot;
    print(a)
end

print (a) -- should be nil
</code></pre>
<p>The conditional statement <code>a</code> in the first judgment statement is an undefined global variable, the value is <code>nil</code>, which is false, so the internal statement is not executed.</p>
<p>The conditional statement <code>print</code> in the second judgment statement is a defined global variable and is true, so the internal statement will execute. The local variable <code>a</code> is defined inside the block, which is executed normally inside, but after the end of the block, <code>a</code> is invalid, and then it is used as an undefined global variable, and the print is <code>nil</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="elseif-and-else-branches"><a class="header" href="#elseif-and-else-branches"><code>elseif</code> and <code>else</code> branches</a></h1>
<p>The previous section supported the <code>if</code> statement. This section continues with the <code>elseif</code> and <code>else</code> branches.</p>
<p>The complete BNF specification is as follows:</p>
<pre><code>     if exp then block {else if exp then block} [else block] end
</code></pre>
<p>In addition to the if judgment, there can also be multiple optional elseif judgment branches in a row, followed by an optional else branch at the end. The control structure diagram is as follows:</p>
<pre><code>     +-------------------+
     | if condition then |-------\ jump to the next `elseif` branch if $condition is false
     +-------------------+       |
                                 |
         block                   |
/&lt;----                           |
|    +-----------------------+&lt;--/
|    | elseif condition then |-----\ jump to the next `elseif` branch if $condition is false
|    +-----------------------+     |
|                                  |
|        block                     |
+&lt;----                             |
|    +-----------------------+&lt;----/
|    | elseif condition then |-------\ jump to the `else` branch if $condition is false
|    +-----------------------+       |
|                                    |
|        block                       |
+&lt;----                               |
|    +------+                        |
|    | else |                        |
|    +------+&lt;-----------------------/
|
|        block
|
|    +-----+
|    | end |
|    +-----+
\---&gt; All block jump here.
      The last block gets here without jump.
</code></pre>
<p>The above diagram depicts the situation where there are 2 <code>elseif</code> branches and 1 <code>else</code> branch. Except for the judgment jump of <code>if</code> in the upper right corner, the rest are jumps to be added. There are 2 types of jumps:</p>
<ul>
<li>The conditional jump on the right side of the figure is executed by the <code>Test</code> bytecode added in the previous section;</li>
<li>The unconditional jump on the left side of the figure needs to add <code>Jump</code> bytecode, which is defined as follows:</li>
</ul>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     // condition structures
     Test(u8, u16),
     Jump(u16),</code></pre>
<p>The syntax analysis process is as follows:</p>
<ul>
<li>
<p>For the <code>if</code> judgment branch, compared with the previous section, the position of the conditional jump remains unchanged, and it is still the end position of the block; however, an unconditional jump instruction needs to be added at the end of the block to jump to the end of the entire if statement;</p>
</li>
<li>
<p>For the <code>elseif</code> branch, it is handled in the same way as the <code>if</code> branch.</p>
</li>
<li>
<p>For the <code>else</code> branch, no processing is required.</p>
</li>
</ul>
<p>The format of the final generated bytecode sequence should be as follows, where <code>...</code> represents the bytecode sequence of the inner code block:</p>
<pre><code>     Test --\  `if` branch
     ...    |
/&lt;-- Jump   |
|      /&lt;---/
|    Test ----\  `elseif` branch
|    ...      |
+&lt;-- Jump     |
|      /&lt;-----/
|    Test ------\  `elseif` branch
|    ...        |
+&lt;-- Jump       |
|      /&lt;-------/
|    ...   `else` branch
|
\--&gt; end of all

</code></pre>
<p>The syntax analysis code is as follows:</p>
<pre><code class="language-rust  ignore">     fn if_stat(&amp;mut self) {
         let mut jmp_ends = Vec::new();

         // `if` branch
         let mut end_token = self. do_if_block(&amp;mut jmp_ends);

         // optional multiple `elseif` branches
         while end_token == Token::Elseif { // If the previous block ends with the keyword `elseif`
             end_token = self.do_if_block(&amp;mut jmp_ends);
         }

         // optional `else` branch
         if end_token == Token::Else { // If the previous block ends with the keyword `else`
             end_token = self. block();
         }

         assert_eq!(end_token, Token::End); // Syntax: `end` at the end

         // Repair the unconditional jump bytecode at the end of the 
         // block in all `if` and `elseif` branches, and jump to the
         // current position
         let iend = self.byte_codes.len() - 1;
         for i in jmp_ends.into_iter() {
             self.byte_codes[i] = ByteCode::Jump((iend - i) as i16);
         }
     }</code></pre>
<p>The processing function <code>do_if_block()</code> for if and elseif is as follows:</p>
<pre><code class="language-rust  ignore">     fn do_if_block(&amp;mut self, jmp_ends: &amp;mut Vec&lt;usize&gt;) -&gt; Token {
         let icond = self.exp_discharge_top(); // read judgment statement
         self.lex.expect(Token::Then); // Syntax: `then` keyword

         self.byte_codes.push(ByteCode::Test(0, 0)); // generate Test bytecode placeholder, leave the parameter blank
         let itest = self.byte_codes.len() - 1;

         let end_token = self. block();

         // If there is an `elseif` or `else` branch, then the current
         // block needs to add an unconditional jump bytecode, to jump
         // to the end of the entire `if` statement. Since the position
         // of the end is not known yet, the parameter is left blank and the
         // The bytecode index is recorded into `jmp_ends`.
         // No need to jump if there are no other branches.
         if matches!(end_token, Token::Elseif | Token::Else) {
             self.byte_codes.push(ByteCode::Jump(0));
             jmp_ends.push(self.byte_codes.len() - 1);
         }

         // Fix the previous Test bytecode.
         // `iend` is the current position of the bytecode sequence,
         // `itest` is the position of the Test bytecode, and the difference
         // between the two is the number of bytecodes that need to be jumped.
         let iend = self.byte_codes.len() - 1;
         self.byte_codes[itest] = ByteCode::Test(icond as u8, (iend - itest) as i16);

         return end_token;
     }</code></pre>
<h2 id="virtual-machine-execution-3"><a class="header" href="#virtual-machine-execution-3">Virtual Machine Execution</a></h2>
<p>The implementation of the newly added unconditional jump bytecode <code>Jump</code> is very simple. Compared with the previous conditional jump bytecode <code>Test</code>, only the conditional judgment is removed:</p>
<pre><code class="language-rust  ignore">                 // conditional jump
                 ByteCode::Test(icond, jmp) =&gt; {
                     let cond = &amp;self. stack[icond as usize];
                     if matches!(cond, Value::Nil | Value::Boolean(false)) {
                         pc += jmp as usize; // jump if false
                     }
                 }

                 // unconditional jump
                 ByteCode::Jump(jmp) =&gt; {
                     pc += jmp as usize;
                 }</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="while-and-break-statements"><a class="header" href="#while-and-break-statements"><code>while</code> and <code>break</code> Statements</a></h1>
<p>This section introduces the <code>while</code> and <code>break</code> statement.</p>
<h2 id="while-statement"><a class="header" href="#while-statement"><code>while</code> Statement</a></h2>
<p>Compared with the simple form of the <code>if</code> statement (excluding <code>elseif</code> and <code>else</code> branches), the <code>while</code> statement just adds an unconditional jump bytecode at the end of the internal block, jumping back to the beginning of the statement. As shown in the jump on the left in the figure below:</p>
<pre><code>/---&gt;+----------------------+
|    | while condition then |---\ skip the block if $condition is false
|    +----------------------+   |
|                               |
|        block                  |
\&lt;----                          |
     +-----+                    |
     | end |                    |
     +-----+                    |
     &lt;--------------------------/

</code></pre>
<p>The format of the final generated bytecode sequence is as follows, where <code>...</code> represents the bytecode sequence of the inner code block:</p>
<pre><code>/--&gt;  Test --\  `if` branch
|     ...    |
\---  Jump   |
        &lt;----/ The end of the entire `while` statement
</code></pre>
<p>The syntax analysis process and code also add an unconditional jump bytecode on the basis of the <code>if</code> statement. We skip the code here. One thing that needs to be changed is that the unconditional jump here is a backward jump. But the second parameter of the previous <code>Jump</code> bytecode is <code>u16</code> type, which can only jump forward. Now we need to change to <code>i16</code> type, and use a negative number to represent a backward jump:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Jump(i16),</code></pre>
<p>Correspondingly, the execution part of the virtual machine needs to be modified as follows:</p>
<pre><code class="language-rust  ignore">         // unconditional jump
         ByteCode::Jump(jmp) =&gt; {
             pc = (pc as isize + jmp as isize) as usize;
         }</code></pre>
<p>Compared with C language, Rust's type management is stricter, so it looks more verbose.</p>
<h2 id="break-statement"><a class="header" href="#break-statement"><code>break</code> Statement</a></h2>
<p>The <code>while</code> statement itself is very simple, but it introduces another statement: <code>break</code>. The <code>break</code> statement itself is also very simple, just unconditionally jump to the end of the block, but the problem is that not all blocks support <code>break</code>, for example, the block inside the if introduced earlier does not support <code>break</code>, only the block of the loop statement supports <code>break</code>. To be precise, what the <code>break</code> wants to jump out of is the <em>loop</em> block of the <em>nearest</em> layer. For example, the following example:</p>
<pre><code class="language-lua">while 123 do -- outer loop block, support `break`
     while true do -- middle-level loop block, support `break`
         a = a + 1
         if a &lt; 10 then -- inner block, does not support `break`
             `break` -- `break` out of the `while true do` loop
         end
     end
end
</code></pre>
<p>There are 3 layers of blocks in the code, the outer and middle while blocks support <code>break</code>, and the inner if block does not support <code>break</code>. At this time, <code>break</code> is to jump out of the middle block.</p>
<p>If the <code>break</code> statement is not within a loop block, it is a syntax error.</p>
<p>In order to realize the above functions, a parameter can be added to the <code>block()</code> function to indicate the latest loop block when calling recursively. Since the block has not ended when the jump bytecode is generated, and the jump destination address is not yet known, so the jump bytecode can only be generated first, and the parameters are left blank; and then the byte is repaired at the end of the block code parameter. So the parameter of the <code>block()</code> function is the index list of the <code>break</code> jump bytecode of the latest loop block. When calling the <code>block()</code> function,</p>
<ul>
<li>If it is a loop block, create a new index list as a call parameter, and after the call ends, use the current address (that is, the end position of the block) to repair the bytecode in the list;</li>
<li>If it is not a cyclic block, use the current list (that is, the current most recent cyclic block) as the call parameter.</li>
</ul>
<p>But the recursive call of <code>block()</code> function is not direct recursion, but indirect recursion. If you want to pass parameters in this way, then all parsing functions must add this parameter, which is too complicated. So put this index list into the global <code>ParseProto</code>. Locality is sacrificed for coding convenience.</p>
<p>Let's look at the specific coding implementation. First add the <code>break_blocks</code> field in <code>ParseProto</code>, the type is a list of &quot;jump bytecode index list&quot;:</p>
<pre><code class="language-rust  ignore">pub struct ParseProto&lt;R: Read&gt; {
     break_blocks: Vec::&lt;Vec::&lt;usize&gt;&gt;,</code></pre>
<p>When parsing the while statement, add a list before calling the <code>block()</code> function; after calling, fix the jump bytecode in the list:</p>
<pre><code class="language-rust  ignore">     fn while_stat(&amp;mut self) {

         // Omit the conditional judgment statement processing part

         // Before calling block(), append a list
         self.break_blocks.push(Vec::new());

         // call block()
         assert_eq!(self.block(), Token::End);

         // After calling block(), pop up the list just added, and fix the jump bytecode in it
         for i in self.break_blocks.pop().unwrap().into_iter() {
             self.byte_codes[i] = ByteCode::Jump((iend - i) as i16);
         }
     }</code></pre>
<p>After the block is prepared, the <code>break</code> statement can be implemented:</p>
<pre><code class="language-rust  ignore">     fn `break`_stat(&amp;mut self) {
         // Get the bytecode list of the nearest loop block
         if let Some(breaks) = self.break_blocks. last_mut() {
             // Generate a jump bytecode placeholder, the parameter is left blank
             self.byte_codes.push(ByteCode::Jump(0));
             // Append to the bytecode list
             `break`s.push(self.byte_codes.len() - 1);
         } else {
             // Syntax error if there is no loop block
             panic!(&quot;break outside loop&quot;);
         }
     }</code></pre>
<h2 id="continue-statement"><a class="header" href="#continue-statement"><code>continue</code> Statement?</a></h2>
<p>After implementing the <code>break</code> statement, the <code>continue</code> statement naturally comes to mind. Moreover, the implementation of <code>continue</code> is similar to <code>break</code>, the difference is that one jumps to the end of the loop, and the other jumps to the beginning of the loop. Adding this function is a convenient thing. But Lua does not support the <code>continue</code> statement! A small part of this has to do with the <code>repeat..until</code> statement. We discuss the <code>continue</code> statement in more detail after introducing the <code>repeat..until</code> statement in the next section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="repeatuntil-and-continue-statements"><a class="header" href="#repeatuntil-and-continue-statements"><code>repeat..until</code> and <code>continue</code> Statements</a></h1>
<p>This section introduces the <code>repeat..until</code> statement, and discusses and attempts to introduce the <code>continue</code> statement that Lua language does not support.</p>
<h2 id="repeatuntil-statement"><a class="header" href="#repeatuntil-statement"><code>repeat..until</code> Statement</a></h2>
<p>The <code>repeat..until</code> statement is similar to the <code>while</code> statement, except that the judgment condition is placed behind to ensure that the internal code block is executed at least once.</p>
<pre><code>     +--------+
     | repeat |
     +--------+
/---&gt;
|        block
|
|    +-----------------+
\----| until condition |
     +-----------------+
</code></pre>
<p>The format of the final generated bytecode sequence is as follows, where <code>...</code> represents the bytecode sequence of the inner code block:</p>
<pre><code>     ... &lt;--\
     Test ---/ `until` judgment condition
</code></pre>
<p>Compared with the bytecode sequence of the <code>while</code> statement, it seems that the Test is put at the end and the original Jump bytecode is replaced. But the situation is not that simple! Putting the judgment conditional statement behind the block will introduce a big problem. The local variables defined in the block may be used in the judgment conditional statement. For example, the following example:</p>
<pre><code class="language-lua">-- keep retrying until the request succeeds
repeat
     local ok = request_xxx()
until ok
</code></pre>
<p>The variable <code>ok</code> after the last line <code>until</code> is obviously intended to refer to the local variable defined in the second line. However, the previous code block analysis function <code>block()</code> has <a href="./ch06-01.if.html#variable-scope-in-block">deleted the internally defined local variables</a> at the end of the function. That is to say, according to the previous syntax analysis logic, when <code>until</code> is parsed, the internally defined <code>ok</code> local variable has become invalid and cannot be used. This is clearly unacceptable.</p>
<p>In order to support the ability to read internal local variables during <code>until</code>, the original <code>block()</code> function needs to be modified (the code is always messed up by these strange requirements), and the control of local variables is independent. For this reason, a <code>block_scope()</code> function is added, which only does syntax analysis; while the scope of internal local variables is completed by the outer <code>block()</code> function. In this way, the place where the <code>block()</code> function was originally called (such as if, while statement, etc.) does not need to be modified, and this special <code>repeat..until</code> statement calls the <code>block_scope()</code> function for finer control. code show as below:</p>
<pre><code class="language-rust  ignore">     fn block(&amp;mut self) -&gt; Token {
         let nvar = self. locals. len();
         let end_token = self. block_scope();
         self.locals.truncate(nvar); // expire internal local variables
         return end_token;
     }
     fn block_scope(&amp;mut self) -&gt; Token {
         ... // The original block parsing process
     }</code></pre>
<p>Then, the analysis code of the <code>repeat..until</code> statement is as follows:</p>
<pre><code class="language-rust  ignore">     fn repeat_stat(&amp;mut self) {
         let istart = self.byte_codes.len();

         self. push_break_block();

         let nvar = self.locals.len(); // Internal local variable scope control!

         assert_eq!(self. block_scope(), Token::Until);

         let icond = self.exp_discharge_top();

         // expire internal local variables AFTER condition exp.
         self.locals.truncate(nvar); // Internal local variable scope control!

         let iend = self.byte_codes.len();
         self.byte_codes.push(ByteCode::Test(icond as u8, -((iend - istart + 1) as i16)));

         self. pop_break_block();
     }</code></pre>
<p>In the above code, the 2 lines commented complete the scope control of the internal local variables in the original <code>block()</code> function. After calling <code>exp_discharge_top()</code> and parsing the conditional judgment statement, the internally defined local variables are deleted.</p>
<h2 id="continue-statement-1"><a class="header" href="#continue-statement-1"><code>continue</code> statement</a></h2>
<p>It took a lot of space to explain the scope of variables in the <code>repeat..until</code> statement, which has a lot to do with the <code>continue</code> statement that does not exist in Lua.</p>
<p>When the <code>break</code> statement was supported in the previous section, it was mentioned that the Lua language does not support the <code>continue</code> statement. There is a lot of debate on this issue, and there is a high demand for adding a <code>continue</code> statement in Lua. As early as 2012, there was a related <a href="http://lua-users.org/wiki/ContinueProposal">proposal</a>, which listed in detail the advantages and disadvantages of adding the <code>continue</code> statement and related discussions. Twenty years have passed, and even though the stubborn Lua added the <code>goto</code> statement in version 5.2, it still did not add the <code>continue</code> statement.</p>
<p>The <a href="https://www.luafaq.org/#T1.26">&quot;Unofficial FAQ&quot;</a> explains this:</p>
<ul>
<li>The <code>continue</code> statement is just one of many control statements, similar ones include <code>goto</code>, <code>break</code> with label, etc. The <code>continue</code> statement is nothing special, there is no need to add this statement;</li>
<li>Conflicts with existing <code>repeat..until</code> statements.</li>
</ul>
<p>In addition, an <a href="http://lua-users.org/lists/lua-l/2008-02/msg01183.html">email</a> from Roberto, the author of Lua, is more representative of the official attitude. The reason for this is the first point above, that is, the <code>continue</code> statement is just one of many control statements. An interesting thing is that there are two examples in this email, and the other example just happens to be <code>repeat..until</code> besides <code>continue</code>. The above unofficial FAQ also mentioned that these two statements conflict.</p>
<p>The reason for the conflict between these two statements is that if there is a <code>continue</code> statement in the <code>repeat..until</code> internal code block, then it will jump to the until conditional judgment position. If there are local variables defined in the block are used in <code>until</code> statement, while the <code>continue</code> statement may skip the definition and jump to the <code>until</code>, then this local variable is meaningless in <code>until</code>. This is where the conflict lies. For example the following code:</p>
<pre><code class="language-lua">repeat
     `continue` -- jump to until, skip the definition of `ok`
     local ok = request_xxx()
until ok -- how to deal with `ok` here?
</code></pre>
<p>In contrast, the equivalent of the <code>repeat..until</code> statement in the C language is the <code>do..while</code> statement, which supports <code>continue</code>. This is because in the <code>do..while</code> statement of the C language, the conditional judgment after the while is outside the scope of the internal code block. For example, the following code will compile error:</p>
<pre><code class="language-c">     do {
         bool ok = request_xx();
     } while (ok); // error: 'ok' undeclared
</code></pre>
<p>Such a specification (the conditional judgment is outside the scope of the inner code block) is not convenient in some usage scenarios (such as the above example), but there are also very simple solutions (such as move <code>ok </code>definition outside the loop), and the syntax analysis is simpler, for example, there is no need to separate the <code>block_scope()</code> function. Then why does Lua stipulate that the conditional judgment statement should be placed within the inner scope? The speculation is as follows, if Lua also follows the practice of C language (the conditional judgment is outside the scope of the internal code block), and then the user writes the following Lua code, <code>ok</code> after the until will be parsed as a Global variables, without reporting errors like C language! This is not the user's intention, thus causing a serious bug.</p>
<pre><code class="language-lua">repeat
     local ok = request_xxx()
until ok
</code></pre>
<p>To sum up, the <code>repeat..until</code> statement needs to put the conditional judgment statement after <code>until</code> in the scope of the internal code block in order to avoid bugs with a high probability; then when the <code>continue</code> statement jumps to the conditional statement, it may skip the definition of local variables, and then there is a conflict.</p>
<h2 id="try-adding-continue-statement"><a class="header" href="#try-adding-continue-statement">Try Adding <code>continue</code> Statement</a></h2>
<p>Lua's official <a href="https://www.luafaq.org/#T1.26">reason for not supporting the <code>continue</code> statement</a> is mainly that they think the frequency of use of the <code>continue</code> statement is very low and it is not worth supporting. But in my personal programming experience, whether in Lua or other languages, the frequency of use of the <code>continue</code> statement is still very high. Although it may not be as good as <code>break</code>, it is far more than <code>goto</code> and <code>break</code> with labels, and even more than <code>repeat..until</code> statement. Besides, the way to implement the <code>continue</code> function in Lua (<code>repeat..until true</code> + <code>break</code>, or <code>goto</code>) is more verbose than using <code>continue</code> directly. So can we add a <code>continue</code> statement to our interpreter?</p>
<p>First of all, we have to resolve the conflict with <code>repeat..until</code> mentioned above. There are several solutions:</p>
<ul>
<li>
<p>Make a rule that the <code>continue</code> statement is not supported in <code>repeat..until</code>, just like the <code>if</code> statement does not support <code>continue</code>. But this is very easy to cause misunderstanding. For example, a piece of code has two layers of loops, the outer layer is a <code>while</code> loop, and the inner layer is a <code>repeat</code> loop; the user wrote a <code>continue</code> statement in the inner loop, intending to make the inner <code>repeat</code> loop take effect, but because <code>repeat</code> does not actually support <code>continue</code>, Then it will take effect in the outer while loop, and <code>continue</code> the outer <code>while</code> loop. This is a serious potential bug.</p>
</li>
<li>
<p>Make a rule that the <code>continue</code> statement is prohibited in <code>repeat..until</code>. If there is <code>continue</code>, an error will be reported. This can avoid the potential bugs of the above scheme, but this prohibition is too strict.</p>
</li>
<li>
<p>Make a rule that if an internal local variable is defined in <code>repeat..until</code>, the <code>continue</code> statement is prohibited. This plan is a little more relaxed than the last one, but it can be more relaxed.</p>
</li>
<li>
<p>Make a rule that after the <code>continue</code> statement appears in <code>repeat..until</code>, the definition of internal local variables is prohibited; in other words, <code>continue</code> prohibits jumping to local variable definitions. This is similar to the restriction on subsequent <code>goto</code> statements. However, it can be more relaxed.</p>
</li>
<li>
<p>On the basis of the previous solution, only the local variables defined after the <code>continue</code> statement are used in the conditional judgment statement after the <code>until</code>, which is prohibited. It’s just that the judgment of whether to use local variables in the statement is very complicated. If function closures and Upvalue are supported later, it is basically impossible to judge. So this plan is not feasible.</p>
</li>
</ul>
<p>In the end, I chose to use the second-to-last solution. For specific coding implementation, there used to be <code>break_blocks</code> in <code>ParseProto</code> to record break statements, and now a similar <code>continue_blocks</code> is added, but the member type is <code>(icode, nvar)</code>. Among them, the first variable icode is the same as the members of <code>break_blocks</code>, and records the position of the Jump bytecode corresponding to the <code>continue</code> statement for subsequent correction; the second variable <code>nvar</code> represents the number of local variables in the <code>continue</code> statement, which is used for Subsequent checks to see if the new local variable has been jumped.</p>
<p>Second, adding a <code>continue</code> statement cannot affect existing code. In order to support the <code>continue</code> statement, it is necessary to use <code>continue</code> as a keyword (similar to the <code>break</code> keyword), so many existing Lua codes use <code>continue</code> as a label, or even a variable name or function name (essentially a variable name) will fail to parse. To this end, a tricky solution is not to use <code>continue</code> as a keyword, but to judge when parsing a statement that if it starts with <code>continue</code> and is followed by a block-ending Token (such as <code>end</code>, etc.), it is considered to be <code>continue</code> statement. Thus in most other places, <code>continue</code> will still be interpreted as a normal Name.</p>
<p>In the corresponding <code>block_scope()</code> function, the part starting with Token::Name, the newly added code is as follows:</p>
<pre><code class="language-rust  ignore">         loop {
             match self. lex. next() {
                 // Omit parsing of other types of statements
                 t@Token::Name(_) | t@Token::ParL =&gt; {
                     // this is not standard!
                     if self.try_continue_stat(&amp;t) { // !! New !!
                         continue;
                     }

                     // The following omits the parsing of standard 
                     // function calls and variable assignment statements
                 }</code></pre>
<p>The <code>try_continue_stat()</code> function is defined as follows:</p>
<pre><code class="language-rust  ignore">     fn try_continue_stat(&amp;mut self, name: &amp;Token) -&gt; bool {
         if let Token::Name(name) = name {
             if name.as_str() != &quot;continue&quot; { // The beginning of the judgment statement is `continue`
                 return false;
             }
             if !matches!(self.lex.peek(), Token::End | Token::Elseif | Token::Else) {
                 return false; // Judgment followed by one of these 3 Tokens
             }

             // Then, it's the `continue` statement. The following processing
             // is similar to the break statement processing
             if let Some(continues) = self.continue_blocks.last_mut() {
                 self.byte_codes.push(ByteCode::Jump(0));
                 continues.push((self.byte_codes.len() - 1, self.locals.len()));
             } else {
                 panic!(&quot;continue outside loop&quot;);
             }
             true
         } else {
             false
         }
     }</code></pre>
<p>Before parsing to the code block of the loop body, it must be prepared first, which is the <code>push_loop_block()</code> function. After the block ends, use <code>pop_loop_block()</code> to handle <code>break</code>s and <code>continue</code>s. The jump corresponding to <code>break</code>s is to jump to the end of the block, that is, the current position; the jump position corresponding to <code>continue</code>s is determined according to different loops (for example, the while loop jumps to the beginning of the loop, and the repeat loop jumps to the end of the loop) , so parameters are required to specify; in addition, when processing continus, it is necessary to check whether there are new definitions of local variables, that is, compare the number of current local variables with the number of local variables in the <code>continue</code> statement.</p>
<pre><code class="language-rust  ignore">     // before entering loop block
     fn push_loop_block(&amp;mut self) {
         self. break_blocks. push(Vec::new());
         self. `continue`_blocks. push(Vec::new());
     }

     // after leaving loop block, fix `break` and `continue` Jumps
     fn pop_loop_block(&amp;mut self, icon`continue`: usize) {
         // breaks
         let iend = self.byte_codes.len() - 1;
         for i in self.break_blocks.pop().unwrap().into_iter() {
             self.byte_codes[i] = ByteCode::Jump((iend - i) as i16);
         }

         // continues
         let end_nvar = self. locals. len();
         for (i, i_nvar) in self.`continue`_blocks.pop().unwrap().into_iter() {
             if i_nvar &lt; end_nvar {
                // i_nvar is the number of local variables in the 
                // `continue` statement, end_nvar is the number of
                // current local variables
                 panic!(&quot;`continue` jump into local scope&quot;);
             }
             self.byte_codes[i] = ByteCode::Jump((i`continue` as isize - i as isize) as i16 - 1);
         }
     }</code></pre>
<p>So far, we have implemented the <code>continue</code> statement while ensuring backward compatibility! You can use the following code to test:</p>
<pre><code class="language-lua">-- validate compatibility
continue = print -- continue as global variable name, and assign it a value
continue(continue) -- call continue as function

-- continue in while loop
local c = true
while c do
    print &quot;hello, while&quot;
    if true then
      c = false
      continue
    end
    print &quot;should not print this!&quot;
end

-- continue in repeat loop
repeat
    print &quot;hello, repeat&quot;
    local ok = true
    if true then
      continue -- continue after local
    end
    print &quot;should not print this!&quot;
until ok

-- continue skip local in repeat loop
-- PANIC!
repeat
    print &quot;hello, repeat again&quot;
    if true then
      continue -- skip `ok`!!! error in parsing
    end
    local ok = true
until ok
</code></pre>
<h2 id="repeatuntil-existence"><a class="header" href="#repeatuntil-existence"><code>repeat..until</code> Existence</a></h2>
<p>As can be seen above, the existence of the <code>repeat..until</code> statement introduces two problems because the scope of the local variables defined in the block needs to be extended in the <code>until</code> part:</p>
<ul>
<li>In programming implementation, it is necessary to create a <code>block_scope()</code> function;</li>
<li>Conflict with <code>continue</code> statement.</li>
</ul>
<p>I personally think that introducing the above two problems in order to support a statement that is rarely used like <code>repeat..until</code> is not worth the candle. If I were to design the Lua language, this statement would not be supported.</p>
<p>In the 8.4 Exercise section of the official &quot;Lua Programming (4th Edition)&quot; book, the following questions are raised:</p>
<blockquote>
<p>Exercise 8.3: Many people think that because <code>repeat-until</code> is rarely used, it should not appear at the end in a simple programming language like Lua language. What do you think?</p>
</blockquote>
<p>I really want to know the author's answer to this question, but unfortunately, none of the exercises in this book give an answer.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="numerical-for-statement"><a class="header" href="#numerical-for-statement">numerical-for Statement</a></h1>
<p>Lua's <code>for</code> statement supports two types:</p>
<ul>
<li>Numeric: <code>for Name '=' exp ',' exp [',' exp] do block end</code></li>
<li>Generics: <code>for namelist in explist do block end</code></li>
</ul>
<p>Generic-for requires function support, and it will be implemented after introducing functions in the next chapter. This section implements numeric-for. It can be seen from the BNF definition that the first two tokens of the two types are the same, and the third token of the numeric type is <code>=</code>. By this distinction two types can be distinguished:</p>
<pre><code class="language-rust  ignore">     fn for_stat(&amp;mut self) {
         let name = self. read_name();
         if self.lex.peek() == &amp;Token::Assign {
             self.for_numerical(name); // numerical
         } else {
             todo!(&quot;generic for&quot;); // generic
         }
     }</code></pre>
<h2 id="control-structure-1"><a class="header" href="#control-structure-1">Control Structure</a></h2>
<p>The semantics of the numerical-for statement is obvious. The three expressions after the equal sign <code>=</code> are the initial value <code>init</code>, the <code>limit</code>, and the <code>step</code>. <code>step</code> can be positive or negative, but not 0. The control structure diagram is as follows (assuming step&gt;0 in the diagram):</p>
<pre><code>     +--------------+
/---&gt;| i &lt;= limit ? |--No--\ jump to the end if exceed limit
|    +--------------+      |
|                          |
|        block             |
|                          |
|    +-----------+         |
\----| i += step |         |
     +-----------+         |
         &lt;-----------------/
</code></pre>
<p>The execution logic in the boxes can be implemented with 1 bytecode respectively, so 2 bytecodes must be executed in each loop: first <code>i+=step</code>, and then judge <code>i&lt;=limit</code>. For performance, the judgment function of the first bytecode can also be added to the bottom bytecode, so that only one bytecode is executed each loop. The control structure diagram is as follows:</p>
<pre><code>       +--------------+
       | i &lt;= limit ? |--No--\ jump to the end if exceed limit
       +--------------+      |
/------&gt;                     |
|       block                |
|                            |
|       +--------------+     |
|       | i += step    |     |
\--Yes--| i &lt;= limit ? |     |
        +--------------+     |
            &lt;----------------/
</code></pre>
<p>Add 2 new bytecodes:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     // for-loop
     ForPrepare(u8, u16),
     ForLoop(u8, u16),</code></pre>
<p>These two bytecodes correspond to the bytecodes of the two boxes in the above figure, and the two associated parameters are the stack start position and jump position respectively. Later, we will see that the first bytecode needs to do other preparations besides judging the jump, so it is called prepare.</p>
<h2 id="variable-storage"><a class="header" href="#variable-storage">Variable Storage</a></h2>
<p>The first parameter associated with the above two bytecodes is the starting position of the stack. To be precise, it is the location where the above three values (init, limit, step) are stored. These 3 values naturally need to be stored on the stack, because one of the functions of the stack is to store temporary variables, and because there is no other place available. The 3 values are stored sequentially, so only one parameter is needed to locate 3 values.</p>
<p>In addition, the for statement also has a control variable, which can reuse the position on the stack of init. During parsing, create an internal temporary variable whose name is Name in BNF, pointing to the position of the first variable on the stack. In order to keep the positions of the other 2 temporary variables from being occupied, 2 more anonymous local variables need to be created. Therefore, the stack at execution time is as follows:</p>
<pre><code>      |        |
sp    +--------+
      | init/i |  control variable Name
sp+1  +--------+
      | limit  |  anonymous variable &quot;&quot;
sp+2  +--------+
      | step   |  anonymous variable &quot;&quot;
      +--------+
      |        |
</code></pre>
<p>The numerical-for statement is special only in the above three temporary variables, and the rest is similar to the control structure introduced before, which is nothing more than jumping according to the conditional judgment statement. The syntax analysis code is as follows:</p>
<pre><code class="language-rust  ignore">     fn for_numerical(&amp;mut self, name: String) {
         self.lex.next(); // skip `=`

         // Read 3 expressions: init, limit, step (default is 1), and place
         // them on the stack in turn
         match self.explist() {
             2 =&gt; self.discharge(self.sp, ExpDesc::Integer(1)),
             3 =&gt; (),
             _ =&gt; panic!(&quot;invalid numerical-for exp&quot;),
         }

         // Create 3 local variables to occupy the position on the stack.
         // Subsequent if the internal block needs local or temporary variables,
         // The position after these 3 variables on the stack will be used.
         self.locals.push(name); // control variable, can be referenced in internal block
         self.locals.push(String::from(&quot;&quot;)); // anonymous variable, purely for placeholder
         self.locals.push(String::from(&quot;&quot;)); // Same as above

         self.lex.expect(Token::Do);

         // Generate ForPrepare bytecode
         self.byte_codes.push(ByteCode::ForPrepare(0, 0));
         let iprepare = self.byte_codes.len() - 1;
         let iname = self.sp - 3;

         self. push_loop_block();

         // inner block
         assert_eq!(self. block(), Token::End);

         // delete 3 temporary variables
         self. locals. pop();
         self. locals. pop();
         self. locals. pop();

         // Generate ForLoop bytecode and fix the previous ForPrepare
         let d = self.byte_codes.len() - iprepare;
         self.byte_codes.push(ByteCode::ForLoop(iname as u8, d as u16));
         self.byte_codes[iprepare] = ByteCode::ForPrepare(iname as u8, d as u16);

         self.pop_loop_block(self.byte_codes.len() - 1);
     }</code></pre>
<h2 id="integer-and-float-point-types"><a class="header" href="#integer-and-float-point-types">Integer and Float-point Types</a></h2>
<p>The previously supported control statements(such as <code>if</code>, <code>while</code>) mainly introduce the syntax analysis part; while the virtual machine execution part only performs simple operations on the stack according to the bytecode. However, the syntax analysis part of the numerical-for loop is relatively simple (mainly because it is similar to the previous control structures), while the virtual machine execution part is very complicated. In fact, it is not difficult, it is just cumbersome. The reason is that Lua supports 2 numeric types, integers and floats. There are a total of 3 expressions (or called variables) in the numeric-for statement, <code>init</code>, <code>limit</code>, and <code>step</code>, each of which may be one of two types, and there are 8 possibilities in total. Although in some cases the type of some variables (such as constants) can be determined in the syntax analysis stage, it is of little significance to deal with this special case alone, and finally it is necessary to deal with all three variables of unknown type situation, which needs to be handled during the execution phase of the virtual machine.</p>
<p>It is too complicated to deal with 8 types one by one; and they cannot be completely classified into one type, because the representation ranges of integers and floating-point numbers are different. In this regard, the Lua language <a href="https://www.lua.org/manual/5.4/manual.html#3.3.5">regulations</a> is divided into two categories:</p>
<ul>
<li>If <code>init</code> and <code>step</code> are integers, then treat them as integers;</li>
<li>Otherwise, handle them as floating point numbers.</li>
</ul>
<p>As for why the second <code>limit</code> variable is not considered in the first category, it is not clear. I think there are some possible reasons, but I'm not sure about them, so I won't discuss them here. It can be realized according to the regulations of Lua. But it does introduce some complications.</p>
<p>Somewhere the 8 possibilities need to be grouped into the 2 types above. It can't be done in the syntax analysis phase, and it is too costly to perform each time the loop is executed, so it is classified once at the beginning of the loop. This is what the <code>ForPrepare</code> bytecode does:</p>
<ul>
<li>If <code>init</code> and <code>step</code> are integers, then convert <code>limit</code> to an integer;</li>
<li>Otherwise, convert all 3 variables to floats.</li>
</ul>
<p>In this way, each time the loop is executed, that is, the ForLoop bytecode, only two cases need to be handled.</p>
<p>It is easy to convert integers to floating-point numbers in the second category, but to convert the floating-point limit to integers in the first category, you must pay attention to the following two points:</p>
<ul>
<li>If <code>step</code> is positive, <code>limit</code> is rounded down; if <code>step</code> is negative, <code>limit</code> is rounded up.</li>
<li>If the <code>limit</code> exceeds the representation range of the integer, then it is converted to the maximum or minimum value of the integer. There is an extreme situation here, such as <code>step</code> is negative, <code>init</code> is the maximum value of an integer, and <code>limit</code> exceeds the maximum value of an integer, then <code>init</code> is smaller than <code>limit</code>, and because Lua clearly stipulates that the control variable of the numerical-for loop will not overflow and reverse, So the expectation is that the loop will not be executed. But according to the above conversion, <code>limit</code> is converted to the maximum value because it exceeds the maximum value of the integer, which is equal to <code>init</code>, and 1 cycle will be executed. Therefore, for special treatment, you can set <code>init</code> and <code>limit</code> to 0 and 1 respectively, so that the loop will not be executed.</li>
</ul>
<p>The specific code for <code>limit</code> variable conversion is as follows:</p>
<pre><code class="language-rust  ignore">fn for_int_limit(limit: f64, is_step_positive: bool, i: &amp;mut i64) -&gt; i64 {
     if is_step_positive {
         if limit &lt; i64::MIN as f64 {
             *i = 0; // Modify init together to ensure that the loop will not be executed
             -1
         } else {
             limit.floor() as i64 // round down
         }
     } else {
         if limit &gt; i64::MAX as f64 {
             *i = 0;
             1
         } else {
             limit.ceil() as i64 // round up
         }
     }
}</code></pre>
<h2 id="virtual-machine-execution-4"><a class="header" href="#virtual-machine-execution-4">Virtual Machine Execution</a></h2>
<p>After introducing the above integer and floating-point number types and conversion details, the next step is to implement the virtual machine execution part of the two bytecodes.</p>
<p>The ForPrepare bytecode does two things: first, it is divided into integer and floating point type loops according to the variable type; Then compare <code>init</code> and <code>limit</code> to determine whether to execute the first cycle. code show as below:</p>
<pre><code class="language-rust  ignore">                ByteCode::ForPrepare(dst, jmp) =&gt; {
                    // clear into 2 cases: integer and float
                    // stack: i, limit, step
                    if let (&amp;Value::Integer(mut i), &amp;Value::Integer(step)) =
                            (&amp;self.stack[dst as usize], &amp;self.stack[dst as usize + 2]) {
                        // integer case
                        if step == 0 {
                            panic!(&quot;0 step in numerical for&quot;);
                        }
                        let limit = match self.stack[dst as usize + 1] {
                            Value::Integer(limit) =&gt; limit,
                            Value::Float(limit) =&gt; {
                                let limit = for_int_limit(limit, step&gt;0, &amp;mut i);
                                self.set_stack(dst+1, Value::Integer(limit));
                                limit
                            }
                            // TODO convert string
                            _ =&gt; panic!(&quot;invalid limit type&quot;),
                        };
                        if !for_check(i, limit, step&gt;0) {
                            pc += jmp as usize;
                        }
                    } else {
                        // float case
                        let i = self.make_float(dst);
                        let limit = self.make_float(dst+1);
                        let step = self.make_float(dst+2);
                        if step == 0.0 {
                            panic!(&quot;0 step in numerical for&quot;);
                        }
                        if !for_check(i, limit, step&gt;0.0) {
                            pc += jmp as usize;
                        }
                    }
                }</code></pre>
<p>The ForLoop bytecode also does two things: first, add <code>step</code> to the control variable; then compare the control variable and <code>limit</code> to determine whether to execute the next loop. The code is omitted here.</p>
<p>So far, we have completed the numeric-for statement.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="goto-statement"><a class="header" href="#goto-statement"><code>goto</code> Statement</a></h1>
<p>This section describes the <code>goto</code> statement.</p>
<p>The <code>goto</code> statement and label can be used together for more convenient code control. But the <code>goto</code> statement also has the following restrictions:</p>
<ul>
<li>You cannot jump to the label defined by the inner block, but you can jump to the outer block;</li>
<li>You cannot jump outside the function (note that the above rule has restricted jumping into the function). Since we do not support functions yet, ignore this for now;</li>
<li>You cannot jump into the scope of local variables, that is, you cannot skip local statements. Note here that the scope ends at the last non-void statement, and the label is considered a void statement. My personal understanding is the statement that does not generate bytecode. For example the following code:</li>
</ul>
<pre><code class="language-lua">while xx do
     if yy then goto continue end
     local var = 123
     -- some code
     ::continue::
end
</code></pre>
<p>The <code>continue</code> label is behind the local variable <code>var</code>, but because it is a void statement, it does not belong to the scope of var, so the above <code>goto</code> is a legal jump.</p>
<p>The implementation of the <code>goto</code> statement naturally uses <code>Jump</code> bytecode. The main task of syntax analysis is to match <code>goto</code> and label, and generate <code>Jump</code> bytecode at the place of <code>goto</code> statement to jump to the corresponding label. Since the <code>goto</code> statement can jump forward, the definition of the corresponding label may not be encountered when the <code>goto</code> statement is encountered; it can also jump backward, so when the label statement is encountered, it needs to be saved for subsequent <code>goto</code> matching. Therefore, two new lists need to be added to <code>ParseProto</code> to save the goto and label information encountered during syntax analysis:</p>
<pre><code class="language-rust  ignore">struct GotoLabel {
     name: String, // The label name to jump to/defined
     icode: usize, // current bytecode index
     nvar: usize, // the current number of local variables, used to determine whether to jump into the scope of local variables
}

pub struct ParseProto&lt;R: Read&gt; {
     gotos: Vec&lt;GotoLabel&gt;,
     labels: Vec&lt;GotoLabel&gt;,</code></pre>
<p>Both lists have the same member type, <code>GotoLabel</code>. Among them, <code>nvar</code> is the current number of local variables. Make sure that the nvar corresponding to the paired <code>goto</code> statement cannot be smaller than the nvar corresponding to the label statement, otherwise it means that there is a new local variable definition between the <code>goto</code> and label statements, that is, <code>goto</code> jump into the scope of the local variable.</p>
<p>There are two implementations of matching <code>goto</code> statement and lable:</p>
<ul>
<li>
<p>One-time match at the end of the block:</p>
<ul>
<li>When encountering a <code>goto</code> statement, create a new <code>GotoLabel</code> to join the list, and generate a placeholder Jump bytecode;</li>
<li>When encountering a label statement, create a new <code>GotoLabel</code> to add to the list.</li>
</ul>
<p>Finally, at the end of the block, match once and fix the placeholder bytecode.</p>
</li>
<li>
<p>Live match:</p>
<ul>
<li>When encountering a <code>goto</code> statement, try to match from the existing label list, if the match is successful, directly generate a complete Jump bytecode; otherwise create a new <code>GotoLabel</code>, and generate a placeholder Jump bytecode;</li>
<li>When encountering a label statement, try to match it from the existing <code>goto</code> list, and if it matches, repair the corresponding placeholder bytecode; since there may be other <code>goto</code> statements adjusted to this point, it is still necessary to create a new <code>GotoLabel</code>.</li>
</ul>
<p>At the end of the block, all matches have completed already.</p>
</li>
</ul>
<p>It can be seen that although real-time matching is a little more complicated, it is more cohesive, and there is no need to execute a final function at the end. But this solution has a big problem: it is difficult to judge non-void statements. For example, in the example at the beginning of this section, when the <code>continue</code> label is parsed, it cannot be judged whether there are other non-void statements in the future. If there is, it is an illegal jump. It can only be judged after parsing to the end of the block. In the first one-time matching scheme, the matching is done at the end of the block. At this time, it is convenient to judge the non-void statement. Therefore, we choose one-time matching here. It should be noted that when Upvalue is introduced later, it will be found that the one-time matching scheme is flawed.</p>
<p>After introducing the above details, the overall process of syntax analysis is as follows:</p>
<ul>
<li>After entering the block, first record the number of <code>goto</code> and label before (outer layer);</li>
<li>Parse block, record <code>goto</code> and label statement information;</li>
<li>Before the end of the block, match the <code>goto</code> statement that appears in this block with all (including the outer layer) label statements: if there is a <code>goto</code> statement that is not matched, it will still be returned to the <code>goto</code> list, because it may be a jump to the block The label defined in the outer layer after exiting; finally delete all the labels defined in the block, because after exiting the block, there should be no other goto statements to jump in.</li>
<li>Before the end of the entire Lua chunk, judge whether the <code>goto</code> list is empty. If it is not empty, it means that some <code>goto</code> statements have no destination, and an error is reported.</li>
</ul>
<p>The corresponding code is as follows:</p>
<p>Record the number of <code>goto</code> and label existing in the outer layer at the beginning of parsing the block; and match and clean up the goto and label defined inside before the end of the block:</p>
<pre><code class="language-rust  ignore">     fn block_scope(&amp;mut self) -&gt; Token {
         let igoto = self.gotos.len(); // Record the number of outer goto before
         let ilabel = self.labels.len(); // record the number of outer labels
         loop {
             // omit other statement analysis
             t =&gt; { // end of block
                 // Match goto and label before exiting the block
                 self.close_goto_labels(igoto, ilabel);
                 break t;
             }
         }
     }</code></pre>
<p>The specific matching code is as follows:</p>
<pre><code class="language-rust  ignore">     // The parameters igoto and ilable are the starting positions of goto
     //  and label defined in the current block
     fn close_goto_labels(&amp;mut self, igoto: usize, ilabel: usize) {
         // Try to match &quot;goto defined in the block&quot; and &quot;all labels&quot;.
         let mut no_dsts = Vec::new();
         for goto in self. gotos. drain(igoto..) {
             if let Some(label) = self.labels.iter().rev().find(|l|l.name == goto.name) { // matches
                 if label.icode != self.byte_codes.len() &amp;&amp; label.nvar &gt; goto.nvar {
                     // Check whether to jump into the scope of local variables.
                     // 1. The bytecode corresponding to the label is not the last one,
                     //    indicating that there are non-void statements in the follow-up
                     // 2. The number of local variables corresponding to the label is
                     //    greater than that of goto, indicating that there are newly
                     //    defined local variables
                     panic!(&quot;goto jump into scope {}&quot;, goto.name);
                 }
                 let d = (label.icode as isize - goto.icode as isize) as i16;
                 self.byte_codes[goto.icode] = ByteCode::Jump(d - 1); // fix bytecode
             } else {
                 // If there is no match, put it back
                 no_dsts.push(goto);
             }
         }
         self. gotos. append(&amp;mut no_dsts);

         // Delete the label defined inside the function
         self. labels. truncate(ilabel);
     }</code></pre>
<p>Finally, before the chunk is parsed, check that all gotos are matched:</p>
<pre><code class="language-rust  ignore">     fn chunk(&amp;mut self) {
         assert_eq!(self. block(), Token::Eos);
         if let Some(goto) = self. gotos. first() {
             panic!(&quot;goto {} no destination&quot;, &amp;goto.name);
         }
     }</code></pre>
<p>This completes the <code>goto</code> statement.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logical-and-relational-operations"><a class="header" href="#logical-and-relational-operations">Logical and Relational Operations</a></h1>
<p>This chapter introduces logical operations and relational operations. Both types of operations have two application scenarios: conditional judgment and evaluation. For example the following code:</p>
<pre><code class="language-lua">-- logic operation
if a and b then -- conditional judgment
     print(t.k or 0) -- evaluate
end

-- Relational operations
if a &gt; b then -- conditional judgment
     print(c &gt; d) -- evaluate
end

-- Combination of logical operations and relational operations
if a &gt; b and c &lt; d then -- conditional judgment
     print (x &gt; 0 and x or -x) -- evaluate
end
</code></pre>
<p>The analysis methods in these two scenarios are slightly different. Generally speaking, conditional judgments occur more often than evaluations, so when introducing these two types of operations in this chapter, we first introduce the parsing in conditional judgment scenarios and optimize them; then complete the evaluation scenario.</p>
<p>The scene of conditional judgment is derived from the control structure in the previous chapter, which is why these two types of operations are not introduced immediately after arithmetic operations in Chapter 5, but must be introduced after the control structure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logical-operations-in-conditional-judgment"><a class="header" href="#logical-operations-in-conditional-judgment">Logical Operations in Conditional Judgment</a></h1>
<p>Logical operations include 3: <code>and</code>, <code>or</code>, and <code>not</code>. The last <code>not</code> is a unary operation, which has been introduced in the previous section <a href="./ch05-01.unary_ops.html">Unary Operation</a>. This chapter only introduces the first two <code>and</code> and <code>or</code>.</p>
<p>Then why not introduce <code>and</code> and <code>or</code> in the previous <a href="./ch05-02.binary_ops.html">binary operation</a> section? Because of &quot;short circuit&quot;! In mainstream programming languages (such as C, Rust), logical operations are short-circuited. For example, for the AND operation, if the first operand is false, then there is no need (and cannot) to execute or check the second operand. For example, the statement <code>is_valid() and count()</code>, if the return value of <code>is_valid()</code> is false, then the subsequent <code>count()</code> cannot be executed. Therefore, the execution process of logical operations is: 1. First judge the left operand, 2. If it is false, exit, 3. Otherwise judge the right operand. While the execution process of the binary arithmetic operation is: 1. First find the left operand, 2. Then find the right operand, 3. Finally calculate. It can be seen that the flow of logical operations is different from that of arithmetic operations, so the previous methods cannot be applied.</p>
<p>Before introducing the logic operation in detail, let's look at two usage scenarios of logic operations:</p>
<ol>
<li>As a judgment condition, such as the judgment condition statement in if, while and other statements in the previous chapter, such as <code>if t and t.k then ... end</code>;</li>
<li>Evaluation, such as <code>print(v&gt;0 and v or -v)</code>.</li>
</ol>
<p>In fact, the first scenario can be regarded as a special case of the second scenario. For example, the above if statement example is equivalent to the following code:</p>
<pre><code class="language-lua">local tmp = t and t.k
if tmp then
     ...
end
</code></pre>
<p>It is to first evaluate the operation statement <code>t and t.k</code>, then put the value into a temporary variable, and finally judge whether the value is true or false to decide whether to jump. However, here we don't actually care whether the specific evaluation result is <code>t</code> or <code>t.k</code>, but only care about true or false, so we can save the temporary variable! As you can see below, the omission of temporary variables can save a bytecode, which is a great optimization. Since most applications of logical operations are in the first scenario, it is worthwhile to separate this scenario from the second general scenario for special optimization, by omitting temporary variables and directly judging whether to jump based on the evaluation result.</p>
<p>As the title of this section indicates, this section only introduces the first scenario; while the next section will introduce the second scenario.</p>
<h2 id="jump-rules"><a class="header" href="#jump-rules">Jump Rules</a></h2>
<p>The short-circuit characteristics of logic operations are introduced above. After each operand is judged, a jump may occur and the next operand is skipped. The bytecode corresponding to the logical operation is to jump according to each operand. Different operation combinations will lead to various jump combinations. Now it is necessary to summarize jump rules from various jump combinations, so as to be used as subsequent parsing rules. This is probably the most convoluted part of the whole interpreter.</p>
<p>The following uses the simplest <code>if</code> statement as the application scenario, and first looks at the most basic and and or operations. The following two figures are the jump schematic diagrams of <code>if A and B then ... end</code> and <code>if X or Y then ... end</code> respectively:</p>
<pre><code> A and B                      X or Y

+-------+                    +-------+
|   A   +-False-\    /--True-+   X   |
+---+---+       |    |       +---+---+
    |True       |    |           |False
    V           |    |           V
+-------+       |    |       +-------+
|   B   +-False&gt;+    |       |   Y   +-False-\
+---+---+       |    |       +---+---+      |
    |True       |    \----------&gt;|True      |
    V           |                V          |
  block         |              block        |
    |           |                |          |
    +&lt;----------/                +&lt;--------/
    V                            V
</code></pre>
<p>The left figure is the AND operation. The processing after the judgment of the two operands A and B is the same: if True, continue to execute; if False, jump to the end of the code block.</p>
<p>The figure on the right is the OR operation. The processing flow of the two operands is different. The processing of the first operand X is: False continues execution, and True jumps to the following code block to start. While the processing of the second operand Y is the same as the processing of A and B before.</p>
<p>However, just looking at these two examples is not able to sum up the general law. Also need to look at some complex:</p>
<pre><code>A and B and C               X or Y or Z                 (A and B) or Y               A and (X or Y)

+-------+                    +-------+                    +-------+                    +-------+
|   A   +-False-\    /--True-+   X   |                    |   A   |-False-\            |   A   +-False-\
+---+---+       |    |       +---+---+                    +---+---+       |            +---+---+       |
    |True       |    |           |False                       |True       |                |True       |
    V           |    |           V                            V           |                V           |
+-------+       |    |       +-------+                    +-------+       |            +-------+       |
|   B   +-False&gt;+    +&lt;-True-+   Y   |            /--True-+   B   |       |    /--True-+   X   |       |
+---+---+       |    |       +---+---+            |       +---+---+       |    |       +---+---+       |
    |True       |    |           |False           |      False|&lt;---------/     |           |False      |
    V           |    |           V                |           V                |           V           |
+-------+       |    |       +-------+            |       +-------+            |       +-------+       |
|   C   +-False&gt;+    |       |   Z   +-False-\    |       |   Y   +-False-\    |       |   Y   +-False&gt;+
+---+---+       |    |       +---+---+       |    |       +---+---+       |    |       +---+---+       |
    |True       |    \----------&gt;|True       |    \----------&gt;|True       |    \----------&gt;|True       |
    V           |                V           |                V           |                V           |
  block         |              block         |              block         |              block         |
    |           |                |           |                |           |                |           |
    +&lt;---------/                 +&lt;----------/                +&lt;---------/                 +&lt;---------/
    V                            V                            V                            V
</code></pre>
<p>According to these 4 diagrams, the following rules can be summarized (the specific steps of induction are omitted here. In practice, more examples may be needed to summarize, but too many examples are too bloated):</p>
<ul>
<li>
<p>The jump condition depends on the logical operator (that is, <code>and</code> or <code>or</code>) behind the statement (such as A, B, X, Y, etc. in the above example):</p>
<ul>
<li>
<p>If it is followed by <code>and</code> operation, False jumps and True continues execution. For example, A and B in the first picture are followed by and operations, so they are all False jumps.</p>
</li>
<li>
<p>If it is followed by an <code>or</code> operation, True jumps and False continues. For example, X and Z in the second picture are followed by or operations, so they are all True jumps.</p>
</li>
<li>
<p>If there is no logical operator behind, that is, the entire judgment statement ends, False jumps and True continues to execute. This rule is the same as for <code>and</code> above. This is true for the last judgment statement in the above four figures.</p>
</li>
</ul>
</li>
<li>
<p>Rules for jump target positions:</p>
<ul>
<li>
<p>If the same jump condition continues, jump to the same position. For example, there are 3 consecutive False jumps in the first picture, and 2 consecutive True jumps in the second picture; and the two False jumps in the third picture are not continuous, so the jump positions are different. Then during syntax analysis, if the two operands have the same jump condition, the jump list is merged.</p>
</li>
<li>
<p>If different jump conditions are encountered, terminate the previous jump list and jump to the end of the current judgment statement. For example, the False of Z in the second figure terminates the previous two True jump lists and jumps to the end of the Z statement; another example is the False jump list before the termination of B’s True in the third figure, and jumps to After the B statement.</p>
</li>
<li>
<p>However, the fourth picture does not seem to comply with the above two rules. The two False jumps are not continuous but connected, or the True jump of X does not end the False jump list of A. This is because A does not operate with <code>X</code>, but with <code>(X or Y)</code>; you need to ask <code>(X or Y)</code> first, and the True jump of X is brand new at this time, and you don’t know the previous The False jump list of A; and then when asking <code>A and (X or Y)</code>, the two jump lists of True and False coexist; the False at the end of the final statement merges the False jump list of A before, and Termination of X's True jump list.</p>
</li>
<li>
<p>The end of the judgment statement corresponds to the False jump, so the True jump list will be terminated and the False jump list will continue. After the end of the block, terminate the False jumpGo to the end of the block list. This is the case in the 4 figures above.</p>
</li>
</ul>
</li>
</ul>
<p>So far, the preparation knowledge has been introduced. Let's start coding.</p>
<h2 id="bytecode-2"><a class="header" href="#bytecode-2">Bytecode</a></h2>
<p>Several conditional judgment statements in the control structure in the previous chapter, including <code>if</code>, <code>while</code>, and <code>repeat..until</code>, etc., all deal with the judgment conditions and jump on False, so there is only one bytecode for testing and jumping, namely <code>Test</code>. But now we need 2 kinds of jumps, jump on False and jump on True. For this reason, we remove the previous <code>Test</code> and add 2 bytecodes:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     TestAndJump(u8, i16), // If Test is True, then Jump.
     TestOrJump(u8, i16), // Jump if Test is False. Same function as `Test` in the previous chapter.</code></pre>
<p>The &quot;And&quot; and &quot;Or&quot; in the naming have nothing to do with the logical operations introduced in this section, but are derived from the method names of the Option and Error types in the Rust language, meaning &quot;and then&quot; and &quot;otherwise then&quot; respectively. However, in the two examples at the beginning of this section, <code>t and t.k</code> can be described as: if t exists &quot;then then&quot; take t.k, <code>t.k or 100</code> can be described as: if t.k exists then take its value &quot;otherwise then&quot; Take 100. It can also be said to be related.</p>
<p>It’s just that the first jump rule introduced above, if it is followed by <code>and</code> operation, False jumps, corresponding to <code>TestOrJump</code>. The <code>and</code> and <code>Or</code> here do not correspond, but it doesn't matter much.</p>
<p>In the official Lua implementation, there is still only one bytecode <code>TEST</code>, which is associated with two parameters: the stack address of the judgment condition (same as ours), and the jump condition (True jump or False jump). For the specific jump position, you need to add a <code>JUMP</code> bytecode for an unconditional jump. It seems that 2 bytecodes are not very efficient. This is done for another application scenario, which will be introduced in the next section.</p>
<h2 id="expdesc-1"><a class="header" href="#expdesc-1">ExpDesc</a></h2>
<p>When parsing logical operators to generate jump bytecodes, the destination of the jump is not yet known. Only one bytecode placeholder can be generated first, and the parameter of the jump position is left blank. The parameters are filled in after the destination location is determined later. This approach is the same as when we introduced control structures in the previous chapter. The difference is that there was only one jump bytecode in the previous chapter, but this time there may be multiple bytecode zippers, such as the first picture above, 3 bytecode jumps Go to the same location. This zipper may be a True jump or a False jump, or these two chains may exist at the same time, such as when Y is resolved in the fourth figure above. So a new ExpDesc type is needed to save the jump list. To this end, a new <code>Test</code> type is defined as follows:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     Test(usize, Vec&lt;usize&gt;, Vec&lt;usize&gt;), // (condition, true-list, false-list)</code></pre>
<p>Associate 3 parameters. The first one is to determine the position of the condition on the stack. No matter what type (constant, variable, table index, etc.) it will be discharged to the stack first, and then the true or false will be judged. The next two parameters are the two jump lists of True and False, and the contents are the positions of the bytecodes that need to be completed.</p>
<p>In the official implementation of Lua, the jump list is implemented by jumping to the blank parameters in the bytecode. For example, if there are three consecutive False jumps in the first figure above, the bytecodes generated by judging A, B, and C are <code>JUMP 0</code>, <code>JUMP $A</code>, <code>JUMP $B</code>, and then save them in ExpDesc <code>$C</code>. In this way, <code>$B</code> can be found through <code>$C</code>, <code>$A</code> can be found through <code>$B</code>, and the parameter <code>0</code> indicates the end of the linked list. Finally, while traversing, it is uniformly fixed as <code>JUMP $end</code>. This design is very efficient, without additional storage, and the zipper can be realized by using the Jump parameter that is temporarily left blank. At the same time, it is also slightly obscure and error-prone. This kind of full use of resources and micro-manipulation of memory according to bits is a very typical practice of C language projects. The Rust language standard library provides a list Vec, although it will generate memory allocation on the heap, which slightly affects performance, but the logic is much clearer and clear at a glance. As long as it is not a performance bottleneck, obscure and dangerous practices should be avoided as much as possible, especially when using the safety-oriented Rust language.</p>
<h2 id="syntax-analysis-5"><a class="header" href="#syntax-analysis-5">Syntax Analysis</a></h2>
<p>Now it is finally ready to parse. Start with the binary operation part of the <code>exp()</code> function. Before introducing the <a href="./ch05-02.binary_ops.html#evaluation-order">evaluation order</a> of binary numerical operations, the first operand must be processed first. It is also introduced at the beginning of this section that for the processing order of logical operations, due to the short-circuit characteristics, the first operation and possible jumps must be processed first, and then the second operand can be parsed. So, before continuing to parse the second operand, the jump is handled:</p>
<pre><code class="language-rust  ignore">     fn preprocess_binop_left(&amp;mut self, left: ExpDesc, binop: &amp;Token) -&gt; ExpDesc {
         match binop {
             Token::And =&gt; ExpDesc::Test(0, Vec::new(), self. test_or_jump(left)),
             Token::Or =&gt; ExpDesc::Test(0, self. test_and_jump(left), Vec::new()),

             _ =&gt; // Omit the part of other types of discharge
         }
     }</code></pre>
<p>In this function, the processing part of logical operation is added. Take <code>and</code> as an example, generate <code>ExpDesc::Test</code> type, temporarily save the processed 2 jump lists, and the associated first parameter is useless, fill in 0 here. Call the <code>test_or_jump()</code> function to process the jump list. According to the rules introduced above, the and operator corresponds to the False jump, which will terminate the previous True jump list, so the <code>test_or_jump()</code> function will terminate the previous True jump list and return only the False jump list. Then create a new list <code>Vec::new()</code> here as the True jump list.</p>
<p>Look at the specific implementation of <code>test_or_jump()</code>:</p>
<pre><code class="language-rust  ignore">     fn test_or_jump(&amp;mut self, condition: ExpDesc) -&gt; Vec&lt;usize&gt; {
         let (icondition, true_list, mut false_list) = match condition {
             // It is a constant of True, no need to test or jump, skip it directly.
             // Example: while true do ... end
             ExpDesc::Boolean(true) | ExpDesc::Integer(_) | ExpDesc::Float(_) | ExpDesc::String(_) =&gt; {
                 return Vec::new();
             }

             // The first operand is already of type Test, indicating that this
             // is not the first logical operator.
             // Just return the existing two jump lists directly.
             ExpDesc::Test(icondition, true_list, false_list) =&gt;
                 (icondition, Some(true_list), false_list),

             // The first operand is another type, indicating that this is the
             // first logical operator.
             // Only need to discharge the first operand to the stack.
             // There was no True jump list before, so return None.
             // There was no False jump list before, so create a new list to save
             // this jump instruction.
             _ =&gt; (self. discharge_any(condition), None, Vec::new()),
         };

         // generate TestOrJump, but leave the second parameter blank
         self.byte_codes.push(ByteCode::TestOrJump(icondition as u8, 0));

         // Put the newly generated bytecode, if it is in the False jump list,
         // for subsequent repair
         false_list.push(self.byte_codes.len() - 1);

         // Finalize the previous True jump list and jump here, if any
         if let Some(true_list) = true_list {
             self.fix_test_list(true_list);
         }

         // return False jump list
         false_list
     }</code></pre>
<p>For the <code>or</code> operator and the corresponding <code>test_and_jump()</code> function, it is similar, just flip the True and False jump lists. It will not be introduced here.</p>
<p>After processing the first operand and the jump, it is very simple to process the second operand, just connect the jump list:</p>
<pre><code class="language-rust  ignore">     fn process_binop(&amp;mut self, binop: Token, left: ExpDesc, right: ExpDesc) -&gt; ExpDesc {
         match binop {
             // omit other binary operator processing
             Token::And | Token::Or =&gt; {
                 // The first operand has been converted to ExpDesc::Test in preprocess_binop_left() above
                 if let ExpDesc::Test(_, mut left_true_list, mut left_false_list) = left {
                     let icondition = match right {
                         // If the second operand is also of Test type, such as the example
                         // of `A and (X or Y)` in the fourth figure above in this section,
                         // Then connect the two jump lists separately.
                         ExpDesc::Test(icondition, mut right_true_list, mut right_false_list) =&gt; {
                             left_true_list.append(&amp;mut right_true_list);
                             left_false_list.append(&amp;mut right_false_list);
                             icondition
                         }
                         // If the second operand is another type, there is no need to deal with the jump list
                         _ =&gt; self.discharge_any(right),
                     };

                     // After returning to the connection, I want to create a new jump list
                     ExpDesc::Test(icondition, left_true_list, left_false_list)
                 } else {
                     panic!(&quot;impossible&quot;);
                 }
             }</code></pre>
<p>After dealing with the binary operation part, the next step is the application scenario. This section only introduces the application scenarios used as judgment conditions, and the evaluation will be introduced in the next section. Several control structure statements (if, while, repeat..until, etc.) directly process the jump bytecode, and the code logic is similar. In the jump rules introduced at the beginning of this section, the judgment statement of the entire logical operation ends, which is a False jump, so calling the test_or_jump() function just introduced can replace and simplify the code that directly processes bytecodes in the previous chapter logic. Here we still use the if statement as an example:</p>
<pre><code class="language-rust  ignore">     fn do_if_block(&amp;mut self, jmp_ends: &amp;mut Vec&lt;usize&gt;) -&gt; Token {
         let condition = self. exp();

         // In the previous chapter, here is to generate Test bytecode.
         // Now, replace and simplify to the test_or_jump() function.
         // Terminate the True jump list and return a new False jump list.
         let false_list = self. test_or_jump(condition);

         self.lex.expect(Token::Then);

         let end_token = self. block();

         if matches!(end_token, Token::Elseif | Token::Else) {
             self.byte_codes.push(ByteCode::Jump(0));
             jmp_ends.push(self.byte_codes.len() - 1);
         }

         // In the last chapter, here is to fix a Test bytecode just generated.
         // Now, a False jump list needs to be modified.
         self.fix_test_list(false_list);

         end_token
     }</code></pre>
<p>This completes the syntax analysis part.</p>
<h2 id="virtual-machine-execution-5"><a class="header" href="#virtual-machine-execution-5">Virtual Machine Execution</a></h2>
<p>The execution part of the virtual machine first needs to process the newly added 2 bytecodes, which are very simple and will be ignored here. What needs to be said is the details of a stack operation. The function when assigning a value to the stack before is as follows:</p>
<pre><code class="language-rust  ignore">     fn set_stack(&amp;mut self, dst: u8, v: Value) {
         let dst = dst as usize;
         match dst.cmp(&amp;self.stack.len()) {
             Ordering::Equal =&gt; self. stack. push(v),
             Ordering::Less =&gt; self.stack[dst] = v,
             Ordering::Greater =&gt; panic!(&quot;fail in set_stack&quot;),
         }
     }</code></pre>
<p>First determine whether the target address dst is within the range of the stack:</p>
<ul>
<li>If it is, assign it directly;</li>
<li>If it is not and it is just the next position, use <code>push()</code> to push it onto the stack;</li>
<li>If not, and past the next position, it was impossible to appear before, so call <code>panic!()</code>.</li>
</ul>
<p>However, the short-circuit characteristics of logic operations may lead to the above-mentioned third situation. For example the following statement:</p>
<pre><code class="language-lua">if (g1 or g2) and g3 then
end
</code></pre>
<p>According to our analysis method, the following temporary variables will be generated, occupying the position on the stack:</p>
<pre><code>|      |
+------+
|  g1  |
+------+
|  g2  |
+------+
|  g3  |
+------+
|      |
</code></pre>
<p>But during execution, if <code>g1</code> is true, the processing of <code>g2</code> will be skipped, and <code>g3</code> will be processed directly. At this time, the position of g2 in the above figure is not set, then g3 will exceed the top of the stack position, as shown in the figure below:</p>
<pre><code>|      |
+------+
|  g1  |
+------+
|      |
:      :
:      : &lt;-- set g3, beyond the top of the stack
</code></pre>
<p>Therefore, it is necessary to modify the above <code>set_stack()</code> function to support setting elements beyond the top of the stack. This can be achieved by calling <code>set_vec()</code>.</p>
<h2 id="test-7"><a class="header" href="#test-7">Test</a></h2>
<p>So far, the application scenario of logical operation in conditional judgment has been completed. This can be tested with the examples in the figures at the beginning of this section. omitted here.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logical-operations-in-evaluation"><a class="header" href="#logical-operations-in-evaluation">Logical Operations in Evaluation</a></h1>
<p>The previous section introduced the logical operations in conditional judgment. This section introduces another scenario, that is, the evaluation.</p>
<p>In the previous section, the syntax analysis process of logical operations in <em>conditional judgment</em> scenarios can be divided into two parts:</p>
<ul>
<li>
<p>Process the logical operation itself, specifically, after encountering the <code>and</code> or <code>or</code> operator in the <code>exp()</code> function, generate the corresponding bytecode and process the True and False jump lists;</p>
</li>
<li>
<p>After the entire logic operation statement is parsed, put the parsing result into the conditional judgment scene of the <code>if</code> statement, first terminate the True jump list, and then terminate the False jump list after the end of the block.</p>
</li>
</ul>
<p>In the <em>evaluation</em> scenario to be introduced in this section, it is also divided into two parts:</p>
<ul>
<li>
<p>Dealing with the logical operation itself, this part is exactly the same as the previous section;</p>
</li>
<li>
<p>After the entire logical operation statement is parsed, the statement is <em>evaluated</em>, which is the part to be introduced in this section.</p>
</li>
</ul>
<p>As shown in the figure below, the previous section completed parts (a) and (b), and this section implements part (c) on the basis of (a).</p>
<pre><code>                                               +------------------------+
+--------------------+                    /---&gt;| (b) Condition judgment |
| (a) Process        |   ExpDesc::Test   |     +------------------------+
| logical operations |------------------&gt;+
+--------------------+                   |     +-----------------+
                                          \---&gt;| (c) Evaluation  |
                                               +-----------------+
</code></pre>
<h2 id="result-type"><a class="header" href="#result-type">Result Type</a></h2>
<p>Logical operations in Lua are different from those in C and Rust. The results of logical operations in C and Rust languages are Boolean types, which only distinguish between true and false. For example, the following C language code:</p>
<pre><code class="language-c">int i=10, j=11;
printf(&quot;%d\n&quot;, i &amp;&amp; j); // output: 1
</code></pre>
<p>Will output <code>1</code>, because the <code>&amp;&amp;</code> operator will first convert the two operands to Boolean type (both are true in this example), and then execute the <code>&amp;&amp;</code> operation, the result is true, which is <code>1</code> in C language. The Rust language is stricter, both operands of <code>&amp;&amp;</code> must be of Boolean type, so the result is also of Boolean type.</p>
<p>But logical operations in Lua evaluate to the last <em>evaluated</em> operand. For example, the following are very common usages:</p>
<ul>
<li>
<p><code>print(t and t.k)</code>, first judge whether <code>t</code> exists, and then find the index of <code>t</code>. If <code>t</code> does not exist, then there is no need to judge <code>t.k</code>, so the result is <code>t</code> which is <code>nil</code>; otherwise, it is <code>t.k</code>.</p>
</li>
<li>
<p><code>print(t.k or 100)</code>, index the table and provide a default value. First judge whether there is <code>k</code> in <code>t</code>, if there is, then there is no need to judge <code>100</code>, so the result is <code>t.k</code>; otherwise it is <code>100</code>.</p>
</li>
<li>
<p><code>print(v&gt;0 and v or -v)</code>, find the absolute value. The result is <code>v</code> if positive, and <code>-v</code> otherwise. Simulates the <code>?:</code> ternary operator in C.</p>
</li>
</ul>
<h2 id="evaluation-rules"><a class="header" href="#evaluation-rules">Evaluation Rules</a></h2>
<p>In order to understand the sentence &quot;the evaluation result of a logical operation is the last evaluated operand&quot; more clearly, some examples are shown below. Here we still use the flowchart at the beginning of the previous section as an example. Let's look at the most basic operations first:</p>
<pre><code> A and B                      X or Y

+-------+                    +-------+
|   A   +-False-\    /--True-+   X   |
+---+---+       |    |       +---+---+
    |True       |    |           |False
    V           |    |           V
+-------+       |    |       +-------+
|   B   |       |    |       |   Y   |
+---+---+       |    |       +---+---+
    |&lt;----------/    \----------&gt;|
    V                            V
</code></pre>
<p>In the figure on the left, if A is False, the evaluation result is A; otherwise, when B is evaluated, since B is the last operand, there is no need to make a judgment, and B is the evaluation result.</p>
<p>In the figure on the right, if X is True, the evaluation result is X; otherwise, when Y is evaluated, since Y is the last operand, there is no need to make a judgment, and Y is the evaluation result.</p>
<p>Let's look at a few more complex examples:</p>
<pre><code>A and B and C               X or Y or Z                 (A and B) or Y               A and (X or Y)

+-------+                    +-------+                    +-------+                    +-------+
|   A   +-False-\    /--True-+   X   |                    |   A   |-False-\            |   A   +-False-\
+---+---+       |    |       +---+---+                    +---+---+       |            +---+---+       |
    |True       |    |           |False                       |True       |                |True       |
    V           |    |           V                            V           |                V           |
+-------+       |    |       +-------+                    +-------+       |            +-------+       |
|   B   +-False&gt;+    +&lt;-True-+   Y   |            /--True-+   B   |       |    /--True-+   X   |       |
+---+---+       |    |       +---+---+            |       +---+---+       |    |       +---+---+       |
    |True       |    |           |False           |      False|&lt;---------/     |           |False      |
    V           |    |           V                |           V                |           V           |
+-------+       |    |       +-------+            |       +-------+            |       +-------+       |
|   C   |       |    |       |   Z   |            |       |   Y   |            |       |   Y   |       |
+---+---+       |    |       +---+---+            |       +---+---+            |       +---+---+       |
    |&lt;---------/     \----------&gt;|                \----------&gt;|                \----------&gt;|&lt;---------/
    V                            V                            V                            V
</code></pre>
<p>The process of summarizing based on these 4 figures is omitted here, and the evaluation rules are directly given:</p>
<ol>
<li>
<p>The last operand does not need to be judged, as long as the previous judgment does not skip the last operand, then the last operand is the final evaluation result. For example, in the first figure above, if both A and B are True, then C will be executed, and C is the evaluation result of the entire statement. C itself does not need to make judgments.</p>
</li>
<li>
<p>In the syntax analysis stage, after the parsing of the entire logical operation statement is completed, the operands on the unterminated jump list may be used as the final evaluation result. This statement is rather convoluted, and the following example illustrates it. For example, in the first figure above, the True jump lists of A and B end in B and C respectively, but the False jump lists are not terminated, then both A and B may be the final evaluation results, for example, if A is False Then A is the final evaluation result. As another counter-example, for example, the two jump lists of A’s True and False in the third figure above are terminated in B and Y respectively, that is to say, when the entire statement is parsed, the jump lists of A are terminated. , then A cannot be the evaluation result, and in either case A will not reach the end of the statement. Except for the third figure, all judgment conditions in other figures may be used as the final evaluation result.</p>
</li>
</ol>
<p>After summarizing the evaluation rules, let's start coding.</p>
<h2 id="expdesc-2"><a class="header" href="#expdesc-2">ExpDesc</a></h2>
<p>A new ExpDesc type representing logical operations was introduced in the previous section and is defined as follows:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     Test(usize, Vec&lt;usize&gt;, Vec&lt;usize&gt;), // (condition, true-list, false-list)</code></pre>
<p>The latter two parameters respectively represent two jump linked lists, which will not be introduced here, and focus on the first parameter: the position of the judgment conditional statement on the stack. As mentioned in the previous section, all statements (such as variables, constants, table indexes, etc.) must be discharged to the stack first to determine whether they are true or false, so here we can use the stack index of <code>usize</code> type to represent the statement. This is no problem in the previous section, but in the evaluation scenario in this section, as mentioned above, the last operand does not need to be judged, so it may not need to be discharged to the stack. Like the following example:</p>
<pre><code class="language-lua">local x = t and t.k
</code></pre>
<p>According to the current practice, first discharge the second operand t.k to a temporary variable on the stack; if t is true, assign the temporary variable to x through <code>Move</code> bytecode. Obviously this temporary variable is unnecessary, and t.k can be directly assigned to x. To do this, we need to delay the evaluation of the conditional statement, or delay the discharge. Then you need to transform the <code>ExpDesc::Test</code> type.</p>
<p>Lua's official approach is to assign two jump lists to all types of ExpDesc:</p>
<pre><code class="language-c">typedef struct expdesc {
   expkind k; // type tag
   union {
     // Data associated with various expkinds, omitted here
   } u;
   int t; /* patch list of 'exit when true' */
   int f; /* patch list of 'exit when false' */
} expdesc;
</code></pre>
<p><code>t</code> and <code>f</code> in the above code are the jump lists of True and False respectively. But it is a bit inconvenient to define it in the Rust language. Because Rust's enum includes tags and associated data, corresponding to <code>k</code> and <code>u</code> above, one enum can define ExpDesc; but if you add two jump lists, you need to encapsulate a layer of struct outside Defined. And the struct variable is defined in the Rust languageWhen all members must be explicitly initialized, then in all places where ExpDesc is defined in the code, <code>t</code> and <code>f</code> must be initialized to Vec::new(). It's not worth it to affect other types for this one type.</p>
<p>Our approach is to define ExpDesc::Test recursively. Change the first parameter type of <code>ExpDesc::Test</code> from <code>usize</code> to <code>ExpDesc</code>. Of course, it cannot be defined directly, but it needs to <a href="https://doc.rust-lang.org/stable/book/ch15-01-box.html#enabling-recursive-types-with-boxes">encapsulate a layer of Box pointer</a>:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     Test(Box&lt;ExpDesc&gt;, Vec&lt;usize&gt;, Vec&lt;usize&gt;), // (condition, true-list, false-list)</code></pre>
<p>This definition has no effect on other types of ExpDesc in the existing code. For the <code>Test</code> type in the existing code, it is only necessary to remove the discharge processing.</p>
<h2 id="bytecode-3"><a class="header" href="#bytecode-3">Bytecode</a></h2>
<p>The functions of the two new bytecodes <code>TestAndJump</code> and <code>TestOrJump</code> in the previous section are both: &quot;test&quot; + &quot;jump&quot;. And the function we need now is: &quot;test&quot; + &quot;assignment&quot; + &quot;jump&quot;. To this end, we add 2 more bytecodes:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Jump(i16),
     TestAndJump(u8, i16),
     TestOrJump(u8, i16),
     TestAndSetJump(u8, u8, u8), // add
     TestOrSetJump(u8, u8, u8), // add</code></pre>
<p>The function of <code>TestAndSetJump</code> is: if the value of the first parameter is tested to be true, it is assigned to the stack position of the second parameter and jumps to the bytecode position of the third parameter. Similar to <code>TestOrSetJump</code>.</p>
<p>Here comes a problem. In the previous jump bytecodes (the first 3 in the above code), the jump parameters are all 2 bytes, <code>i16</code> type, and the range of jumps can be large. And the newly added 2 bytecodes are associated with 3 parameters, so there is only one byte left for the jump parameter.</p>
<p>This is why, as mentioned in the previous section, in the official implementation of Lua, 2 bytecodes are used to represent conditional jump instructions. For example, as opposed to <code>TestAndJump(t, jmp)</code>, it is <code>TEST(t, 0); JUMP(jmp)</code>; and in the evaluation scenario introduced in this section, it is necessary to add a target address parameter dst, which is <code>TESTSET (dst, t, 0); JUMP(jmp)</code>. This ensures that the jump parameter has 2 bytes of space. Moreover, although there are 2 bytecodes, during the execution of the virtual machine, when the <code>TEST</code> or <code>TESTSET</code> bytecode is executed, if a jump is required, the parameter of the next bytecode JUMP can be directly removed And execute the jump without having to do another instruction dispatch for the JUMP. It is equivalent to 1 bytecode, and JUMP is only used as an extended parameter, so it does not affect the performance during execution.</p>
<p>But we still use 1 byte code here, and use 1 byte to represent the jump parameter. In the conditional judgment scenario in the previous section, the judgment of the last operand is to jump to the end of the entire block, and the jump distance may be very long, requiring 2 bytes of space. In the evaluation scenario in this section, only jumps are made within the logic operation statement. You can refer to the above 6 figures, and the jump distance will not be very long; and since it only jumps forward, there is no need to represent negative numbers. So 1 byte <code>u8</code> type means that 256 distances are enough to cover. When conditions permit, 1 bytecode is always better than 2.</p>
<h2 id="syntax-analysis-6"><a class="header" href="#syntax-analysis-6">Syntax Analysis</a></h2>
<p>After introducing the above modification points, now start the syntax analysis. The so-called evaluation is discharge. So we only need to complete the <code>ExpDesc::Test</code> type in the <code>discharge()</code> function. In the previous section, this is not complete. The specific discharge method is: first discharge the recursively defined conditional statement, and then repair the judgment bytecodes in the two jump lists.</p>
<pre><code class="language-rust  ignore">     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             // omit other types
             ExpDesc::Test(condition, true_list, false_list) =&gt; {
                 // fix TestSet list after discharging

                 // first discharge the recursively defined conditional statement
                 self.discharge(dst, *condition);

                 // Fix the judgment bytecode in the True jump list
                 self.fix_test_set_list(true_list, dst);
                 // Fix the judgment bytecode in the False jump list
                 self.fix_test_set_list(false_list, dst);
                 return;
             }</code></pre>
<p>Fixing the jump list <code>fix_test_set_list()</code> function needs to do 2 things:</p>
<ul>
<li>fill jump parameters that were left blank before;</li>
<li>Replace the previously generated <code>TestAndJump</code> and <code>TestOrJump</code> bytecodes with <code>TestAndSetJump</code> and <code>TestOrSetJump</code> respectively.</li>
</ul>
<p>The specific code is as follows:</p>
<pre><code class="language-rust  ignore">     fn fix_test_set_list(&amp;mut self, list: Vec&lt;usize&gt;, dst: usize) {
         let here = self.byte_codes.len();
         let dst = dst as u8;
         for i in list.into_iter() {
             let jmp = here - i - 1; // should not be negative
             let code = match self. byte_codes[i] {
                 ByteCode::TestOrJump(icondition, 0) =&gt;
                     if icondition == dst {
                         // If the conditional statement is just at the target position,
                         // there is no need to change it to TestAndSetJump
                         ByteCode::TestOrJump(icondition, jmp as i16)
                     } else {
                         // Modify to TestAndSetJump bytecode
                         ByteCode::TestOrSetJump(dst as u8, icondition, jmp as u8)
                     }
                 ByteCode::TestAndJump(icondition, 0) =&gt;
                     if icondition == dst {
                         ByteCode::TestAndJump(icondition, jmp as i16)
                     } else {
                         ByteCode::TestAndSetJump(dst as u8, icondition, jmp as u8)
                     }
                 _ =&gt; panic!(&quot;invalid Test&quot;),
             };
             self.byte_codes[i] = code;
         }
     }</code></pre>
<h2 id="test-8"><a class="header" href="#test-8">Test</a></h2>
<p>So far, the application scenario of logical operations in evaluation has been completed. This can be tested with the examples in the figures at the beginning of this section. omitted here.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="relational-operations-in-conditional-judgment"><a class="header" href="#relational-operations-in-conditional-judgment">Relational Operations in Conditional Judgment</a></h1>
<p>The previous two sections describe logical operations, and the next two describe relational operations.</p>
<p>Relational operations, that is, compares, have 6 operators: equal, not equal, greater than, less than, greater than or equal to, less than or equal to. When introducing logical operations in the previous two sections, it was said that logical operations cannot use the analysis process of binary numerical operations in Chapter 5 because of the short-circuit feature. The relational operations did not use the parsing process in Chapter 5, for a different reason: for performance.</p>
<p>If performance is not considered, relational operations can use the parsing process in Chapter 5. For example, for the equal operation, the following bytecode can be generated: <code>EQ $r $a $b</code>, that is, compare <code>a</code> and <code>b</code>, and assign the Boolean result to <code>r</code>. If performance is to be considered, it depends on the application scenarios of relational operations. This part is almost the same as the logical operations introduced in the previous two sections, and there are also two application scenarios:</p>
<ol>
<li>As a judgment condition, such as the judgment condition statement in the if, while and other statements in the previous chapter, such as <code>if a == b then ...</code>;</li>
<li>Evaluation, such as <code>print(a == b)</code>.</li>
</ol>
<p>Like logical operations, the first scenario can be regarded as a simplified version of the second scenario. It does not require specific evaluation, but only needs to judge whether it is true or false. For example, the example of the if statement above can also be interpreted according to the second scenario. It is considered that <code>a == b</code> is first evaluated to a temporary variable, and then it is judged whether the temporary variable is true to decide whether to jump. Temporary variables can be omitted here! Since most applications of relational computing are in the first scenario, it is worthwhile to separate this scenario from the second general scenario for special optimization, by omitting temporary variables and directly judging whether to jump based on the evaluation result.</p>
<p>As the title of this section indicates, this section only introduces the first scenario; the next section will introduce the second scenario.</p>
<h2 id="bytecode-4"><a class="header" href="#bytecode-4">Bytecode</a></h2>
<p>Still using the <code>if</code> statement and the equal operation as an example, in the <code>if a == b then ... end</code> scenario, the first bytecode sequence that comes to mind is as follows:</p>
<pre><code>EQ $tmp $a $b    # Compare whether a and b are equal, and the result is stored in a temporary variable
TEST $tmp $jmp   # Determine whether to jump according to the temporary variable
</code></pre>
<p>Now save the temporary variable $tmp and merge the two bytecodes, as follows:</p>
<pre><code>EQ $a $b $jmp   # Compare whether a and b are equal to decide whether to jump
</code></pre>
<p>But the problem is that this requires 3 parameters, leaving only 1 byte of space for the last jump parameter, indicating that the range is too small. For this reason, it can be split into 2 bytecodes:</p>
<pre><code>EQ $a $b      # Determine whether a and b are equal, if they are equal, skip the next statement, ie pc++
JUMP $jmp     # unconditional jump
</code></pre>
<p>In this way, 2 bytes can be used to represent the jump parameter. However, since 2 bytecodes are still needed, what is the difference from the original &quot;EQ+TEST&quot; scheme? Why make it so complicated?</p>
<ul>
<li>
<p>When the virtual machine is executing, if it is judged that <code>a</code> and <code>b</code> are equal and the following JUMP bytecode is skipped, then only 1 bytecode is executed; while the original &quot;EQ+TEST&quot; scheme always executes 2 bytes code. I don’t know the probability that the if statement is true, but the probability of the while statement is true is still very high, so this is equivalent to saving the execution of 1 bytecode with a high probability;</p>
</li>
<li>
<p>Even if the judgment is false and the following JUMP bytecode needs to be executed, then the next bytecode can be read directly when the EQ bytecode is executed, without having to go through another instruction distribution. The JUMP bytecode here is equivalent to an extended parameter of the EQ bytecode, rather than an independently executed bytecode. This is what Lua's official implementation does. This is also because the type of bytecode can be ignored in C language, and the parameters in the bytecode can be directly read through bit operations. But in the Rust language, if unsafe is not used, the enum tag cannot be ignored and the parameters can be read directly, so this optimization cannot be implemented in our interpreter.</p>
</li>
<li>
<p>We can directly decide whether to jump or not according to the judgment result. In the original &quot;EQ+TEST&quot; scheme, it is necessary to write the judgment result into a temporary variable on the stack first, then read the temporary variable when the TEST bytecode is executed, and then judge true or false again, thus adding a temporary variable Reading and writing, but also a true or false judgment.</p>
</li>
</ul>
<p>The advantage is such an advantage. Yes, but not much. Especially compared with the implementation complexity it brings, it is even less. The original &quot;EQ+TEST&quot; scheme only needs to add a few operators to the <a href="./ch05-02.binary_ops.html">Binary Numerical Operation</a> introduced earlier; but the new scheme needs to be described earlier logical operation coordination. However, we still choose to follow the official implementation of Lua, and trade the complexity of the implementation for some execution efficiency optimization.</p>
<p>In addition, regarding the types of the two operands in the bytecode, according to the previous description of <a href="./ch04-05.table_rw_and_bnf.html#execute-the-assignment">Bytecode Parameter Type</a>, it is similar to the bytecode of the binary value operation, each relational operator also corresponds to 3 bytecodes, for example, for equality operators: <code>Equal</code>, <code>EqualInt</code> and <code>EqualConst</code>, a total of 3 bytecodes. A total of 6 relational operators are 18 bytecodes.</p>
<h2 id="combined-with-logical-operations"><a class="header" href="#combined-with-logical-operations">Combined with Logical Operations</a></h2>
<p>Combining relational and logical operations is very common. Take the <code>a&gt;b and b&lt;c</code> statement as an example. According to the introduction in the previous two sections, this is a logical operation statement. The two operands are <code>a&gt;b</code> and <code>b&lt;c</code> respectively. The operand discharges to a temporary variable on the stack in order to judge true or false. In order to avoid the use of temporary variables here, it is necessary to make relational operations and logical operations cooperate with each other.</p>
<p>For relational operation statements, the ExpDesc type needs to be added: <code>Compare</code>. Let's see what parameters need to be associated with this type if it is to be combined with logical operations, that is, for logical operation statements that use relational operations as operands.</p>
<p>First of all, if it is not converted to the <code>ExpDesc::Test</code> type, then the <code>Compare</code> type needs to maintain two jump lists of True and False;</p>
<p>Secondly, for the two jumps of True and False, the previous logical operations are distinguished by 2 bytecodes, <code>TestAndJump</code> and <code>TestOrJump</code>. The same can be done for relational operations, such as <code>EqualTrue</code> and <code>EqualFalse</code> bytecodes for equal operations. However, the relational operators have a total of 18 bytecodes. If each bytecode needs to distinguish between True and False jumps, then 36 bytecodes are required. That's too many! Fortunately, there is another method. The <code>EQ</code> bytecode introduced above only has 2 parameters, and a Boolean parameter can be added to indicate whether to jump True or False.</p>
<p>Finally, for the two jumps of True and False, it needs to be determined according to the logical operator behind it. For example, in the above example of <code>a&gt;b and b&lt;c</code>, it cannot be determined when it is parsed to <code>a&gt;b</code>, but it can only be determined when it is parsed to <code>and</code>. Therefore, the complete bytecode cannot be generated when parsing the relational operation statement, so the relevant information can only be stored in the <code>Compare</code> type first, and then the bytecode is generated after the jump type is determined.</p>
<p>In summary, the new types of relational operations are defined as follows:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     Compare(fn(u8,u8,bool)-&gt;ByteCode, usize, usize, Vec&lt;usize&gt;, Vec&lt;usize&gt;),</code></pre>
<p>The first 3 parameters are bytecode type and the first 2 parameters are used to generate bytecode after determining the jump type; the latter 2 parameters are True and False jump lists. The whole type is equivalent to the combination of <code>BinaryOp</code> and <code>Test</code> types.</p>
<p>Here is the same problem as the logical operation introduced earlier. When the bytecode is generated, the destination address of the jump cannot be determined, and the complete bytecode cannot be generated immediately. It needs to be processed after determining the destination address. . However, this is different from the previous logical operation solution. The previous logical operation method is: first generate a bytecode placeholder, and only leave the parameters of the jump destination address blank; after determining the destination address, fix the corresponding parameters in the bytecode (<code>fix_test_list()</code> function ). The method of relational operation here is to store all the information in <code>ExpDesc::Compare</code> (causing the definition of this type to be very long), and then directly generate the complete bytecode after the destination address is determined later.</p>
<p>In fact, for the processing of relational operations, theoretically, logical operations can also be used to generate bytecodes and then repair them. However, there are 18 bytecodes corresponding to relational operations, which is too many. If you still follow <code>fix_test_list()</code> the method of function matching first and then generating bytecode, the code is too complicated. If it is in the C language, the parameters in the bytecode can be directly corrected by bit operations, regardless of the bytecode type; while directly modifying the associated parameters in the enum in Rust requires unsafe.</p>
<p>Another difference is that when parsing logical operations, bytecodes must be generated immediately to take place. The <code>Compare</code> type operand of the relational operation will determine the jump type in the <code>test_or_jump()</code> function immediately after, and then the bytecode can be generated, so there is no need to occupy a place, and there is no need to generate a word first. section code then fixed it again.</p>
<h2 id="syntax-analysis-7"><a class="header" href="#syntax-analysis-7">Syntax Analysis</a></h2>
<p>The syntax analysis of relational operations is divided into two parts:</p>
<ul>
<li>
<p>The parsing operation itself generates the corresponding <code>ExpDesc::Compare</code> according to the operator. This part is similar to <a href="./ch05-02.binary_ops.html">Binary Numerical Operation</a>, which is skipped here.</p>
</li>
<li>
<p>The combination of relational operations and logical operations, that is, the combination of <code>ExpDesc::Compare</code> and <code>ExpDesc::Test</code>. In the previous analysis of logical operations, the processing of <code>ExpDesc::Compare</code> has been added.</p>
</li>
</ul>
<p>For example, when the left operand is logically operated, bytecode is generated and two jump lists are processed:</p>
<pre><code class="language-rust  ignore">     fn test_or_jump(&amp;mut self, condition: ExpDesc) -&gt; Vec&lt;usize&gt; {
         let (code, true_list, mut false_list) = match condition {
             ExpDesc::Boolean(true) | ExpDesc::Integer(_) | ExpDesc::Float(_) | ExpDesc::String(_) =&gt; {
                 return Vec::new();
             }
             // Add a Compare type.
             // Generate 2 bytecodes.
             // The two jump lists are handled in the same way as `ExpDesc::Test` below.
             ExpDesc::Compare(op, left, right, true_list, false_list) =&gt; {
                 // If it is determined to be a True jump, that is, the associated
                 // third parameter, the complete bytecode can be generated.
                 self.byte_codes.push(op(left as u8, right as u8, true));

                 // Generate Jump bytecode, but the jump destination address is not
                 // yet known, and subsequent repairs are required. to this end,
                 // Add processing of Jump bytecode in fix_test_list().
                 (ByteCode::Jump(0), Some(true_list), false_list)
             }
             ExpDesc::Test(condition, true_list, false_list) =&gt; {
                 let icondition = self.discharge_any(*condition);
                 (ByteCode::TestOrJump(icondition as u8, 0), Some(true_list), false_list)
             }
             _ =&gt; {
                 let icondition = self.discharge_any(condition);
                 (ByteCode::TestOrJump(icondition as u8, 0), None, Vec::new())
             }
         };</code></pre>
<p>now dealing with the right operand:</p>
<pre><code class="language-rust  ignore">     fn process_binop(&amp;mut self, binop: Token, left: ExpDesc, right: ExpDesc) -&gt; ExpDesc {
         match binop {
             Token::And | Token::Or =&gt; {
                 if let ExpDesc::Test(_, mut left_true_list, mut left_false_list) = left {
                     match right {
                         // Add a Compare type.
                         // The processing method is similar to the `ExpDesc::Test` type below.
                         ExpDesc::Compare(op, l, r, mut right_true_list, mut right_false_list) =&gt; {
                             left_true_list.append(&amp;mut right_true_list);
                             left_false_list.append(&amp;mut right_false_list);
                             ExpDesc::Compare(op, l, r, left_true_list, left_false_list)
                         }
                         ExpDesc::Test(condition, mut right_true_list, mut right_false_list) =&gt; {
                             left_true_list.append(&amp;mut right_true_list);
                             left_false_list.append(&amp;mut right_false_list);
                             ExpDesc::Test(condition, left_true_list, left_false_list)
                         }
                         _ =&gt; ExpDesc::Test(Box::new(right), left_true_list, left_false_list),
                     }
                 } else {
                     panic!(&quot;impossible&quot;);
                 }
             }</code></pre>
<h2 id="virtual-machine-execution-6"><a class="header" href="#virtual-machine-execution-6">Virtual Machine Execution</a></h2>
<p>There are 6 relational operators in total. Since we have previously implemented the <code>Eq</code> trait for <code>Value</code>, the equal and not equal operations can use <code>==</code> and <code>!=</code> to directly compare the Value operands. But for the other 4 operators, you need to implement a new trait for <code>Value</code>, which is <code>PartialOrd</code>. The reason why it is not <code>Ord</code> is because different types of Value cannot be compared in size. There is no need to use <code>PartialEq</code> because different types of Value can be compared for equality, and the return result is False. For example, the following two statements:</p>
<pre><code class="language-lua">print (123 == 'hello') -- prints false
print (123 &gt; 'hello') -- throw exception
</code></pre>
<p>Lua's comparison operators only support numeric and string types. So the <code>PartialOrd</code> implementation of <code>Value</code> is as follows:</p>
<pre><code class="language-rust  ignore">impl PartialOrd for Value {
    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;std::cmp::Ordering&gt; {
        match (self, other) {
            // numbers
            (Value::Integer(i1), Value::Integer(i2)) =&gt; Some(i1.cmp(i2)),
            (Value::Integer(i), Value::Float(f)) =&gt; (*i as f64).partial_cmp(f),
            (Value::Float(f), Value::Integer(i)) =&gt; f.partial_cmp(&amp;(*i as f64)),
            (Value::Float(f1), Value::Float(f2)) =&gt; f1.partial_cmp(f2),

            // strings
            (Value::ShortStr(len1, s1), Value::ShortStr(len2, s2)) =&gt; Some(s1[..*len1 as usize].cmp(&amp;s2[..*len2 as usize])),
            (Value::MidStr(s1), Value::MidStr(s2)) =&gt; Some(s1.1[..s1.0 as usize].cmp(&amp;s2.1[..s2.0 as usize])),
            (Value::LongStr(s1), Value::LongStr(s2)) =&gt; Some(s1.cmp(s2)),

            // strings of different types
            (Value::ShortStr(len1, s1), Value::MidStr(s2)) =&gt; Some(s1[..*len1 as usize].cmp(&amp;s2.1[..s2.0 as usize])),
            (Value::ShortStr(len1, s1), Value::LongStr(s2)) =&gt; Some(s1[..*len1 as usize].cmp(s2)),
            (Value::MidStr(s1), Value::ShortStr(len2, s2)) =&gt; Some(s1.1[..s1.0 as usize].cmp(&amp;s2[..*len2 as usize])),
            (Value::MidStr(s1), Value::LongStr(s2)) =&gt; Some(s1.1[..s1.0 as usize].cmp(s2)),
            (Value::LongStr(s1), Value::ShortStr(len2, s2)) =&gt; Some(s1.as_ref().as_slice().cmp(&amp;s2[..*len2 as usize])),
            (Value::LongStr(s1), Value::MidStr(s2)) =&gt; Some(s1.as_ref().as_slice().cmp(&amp;s2.1[..s2.0 as usize])),

            (_, _) =&gt; None,
        }
    }
}</code></pre>
<p>For floating-point numbers, the <code>partial_cmp()</code> method needs to be called because the <code>Nan</code> of floating-point numbers cannot be compared.</p>
<p>Types that implement the <code>PartialOrd</code> trait can directly use several relatively large symbols such as <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, and <code>&lt;=</code>. But <code>PartialOrd</code> actually has 3 return results for comparison: true, false, and not comparable. Corresponding to the Lua language, they are true, false, and throw an exception. However, the above-mentioned 4 comparison symbols can only give 2 results, and return false if they cannot be compared. So in order to be able to judge the situation that cannot be compared, we cannot use these 4 symbols directly, but use the original <code>partial_cmp()</code> function. The following is the execution code of <code>LesEq</code> and <code>Less</code> two bytecodes:</p>
<pre><code class="language-rust  ignore">     ByteCode::LesEq(a, b, r) =&gt; {
         let cmp = &amp;self.stack[a as usize].partial_cmp(&amp;self.stack[b as usize]).unwrap();
         if !matches!(cmp, Ordering::Greater) == r {
             pc += 1;
         }
     }
     ByteCode::Less(a, b, r) =&gt; {
         let cmp = &amp;self.stack[a as usize].partial_cmp(&amp;self.stack[b as usize]).unwrap();
         if matches!(cmp, Ordering::Less) == r {
             pc += 1;
         }
     }</code></pre>
<p>Here <code>unwarp()</code> is used to throw an exception. In the follow-up, when standardizing error handling, improvements need to be made here.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="relational-operations-in-evaluation"><a class="header" href="#relational-operations-in-evaluation">Relational Operations in Evaluation</a></h1>
<p>The previous section introduced the relational operations in <em>conditional judgment</em>. This section introduces another scenario, that is, the processing during <em>evaluation</em>.</p>
<p>Similar to logical operations, to process the relationship judgment in the evaluation, we only need to discharge the <code>ExpDesc::Compare</code> parsed in the previous section to the stack. As shown in the figure below, the previous section completed parts (a) and (b), and this section implements part (c) on the basis of (a).</p>
<pre><code>                                                  +------------------------+
+-----------------------+                    /---&gt;| (b) Condition judgment |
| (a) Process           |   ExpDesc::Test   |     +------------------------+
| relational operations |------------------&gt;+
+-----------------------+                   |     +-----------------+
                                             \---&gt;| (c) Evaluation  |
                                                  +-----------------+                                              
</code></pre>
<p>The evaluation of the logical operation is to replace the <code>TestAndJump</code> and <code>TestOrJump</code> bytecodes in the two jump lists with <code>TestAndSetJump</code> and <code>TestOrSetJump</code> respectively. For relational operations, although we can also do it like this, it would be too verbose to add a Set version to all 18 bytecodes. Here we refer to the official implementation of Lua. For the following Lua code:</p>
<pre><code class="language-lua">print(123 == 456)
</code></pre>
<p>Compile the available bytecode sequence:</p>
<pre><code>luac  -l tt.lua

main &lt;tt.lua:0,0&gt; (9 instructions at 0x6000037fc080)
0+ params, 2 slots, 1 upvalue, 0 locals, 1 constant, 0 functions
    1	[1]	VARARGPREP	0
    2	[1]	GETTABUP 	0 0 0	; _ENV &quot;print&quot;
    3	[1]	LOADI    	1 456
    4	[1]	EQI      	1 123 1
    5	[1]	JMP      	1	; to 7
    6	[1]	LFALSESKIP	1
    7	[1]	LOADTRUE 	1
    8	[1]	CALL     	0 2 1	; 1 in 0 out
    9	[1]	RETURN   	0 1 1	; 0 out
</code></pre>
<p>Among them, the 4th and 5th bytecodes are comparison operations. The key lies in the following two bytecodes:</p>
<ul>
<li>The sixth bytecode <code>LFALSESKIP</code> is specially used for the evaluation of relational operations. The function is to set False to the target address and skip the next statement;</li>
<li>The seventh bytecode <code>LOADTRUE</code>, the function is to load True to the target address.</li>
</ul>
<p>These two bytecodes, together with the 4th and 5th bytecodes above, can realize the function of finding Boolean values:</p>
<ul>
<li>If the fourth bytecode comparison result is true, execute the JMP of the fifth, skip the next statement, execute the seventh statement, and set True;</li>
<li>If the comparison result of the fourth bytecode is false, then skip the fifth article, and execute the LFALSESKIP of the sixth article, set False and skip the next article.</li>
</ul>
<p>This is very clever, but also very long-winded. If you follow the previous method of <a href="./ch05-02.binary_ops.html">Binary Arithmetic Operation</a>, the above function only needs one bytecode: <code>EQ $dst $a $b</code>. The reason why it is so complicated now is to <a href="./ch07-03.relational_in_condition.html#bytecode">optimize</a> for relational operations in <em>conditional judgment</em> scenarios, thus hurting performance in <em>evaluation</em> scenarios, after all, the latter appears too little.</p>
<h2 id="syntax-analysis-8"><a class="header" href="#syntax-analysis-8">Syntax Analysis</a></h2>
<p>The evaluation process is to discharge <code>ExpDesc::Compare</code> onto the stack,</p>
<pre><code class="language-rust  ignore">     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             // omit other types of processing

             // Evaluation of the logical operations introduced earlier
             ExpDesc::Test(condition, true_list, false_list) =&gt; {
                 self.discharge(dst, *condition);
                 self.fix_test_set_list(true_list, dst);
                 self.fix_test_set_list(false_list, dst);
                 return;
             }

             // evaluation of relational operations
             ExpDesc::Compare(op, left, right, true_list, false_list) =&gt; {
                 // Generate 2 bytecodes for relational operations
                 self.byte_codes.push(op(left as u8, right as u8, false));
                 self.byte_codes.push(ByteCode::Jump(1));

                 // Terminate False jump list, go to `SetFalseSkip` bytecode, evaluate False
                 self.fix_test_list(false_list);
                 self.byte_codes.push(ByteCode::SetFalseSkip(dst as u8));

                 // Terminate True jump list, go to `LoadBool(true)` bytecode, evaluate True
                 self.fix_test_list(true_list);
                 ByteCode::LoadBool(dst as u8, true)
             }
         };
         self.byte_codes.push(code);</code></pre>
<p>In comparison, the evaluation of the logical operation <code>ExpDesc::Test</code> is simple.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="function"><a class="header" href="#function">Function</a></h1>
<p>This chapter introduces functions. There are two types of functions in Lua:</p>
<ul>
<li>Lua function, defined in Lua;</li>
<li>External functions are generally implemented in the interpreter language. For example, in the official implementation of Lua, they are C functions; while in our case, they are Rust functions. For example, the <code>print</code> function at the beginning of this project was implemented in Rust in the interpreter.</li>
</ul>
<p>The definition (syntax analysis) and call (virtual machine execution) of the former are both in the Lua language, and the process is complete, so the former will be discussed and implemented first. Then introduce the latter and related API.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="define-and-call"><a class="header" href="#define-and-call">Define and Call</a></h1>
<p>Our interpreter only supported sequential execution at first, and later added control structures to support conditional jumps, and blocks also make the scope of variables. Functions, on the other hand, exist more independently in terms of resolution, execution, or scope. To do this, the current framework for parsing and virtual machine execution needs to be modified.</p>
<h2 id="transform-parseproto"><a class="header" href="#transform-parseproto">Transform ParseProto</a></h2>
<p>The definition of a function can be nested, that is, the function can be defined again inside another function. If the entire code is regarded as the main function, then our current syntax analysis is equivalent to only supporting this one function. In order to support nested definitions of functions, the parsing needs to be modified. First transform the data structure.</p>
<p>Currently, the context structure of the parsing process is <code>ParseProto</code>, and this is also the structure returned to the virtual machine for execution. It is defined as follows:</p>
<pre><code class="language-rust  ignore">pub struct ParseProto&lt;R: Read&gt; {
     pub constants: Vec&lt;Value&gt;,
     pub byte_codes: Vec&lt;ByteCode&gt;,

     sp: usize,
     locals: Vec&lt;String&gt;,
     break_blocks: Vec&lt;Vec&lt;usize&gt;&gt;,
     continue_blocks: Vec&lt;Vec&lt;(usize, usize)&gt;&gt;,
     gotos: Vec&lt;GotoLabel&gt;,
     labels: Vec&lt;GotoLabel&gt;,
     lex: Lex&lt;R&gt;,
}</code></pre>
<p>The specific meaning of each field has been introduced in detail before, and will be ignored here. Here only the fields are distinguished according to the independence of the function:</p>
<ul>
<li>the final <code>lex</code> field is parsed throughout the code;</li>
<li>All remaining fields are data inside the function.</li>
</ul>
<p>In order to support nested definitions of functions, the global part (<code>lex</code> field) and the function part (other fields) need to be disassembled. The newly defined data structure <code>PerFuncProto_</code> parsed by the function (because we will not adopt this solution in the end, <code>_</code> is added to the name of the structure), including other fields left after removing <code>lex</code> from the original <code>ParseProto</code>:</p>
<pre><code class="language-rust  ignore">struct PerFuncProto_ {
     pub constants: Vec&lt;Value&gt;,
     pub byte_codes: Vec&lt;ByteCode&gt;,
     sp: usize,
     ... // omit more fields
}</code></pre>
<p>In order to support the nesting of functions, it is necessary to support multiple function analysis bodies at the same time. The most intuitive idea is to define a list of function bodies:</p>
<pre><code class="language-rust  ignore">struct ParseProto&lt;R: Read&gt; {
     funcs: Vec&lt;PerFuncProto_&gt;, // The list of function analysis body PerFuncProto_ just defined
     lex: Lex&lt;R&gt;, // global data
}</code></pre>
<p>Each time a new layer of functions is nested, a new member is pushed into the <code>funcs</code> field; it pops up after the function is parsed. The last member of <code>funcs</code> represents the current function. This definition is very intuitive, but there is a problem. It is very troublesome to access all the fields of the current function. For example, to access the <code>constants</code> field, you need <code>self.funcs.last().unwrap().constants</code> to read or <code>self .funcs.last_mut().unwrap().constants</code> writes. It's too inconvenient, and the execution efficiency should also be affected.</p>
<p>If it is C language, then this problem is easy to solve: add a pointer member of type <code>PerFuncProto_</code> in <code>ParseProto</code>, such as <code>current</code>, which points to the last member of <code>funcs</code>. This pointer is updated every time the function body is pushed or popped. Then we can directly use this pointer to access the current function, such as <code>self.current.constants</code>. This approach is very convenient but Rust thinks it is not &quot;safe&quot;, because the validity of this pointer cannot be guaranteed at the Rust syntax level. Although there are only two places to update this pointer, which is relatively safe, but since you use Rust, you must follow the rules of Rust.</p>
<p>For Rust, a feasible solution is to add an index (rather than a pointer), such as <code>icurrent</code>, pointing to the last member of <code>funcs</code>. This index is also updated every time the function body is pushed or popped. When accessing the current function information, we can use <code>self.funcs[icurrent].constants</code>. While the Rust language allows this, it's really just a variant of the pointer scheme above, and can still cause bugs due to incorrect updates of the index. For example, if the index exceeds the length of <code>funcs</code>, it will panic, and if it is smaller than expected, there will be code logic bugs that are more difficult to debug. In addition, during execution, Rust's list index will be compared with the length of the list, which will also slightly affect performance.</p>
<p>There is also a less intuitive solution that doesn't have the problems above: use recursion. When parsing nested functions, the most natural way is to recursively call the code of the parsing function, then each call will have an independent stack (Rust's call stack), so we can create a function parsing body every time you call it and use it Parse the current Lua function, and return the parsing body for the outer function to process after the call ends. In this solution, only the information of the current function can be accessed during the parsing process, and the information of the outer function cannot be accessed. Naturally, the problem of inconvenient access to the information of the current function just mentioned does not exist. For example, accessing constants still uses <code>self.constants</code>, even without modifying existing code. The only thing to solve is the global data <code>Lex</code>, which can be passed on as a parameter of the analysis function.</p>
<p>In this solution, there is no need to define a new data structure, just change the <code>lex</code> field in the original <code>ParseProto</code> from <code>Lex</code> type to <code>&amp;mut Lex</code>. The syntax analysis function definition for parsing Lua functions is originally the method of <code>ParseProto</code>, which is defined as:</p>
<pre><code class="language-rust  ignore">impl&lt;'a, R: Read&gt; ParseProto&lt;'a, R&gt; {
     fn chunk(&amp;mut self) {
         ...
     }</code></pre>
<p>Now change to a normal function, defined as:</p>
<pre><code class="language-rust  ignore">fn chunk(lex: &amp;mut Lex&lt;impl Read&gt;) -&gt; ParseProto {
     ...
}</code></pre>
<p>The parameter <code>lex</code> is global data, and each recursive call is directly passed to the next layer. The return value is the parsed information of the current Lua function created inside <code>chunk()</code>.</p>
<p>In addition, the <code>chunk()</code> function internally calls the <code>block()</code> function to parse the code, and the latter returns the end Token of the block. Previously, the <code>chunk()</code> function was only used to process the entire code block, so the end Token could only be <code>Token::Eos</code>; but now it may also be used to parse other internal functions, and the expected end Token is <code>Token ::End</code>. Therefore, the <code>chunk()</code> function needs to add a new parameter, indicating the expected end Token. So the definition is changed to:</p>
<pre><code class="language-rust  ignore">fn chunk(lex: &amp;mut Lex&lt;impl Read&gt;, end_token: Token) -&gt; ParseProto {
     ...
}</code></pre>
<h2 id="add-funcproto"><a class="header" href="#add-funcproto">Add FuncProto</a></h2>
<p>We just modified <code>ParseProto</code> and the type of <code>lex</code>. Now let's do a small optimization by the way. The first two <code>pub</code> modified fields in <code>ParseProto</code> are also returned to the virtual machine for execution; most of the latter fields are only used for syntax analysis, which are internal data and do not need to be returned to the virtual machine. These two parts can be disassembled so that only the part needed by the virtual machine is returned. To do this, add the <code>FuncProto</code> data structure:</p>
<pre><code class="language-rust  ignore">// Return information to the virtual machine to execute
pub struct FuncProto {
     pub constants: Vec&lt;Value&gt;,
     pub byte_codes: Vec&lt;ByteCode&gt;,
}

#[derive(Debug)]
struct ParseProto&lt;'a, R: Read&gt; {
     // Return information to the virtual machine to execute
     fp: FuncProto,

     // syntax analysis internal data
     sp: usize,
     locals: Vec&lt;String&gt;,
     break_blocks: Vec&lt;Vec&lt;usize&gt;&gt;,
     continue_blocks: Vec&lt;Vec&lt;(usize, usize)&gt;&gt;,
     gotos: Vec&lt;GotoLabel&gt;,
     labels: Vec&lt;GotoLabel&gt;,
     lex: Lex&lt;R&gt;,

     // global data
     lex: &amp;'a mut Lex&lt;R&gt;,
}</code></pre>
<p>So the return value of the <code>chunk()</code> function is changed from <code>ParseProto</code> to <code>FuncProto</code>. Its full definition is as follows:</p>
<pre><code class="language-rust  ignore">fn chunk(lex: &amp;mut Lex&lt;impl Read&gt;, end_token: Token) -&gt; FuncProto {
     // Generate a new ParseProto to parse the current new Lua function
     let mut proto = ParseProto::new(lex);

     // call block() parsing function
     assert_eq!(proto.block(), end_token);
     if let Some(goto) = proto. gotos. first() {
         panic!(&quot;goto {} no destination&quot;, &amp;goto.name);
     }

     // only returns the FuncProto part
     proto.fp
}</code></pre>
<p>In this way, when syntactically analyzing Lua built-in functions, just recursively call <code>chunk(self.lex, Token::End)</code>. The specific syntax analysis is introduced below.</p>
<h2 id="syntax-analysis-9"><a class="header" href="#syntax-analysis-9">Syntax Analysis</a></h2>
<p>The general process of parsing Lua functions is introduced above, now let's look at the specific syntax analysis. By now, we should be familiar with syntax analysis already, and it can be executed according to BNF. Lua's function definition has 3 places:</p>
<ol>
<li>Global functions;</li>
<li>Local functions:</li>
<li>An anonymous function is a case of the expression <code>exp</code> statement.</li>
</ol>
<p>The BNF rules are as follows:</p>
<pre><code>stat :=
     `function` funcname funcbody | # 1. Global function
     `local` `function` Name funcbody | # 2. Local function
     # omit other cases

exp := functiondef | omit other cases
functiondef := `function` funcbody # 3. Anonymous function

funcbody ::= '(' [parlist] ')' block end # Function definition
</code></pre>
<p>It can be seen from the above rules that the difference between these three definitions is only at the beginning, and at the end they all belong to <code>funcbody</code>. Here only the simplest second case, the local function, is introduced.</p>
<pre><code class="language-rust  ignore">     fn local_function(&amp;mut self) {
         self.lex.next(); // skip keyword `function`
         let name = self.read_name(); // function name, or local variable name
         println!(&quot;== function: {name}&quot;);

         // currently does not support parameters, skip `()`
         self.lex.expect(Token::ParL);
         self.lex.expect(Token::ParR);

         // Call the chunk() parsing function
         let proto = chunk(self.lex, Token::End);

         // Put the parsed result FuncProto into the constant table
         let i = self.add_const(Value::LuaFunction(Rc::new(proto)));
         // load function through LoadConst bytecode
         self.fp.byte_codes.push(ByteCode::LoadConst(self.sp as u8, i as u16));

         // create local variable
         self. locals. push(name);
     }</code></pre>
<p>The parsing process is simple. It should be noted that the processing method of the function prototype FuncProto returned by the <code>chunk()</code> function is to put it in the constant table as a constant. It can be compared that a string is a constant composed of a series of character sequences; and the function prototype FuncProto is a constant composed of a series of constant tables and bytecode sequences. It also exists in the constant table, and it is also loaded with <code>LoadConst</code> bytecode.</p>
<p>To this end, it is necessary to add a new Value type <code>LuaFunction</code> to represent the Rust function, and change the type that originally represented the Lua function from <code>Function</code> to <code>RustFunction</code>:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     LongStr(Rc&lt;Vec&lt;u8&gt;&gt;),
     LuaFunction(Rc&lt;FuncProto&gt;),
     RustFunction(fn (&amp;mut ExeState) -&gt; i32),</code></pre>
<p>The data type associated with <code>LuaFunction</code> is <code>Rc&lt;FuncProto&gt;</code>, and it can also be seen from here that it is similar to a string constant.</p>
<p>The syntax analysis of &quot;defining a function&quot; is completed above, and the syntax analysis of &quot;calling a function&quot; is related to functions. But when &quot;calling a function&quot;, the Lua function and the Rust function are treated equally, and the Lua programmer does not even know what the function is implemented when calling the function; since the Rust function <code>print()</code> has been called before Syntactic analysis, so there is no need to perform syntax analysis specifically for Lua function calls.</p>
<h2 id="virtual-machine-execution-7"><a class="header" href="#virtual-machine-execution-7">Virtual Machine Execution</a></h2>
<p>Like syntax analysis, our previous virtual machine execution part only supports one layer of Lua functions. In order to support function calls, the easiest way is to recursively call the virtual machine to execute, that is, the <code>execute()</code> function. code show as below:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, _) =&gt; {
         self. func_index = func as usize;
         match &amp;self. stack[self. func_index] {
             Value::RustFunction(f) =&gt; { // previously supported Rust functions
                 f(self);
             }
             Value::LuaFunction(f) =&gt; { // new Lua function
                 let f = f. clone();
                 self.execute(&amp;f); // recursively call the virtual machine!
             }
             f =&gt; panic!(&quot;invalid function: {f:?}&quot;),
         }
     }</code></pre>
<p>However, special handling of the stack is required. During parsing, each time a new function is parsed, the stack pointer (the <code>sp</code> field in the <code>ParseProto</code> structure) starts from 0. Because during syntax analysis, the absolute starting address of the stack when the virtual machine is executed is not known. Then, when the virtual machine is executing, when accessing the stack, the stack index in the bytecode used needs to add the offset of the stack start address of the current function. For example, for the following Lua code:</p>
<pre><code class="language-lua">local a, b = 1, 2
local function foo()
     local x, y = 1, 2
end
foo()
</code></pre>
<p>When parsing the <code>foo()</code> function definition, the stack addresses of the local variables x and y are 0 and 1, respectively. When the last line of code is executed and the <code>foo()</code> function is called, the function <code>foo</code> is placed at the absolute index 2 of the stack. At this time, the absolute indexes of the local variables x and y are 3 and 4. Then when the virtual machine executes, it needs to convert the relative addresses 0 and 1 into 3 and 4.</p>
<pre><code>  absolute     relative
  address      address
        +-----+ &lt;---base of main function
      0 |  a  | 0
        +-----+
      1 |  b  | 1
        +-----+
      2 | foo | 2
        +-----+ &lt;---base of foo()
      3 |  x  | 0
        +-----+
      4 |  y  | 1
        +-----+
        |     |

</code></pre>
<p>When executing the Rust function <code>print()</code> before, in order to allow the <code>print()</code> function to read the parameters, the <code>func_index</code> member is set in <code>ExeState</code> to point to the address of the function on the stack. Now call the Lua function, still the same. However, <code>func_index</code> is renamed to <code>base</code> here, and points to the next address of the function.</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, _) =&gt; {
         self.base += func as usize + 1; // Set the absolute address of the function on the stack
         match &amp;self.stack[self.base-1] {
             Value::RustFunction(f) =&gt; {
                 f(self);
             }
             Value::LuaFunction(f) =&gt; {
                 let f = f. clone();
                 self. execute(&amp;f);
             }
             f =&gt; panic!(&quot;invalid function: {f:?}&quot;),
         }
         self.base -= func as usize + 1; // restore
     }</code></pre>
<p>All previous write operations to the stack were called <code>set_stack()</code> method, now need to add self.base offset:</p>
<pre><code class="language-rust  ignore">     fn set_stack(&amp;mut self, dst: u8, v: Value) {
         set_vec(&amp;mut self.stack, self.base + dst as usize, v); // plus self.base
     }</code></pre>
<p>All previous read operations on the stack were directly <code>self.stack[i]</code>, and now a new function <code>get_stack()</code> is also extracted, and the self.base offset is added when accessing the stack:</p>
<pre><code class="language-rust  ignore">     fn get_stack(&amp;self, dst: u8) -&gt; &amp;Value {
         &amp;self.stack[self.base + dst as usize] // plus self.base
     }</code></pre>
<p>So far, we have completed the most basic definition and calling of Lua functions. Thanks to the power of recursion, the code changes are not big. But it's just the beginning of the full feature. The next section adds support for parameters and return values.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="arguments"><a class="header" href="#arguments">Arguments</a></h1>
<p>The previous section introduced the definition and calling process of Lua functions. This section describes the arguments of the function.</p>
<p>The term &quot;argument&quot; has two concepts:</p>
<ul>
<li>&quot;parameter&quot;, refers to the variable in the function prototype, including information such as parameter name and parameter type;</li>
<li>&quot;argument&quot;, refers to the actual value when the function is called.</li>
</ul>
<p>When introducing syntax analysis and virtual machine execution later in this section, &quot;parameter&quot; and &quot;argument&quot; must be clearly distinguished sometimes.</p>
<p>A very important point is: in the Lua language, the parameters of the function are local variables! During syntax analysis, the parameters will also be placed in the initial position of the local variable table, so that if there is a reference to the parameter in the subsequent code, it will also be located in the local variable table. In the virtual machine execution phase, the arguments are loaded onto the stack immediately following the function entry, followed by local variables, which is consistent with the order in the local variable table in the syntax analysis phase. For example, for the following functions:</p>
<pre><code class="language-lua">local function foo(a, b)
     local x, y = 1, 2
end
</code></pre>
<p>When the <code>foo()</code> function is executed, the stack layout is as follows (numbers 0-3 on the right side of the stack are relative indices):</p>
<pre><code>|     |
+-----+
| foo |
+=====+ &lt;---base
|  a  | 0  \
+-----+     + arguments
|  b  | 1  /
+-----+
|  x  | 2  \
+-----+     + local variables
|  y  | 3  /
+-----+
|     |
</code></pre>
<p>The only difference between arguments and local variables is that the value of the parameter is passed in by the caller when calling, while the local variable is assigned inside the function.</p>
<h2 id="syntax-analysis-of-parameter"><a class="header" href="#syntax-analysis-of-parameter">Syntax Analysis of Parameter</a></h2>
<p>The syntax analysis of the parameter is also the syntax analysis of the function definition. When the function definition was introduced in the previous section, the parameter part was omitted in the process of syntax analysis, and it is added now. The BNF of the function definition is funcbody, which is defined as follows:</p>
<pre><code>    funcbody ::= `(` [parlist] `)` block end
    parlist ::= namelist [`,` `...`] | `...`
    namelist ::= Name {`,` Name}
</code></pre>
<p>As you can see, the parameter list consists of two optional parts:</p>
<ul>
<li>
<p>Multiple optional Names are fixed parameters. In the previous section, when parsing the new function and creating the <code>FuncProto</code> structure, the <code>locals</code> field of the local variable table was initialized to an empty list. Now initialize to a parameter list instead. In this way, the parameters are at the front of the local variable table, and the subsequent newly created local variables follow, which is consistent with the stack layout diagram at the beginning of this section. In addition, since the number of arguments of the calling function in Lua language is allowed to be different from the number of parameters. If it is more, it will be discarded, and if it is less, it will be filled with nil. Therefore, the number of parameters should also be added to the result of <code>FuncProto</code> for comparison during virtual machine execution.</p>
</li>
<li>
<p>The last optional <code>...</code> indicates that this function supports variable arguments. If it is supported, then in the subsequent syntax analysis, <code>...</code> can be used in the body of the function to refer to variable parameters, and in the virtual machine execution stage, special processing should also be done for variable parameters. Therefore, a flag needs to be added in <code>FuncProto</code> to indicate whether this function supports variable parameters.</p>
</li>
</ul>
<p>In summary, there are three modification points in total. Add two fields to <code>FuncProto</code>:</p>
<pre><code class="language-rust  ignore">pub struct FuncProto {
     // Whether to support variable parameters.
     // Used in both parsing and virtual machine execution.
     pub has_varargs: bool,

     // The number of fixed parameters. 
     // Used in virtual machine execution.
     pub nparam: usize,
     
     pub constants: Vec&lt;Value&gt;,
     pub byte_codes: Vec&lt;ByteCode&gt;,
}</code></pre>
<p>In addition, when initializing the <code>ParseProto</code> structure, use the parameter list to initialize the local variable <code>locals</code> field. code show as below:</p>
<pre><code class="language-rust  ignore">impl&lt;'a, R: Read&gt; ParseProto&lt;'a, R&gt; {
     // Add has_varargs and params two parameters
     fn new(lex: &amp;'a mut Lex&lt;R&gt;, has_varargs: bool, params: Vec&lt;String&gt;) -&gt; Self {
         ParseProto {
             fp: FuncProto {
                 has_varargs: has_varargs, // Whether to support variable parameters
                 nparam: params.len(), // number of parameters
                 constants: Vec::new(),
                 byte_codes: Vec::new(),
             },
             sp: 0,
             locals: params, // Initialize the locals field with the parameter list
             break_blocks: Vec::new(),
             continue_blocks: Vec::new(),
             gotos: Vec::new(),
             labels: Vec::new(),
             lex: lex,
         }
     }</code></pre>
<p>At this point, the syntax analysis of the parameters is completed. It involves variable parameters, virtual machine execution and other parts, which will be described in detail below.</p>
<h2 id="syntax-analysis-of-arguments"><a class="header" href="#syntax-analysis-of-arguments">Syntax Analysis of Arguments</a></h2>
<p>Syntactic analysis of arguments, that is, syntactic analysis of function calls. This has been implemented in the previous chapter when prefixexp was implemented: the parameter list is read through the <code>explist()</code> function, and loaded to the position behind the function entry on the stack in turn. Consistent with the stack layout diagram at the beginning of this section, it is equivalent to assigning values to parameters. The actual number of arguments is parsed here and written into the arguments of the bytecode <code>Call</code> for comparison with the formal during the execution phase of the virtual machine.</p>
<p>But the implementation at the time was incomplete and did not support variable parameters. More details later in this section.</p>
<h2 id="virtual-machine-execution-8"><a class="header" href="#virtual-machine-execution-8">Virtual Machine Execution</a></h2>
<p>In the above syntax analysis of the arguments, the arguments have been loaded onto the stack, which is equivalent to assigning values to the parameters, so when the virtual machine executes the function call, it does not need to process the parameters. However, in the Lua language, the number of arguments may not be equal to the number of parameters when a function is called. If there are more arguments than parameters, there is no need to deal with it, and the extra part is considered to be a temporary variable that occupies the stack position but is useless; but if the argument is less than the parameter, then the insufficient part needs to be set to nil, otherwise the subsequent words The reference to this parameter by the section code will cause Lua's stack access exception. In addition, the execution of <code>Call</code> bytecode does not require other processing of parameters.</p>
<p>As mentioned above in the grammatical analysis, the number of parameters and arguments are respectively in the <code>nparam</code> field in the <code>FuncProto</code> structure and the associated parameters of <code>Call</code> bytecode. So the virtual machine execution code of the function call is as follows:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, narg) =&gt; { // `narg` is the actual number of arguments passed in
         self.base += func as usize + 1;
         match &amp;self.stack[self.base - 1] {
             Value::LuaFunction(f) =&gt; {
                 let narg = narg as usize;
                 let f = f. clone();
                 if narg &lt; f.nparam { // `f.nparam` is the number of parameters in the function definition
                     self.fill_stack(narg, f.nparam - narg); // fill nil
                 }
                 self. execute(&amp;f);
             }</code></pre>
<p>So far, the fixed parameter part is completed, which is relatively simple; the variable parameter part is introduced below, and it becomes complicated.</p>
<h2 id="variable-parameters"><a class="header" href="#variable-parameters">Variable Parameters</a></h2>
<p>In Lua, the <code>...</code> expression is used for variable parameters and variable arguments both. It's variable parameters in parameter list in function definition; and it's variable arguments otherwise.</p>
<p>Variable parameters have been mentioned in <a href="ch08-02.arguments.html#syntax-analysis-of-parameter">Syntax Analysis of parameters</a> above, and their functions are relatively simple, which just indicates that this function does support variable parameters. The rest of this section mainly introduces the processing of variable arguments when executing a function call.</p>
<p>At the beginning of this section, the parameters of the function are introduced as local variables, and the layout of the stack is drawn. However, this statement is only suitable for fixed arguments, but not for variable parameters. Add variable parameters to the previous <code>foo()</code> function as an example, the code is as follows:</p>
<pre><code class="language-lua">local function foo(a, b, ...)
     local x, y = 1, 2
     print(x, y, ...)
end
foo(1, 2, 3, 4, 5)
</code></pre>
<p>What should the stack layout look like after adding variable parameters? In other words, where does the variable argument exist? When the last line <code>foo()</code> in the above code is called, <code>1</code> and <code>2</code> correspond to the parameters <code>a</code> and <code>b</code> respectively, and <code>3</code>, <code>4</code> and <code>5</code> are variable Arguments. Before the call starts, the stack layout is as follows:</p>
<pre><code>|     |
+-----+
| foo |
+=====+ &lt;-- base
|  1  |  \
+-----+   + Fixed arguments, corresponding to `a` and `b`
|  2  |  /
+-----+
|  3  |  \
+-----+   |
|  4  |   + Variable arguments, corresponding to `...`
+-----+   |
|  5  |  /
+-----+
|     |
</code></pre>
<p>After entering the <code>foo()</code> function, where should the next three arguments exist? The most direct idea is to keep the above layout unchanged, that is, the variable arguments are stored behind the fixed arguments. However, this is not acceptable! Because this will occupy the space of local variables, that is, <code>x</code> and <code>y</code> in the example will be moved back, and the distance moved back is the number of variable arguments. However, the number of variable arguments cannot be determined during the syntax analysis stage, so the position of the local variable on the stack cannot be determined, and the local variable cannot be accessed.</p>
<p>The official implementation of Lua is to ignore the variable parameters in the syntax analysis stage, so that the local variables are still behind the fixed parameters. But when the virtual machine is executing, after entering the function, the variable parameters are moved to the front of the function entry, and the number of variable arguments is recorded. In this way, when accessing variable parameters, the stack position can be located according to the function entry position and the number of variable arguments, that is, <code>stack[self.base - 1 - number of arguments.. self.base - 1] </code>. The following is a stack layout diagram:</p>
<pre><code>|     |
+-----+
|  3  | -4 \
+-----+     |                                  num_varargs: usize  // record the #variable arguments
|  4  | -3  + move the variable arguments           +-----+
+-----+     | to the front of the function entry    |  3   |
|  5  | -2 /                                        +-----+
+-----+
| foo | &lt;-- function entry
+=====+ &lt;-- base
| a=1 | 0  \
+-----+     + fixed arguments, corresponding to `a` and `b`
| b=2 | 1  /
+-----+
|  x  | 2  \
+-----+     + local variables
|  y  | 3  /  following to fixed arguments

</code></pre>
<p>Since this solution needs to record additional information (the number of variable arguments) when the virtual machine is executed, and also move the parameters on the stack, it is easier to record the variable arguments directly:</p>
<pre><code>|     |
+-----+
| foo | &lt;-- function entry                 varargs: Vec&lt;Value&gt;  // record variable arguments
+=====+                                       +-----+-----+-----+
| a=1 | 0  \                                  |  3  |  4  |  5  |
+-----+     + fixed arguments                 +-----+-----+-----+
| b=2 | 1  /
+-----+
|  x  | 2  \
+-----+     + local variables
|  y  | 3  /


</code></pre>
<p>Compared with the official implementation of Lua, this method does not use the stack, but uses <code>Vec</code>, which will have additional memory allocation on the heap. But more intuitive and clear.</p>
<p>After determining the storage method of the variable arguments, we can perform syntax analysis and virtual machine execution.</p>
<h2 id="expdescvarargs-and-application-scenarios"><a class="header" href="#expdescvarargs-and-application-scenarios">ExpDesc::VarArgs and Application Scenarios</a></h2>
<p>The above is about passing variable parameters when the function is called, and then introduces how to access variable parameters in the function body.</p>
<p>Access to a variable argument is an independent expression, the syntax is <code>...</code>, parsed in the <code>exp_limit()</code> function, and a new expression type <code>ExpDesc::VarArgs</code> is added, this type is not associated parameter.</p>
<p>It is very simple to read this expression, first check whether the current function supports variable parameters (whether there is <code>...</code> in the function prototype), and then return <code>ExpDesc::VarArgs</code>. The specific code is as follows:</p>
<pre><code class="language-rust  ignore">     fn exp_limit(&amp;mut self, limit: i32) -&gt; ExpDesc {
         let mut desc = match self. lex. next() {
             Token::Dots =&gt; {
                 if !self.fp.has_varargs { // Check if the current function supports variable parameters?
                     panic!(&quot;no varargs&quot;);
                 }
                 ExpDesc::VarArgs // New expression type
             }</code></pre>
<p>But what to do with <code>ExpDesc::VarArgs</code> read? This requires first sorting out the three scenarios of using variable arguments:</p>
<ol>
<li>
<p>When <code>...</code> is used as the last argument of a function call, the last value of a return statement, or the last list member of a table construction, it represents all the arguments passed in. For example, the following example:</p>
<pre><code class="language-lua">print(&quot;hello: &quot;, ...) -- last argument
local t = {1, 2, ...} -- last list member
return a+b, ... -- the last return value
</code></pre>
</li>
<li>
<p>When <code>...</code> is used as the last expression after the equal sign <code>=</code> of a local variable definition statement or an assignment statement, the number will be expanded or reduced as required. For example, the following example:</p>
<pre><code class="language-lua">local x, y = ... -- Take the first 2 arguments and assign them to x and y respectively
t.k, t.j = a, ... -- Take the first argument and assign it to t.j
</code></pre>
</li>
<li>
<p>Other places only represent the first actual argument passed in. For example, the following example:</p>
<pre><code class="language-lua">local x, y = ..., b -- not the last expression, only take the first argument and assign it to x
t.k, t.j = ..., b -- not the last expression, only take the first argument and assign it to t.k
if ... then -- conditional judgment
    t[...] = ... + f -- table index, and operands of binary operations
end
</code></pre>
</li>
</ol>
<p>Among them, the first scenario is the most basic, but it is also the most complicated to implement; the latter two scenarios are special cases and relatively simple to implement. The three scenarios are analyzed in turn below.</p>
<h2 id="scenario-1-all-variable-arguments"><a class="header" href="#scenario-1-all-variable-arguments">Scenario 1: All Variable Arguments</a></h2>
<p>The first scenario is introduced first, that is, loading all variable arguments. The 3 statements in this scenario are as follows:</p>
<ol>
<li>
<p>The last argument of the function call, is to use the variable arguments of the <em>current</em> function as the variable arguments of the <em>calling</em> function. Here it involves variable arguments in 2 functions, which is a bit confusing and inconvenient to describe;</p>
</li>
<li>
<p>The last value of the return statement, but the return value is not supported yet, which will be introduced in the next section;</p>
</li>
<li>
<p>The last list member of the table construction.</p>
</li>
</ol>
<p>The implementation ideas of these three statements are similar. When parsing the expression list, only the previous expression is discharged, and the last expression is not discharged; and then after the complete statement is parsed, it is checked separately whether the last statement is <code>ExpDesc::VarArgs</code>:</p>
<ul>
<li>
<p>If not, discharge normally. In this case, the quantity of all expressions can be determined during parsing, and the number of values can be encoded into the corresponding bytecode.</p>
</li>
<li>
<p>If yes (<code>ExpDesc::VarArgs</code>), use the newly added bytecode <code>VarArgs</code> to load all variable parameters, and the number of arguments is not known during syntax analysis, but can only be known when the virtual machine is executed, so the total number of expressions can't be encoded into the corresponding bytecode, so it needs to be handled with a special value or a new bytecode.</p>
</li>
</ul>
<p>Among the three statements, the third statement table structure is relatively the simplest, so we introduce it first.</p>
<p>The syntax analysis process of the previous table construction is: in the process of reading all members in a loop, if an array member is parsed, it will be immediately discharged to the stack; after the loop reading is completed, all array members are loaded on the stack in turn, and then generated <code>SetList</code> bytecode adds it to the list. The second associated parameter of this <code>SetList</code> bytecode is the number of array members. For simplicity, the processing of batch loading when there are more than 50 members is ignored here.</p>
<p>Now modify the process: in order to process the last expression alone, when parsing to an array member, we need delay the discharge. The specific method is relatively simple but not easy to describe, you can refer to the following code. The code is excerpted from the <code>table_constructor()</code> function, and only the content related to this section is kept.</p>
<pre><code class="language-rust  ignore">     // Add this variable to save the last read array member
     let mut last_array_entry = None;

     // Loop to read all members
     loop {
         let entry = // omit the code to read members
         match entry {
             TableEntry::Map((op, opk, key)) =&gt; // omit the code of the member part of the dictionary
             TableEntry::Array(desc) =&gt; {
                 // Use the replace() function to replace the last read member with the new member desc
                 // and discharge. And the new member, the current &quot;last member&quot;, is
                 // Store in last_array_entry.
                 if let Some(last) = last_array_entry. replace(desc) {
                     self.discharge(sp0, last);
                 }
             }
         }
     }

     // process the last expression, if any
     if let Some(last) = last_array_entry {
         let num = if self. discharge_expand(last) {
             // variable arguments. It is impossible to know the specific number
             // of arguments in the syntax analysis stage, so `0` is used to
             // represent all arguments on the stack.
             0
         } else {
             // not variable arguments, so we can calculate the total number of members
             (self.sp - (table + 1)) as u8
         };
         self.fp.byte_codes.push(ByteCode::SetList(table as u8, num));
     }</code></pre>
<p>The above code sorting process is relatively simple, so I won’t introduce them line by line here. There are a few details to cover when dealing with the last expression:</p>
<ul>
<li>Added <code>discharge_expand()</code> method for special handling of <code>ExpDesc::VarArgs</code> type expressions. It is foreseeable that this function will be used by the other two statements (return statement and function call statement) later. Its code is as follows:</li>
</ul>
<pre><code class="language-rust  ignore">     fn discharge_expand(&amp;mut self, desc: ExpDesc) -&gt; bool {
         match desc {
             ExpDesc::VarArgs =&gt; {
                 self.fp.byte_codes.push(ByteCode::VarArgs(self.sp as u8));
                 true
             }
             _ =&gt; {
                 self.discharge(self.sp, desc);
                 false
             }
         }
     }</code></pre>
<ul>
<li>
<p>If the last expression is a variable parameter, then the second associated parameter of <code>SetList</code> bytecode is set to <code>0</code>. Previously (when variable arguements expressions were not supported), this parameter of <code>SetList</code> bytecode could not be 0, because if there is no array member, then it is sufficient not to generate <code>SetList</code> bytecode, and there is no need to generate an association <code>SetList</code> with parameter 0. So here we can use <code>0</code> as a special value. In contrast, the other two statements in this scenario (return statement and function call statement) originally support 0 expressions, that is, there is no return value and no parameters, so <code>0</code> cannot be used as a special value. Then think of other ways.</p>
<p>Of course, the special value <code>0</code> may not be used here, but a new bytecode, such as <code>SetListAll</code>, is specially used to deal with this situation. These two approaches are similar, we still choose to use the special value <code>0</code>.</p>
</li>
<li>
<p>When the virtual machine is executing, if the second associated parameter of <code>SetList</code> is <code>0</code>, all the values behind the table on the stack will be fetched. That is, from the position of the table to the top of the stack, they are all expressions used for initialization. The specific code is as follows, adding the judgment of <code>0</code>:</p>
</li>
</ul>
<pre><code class="language-rust  ignore">     ByteCode::SetList(table, n) =&gt; {
         let ivalue = self.base + table as usize + 1;
         if let Value::Table(table) = self.get_stack(table). clone() {
             let end = if n == 0 { // 0, variable arguments, means all expressions up to the top of stack
                 self.stack.len()
             } else {
                 ivalue + n as usize
             };
             let values = self.stack.drain(ivalue .. end);
             table.borrow_mut().array.extend(values);
         } else {
             panic!(&quot;not table&quot;);
         }
     }</code></pre>
<ul>
<li>Since  the actual number of expressions can be obtained according to the top of the stack when the virtual machine is executed in the case of variable arguments, then can we do this in the case of fixed expressions before? In this way, is the second parameter associated with <code>SetList</code> useless? The answer is no, because there may be temporary variables on the stack! For example the following code:</li>
</ul>
<pre><code class="language-lua">t = { g1+g2 }
</code></pre>
<p>The two operands of the expression <code>g1+g2</code> are global variables. Before evaluating the entire expression, they must be loaded on the stack separately, and two temporary variables need to be occupied. The stack layout is as follows:</p>
<pre><code>|       |
+-------+
|   t   |
+-------+
| g1+g2 | load the global variable g1 into here temporaryly, and covered by g1+g2 later
+-------+
|   g2  | load the global variable g2 into here temporaryly
+-------+
|       |
</code></pre>
<p>At this time, the top of the stack is g2. If the method of going from the back of the list to the top of the stack is also followed, then g2 will also be considered a member of the list. Therefore, for the previous case (fixed number of expressions), it is still necessary to determine the number of expressions in the syntax analysis stage.</p>
<ul>
<li>Then, why can the top of the stackto determine the number of expressions in the case of variable arguments? This requires the virtual machine to clean up temporary variables when executing bytecodes that load variable parameters. this point is very important. The specific code is as follows:</li>
</ul>
<pre><code class="language-rust  ignore">     ByteCode::VarArgs(dst) =&gt; {
         self.stack.truncate(self.base + dst as usize); // Clean up temporary variables! ! !
         self.stack.extend_from_slice(&amp;varargs); // load variable parameters
     }</code></pre>
<p>So far, the processing of the variable arguments as the last expression of the table construction is completed. There are not many related codes, but it is not easy to sort out the ideas and some details.</p>
<h2 id="scenario-1-all-variable-arguments-continued"><a class="header" href="#scenario-1-all-variable-arguments-continued">Scenario 1: All Variable Arguments (continued)</a></h2>
<p>The table construction statement in the first scenario was introduced above, and now we introduce the case where variable arguments are used as the last parameter of a function call. Just listening to this description is confusing. These two statements handle variable arguments in the same way, and only the differences are introduced here.</p>
<p>It has been explained in the introduction of <a href="ch08-02.arguments.html#syntax-analysis-of-arguments">Syntax Analysis of arguments</a> above that all arguments are loaded to the top of the stack sequentially through the <code>explist()</code> function, and the number of arguments is written to <code>Call</code> bytecode. But the implementation at the time did not support variable arguments. Now in order to support variable arguments, the last expression needs to be treated specially. To do this, we modify the <code>explist()</code> function to keep and return the last expression, but just discharge the previous expressions onto the stack in turn. The specific code is relatively simple, skip it here. To review, in the <a href="./ch04-05.table_rw_and_bnf.html#write-table-and-assignment-statement">assignment statement</a>, when reading the expression list on the right side of the equal sign <code>=</code>, we also need to keep the last expression not discharged. After modifying the <code>exp_list()</code> function this time, it can also be used in the assignment statement.</p>
<p>After modifying the <code>explist()</code> function, combined with the above introduction to the table construction statement, the variable arguments in the function call can be realized. code show as below:</p>
<pre><code class="language-rust  ignore">     fn args(&amp;mut self) -&gt; ExpDesc {
         let ifunc = self.sp - 1;
         let narg = match self. lex. next() {
             Token::ParL =&gt; { // parameter list wrapped in brackets ()
                 if self.lex.peek() != &amp;Token::ParR {
                     // Read the argument list. Keep and return the last expression
                     // `last_exp`, and discharge the previous expressions onto the
                     // stack in turn and return their number `nexp`.
                     let (nexp, last_exp) = self.explist();
                     self.lex.expect(Token::ParR);

                     if self. discharge_expand(last_exp) {
                         // Variable arguments !!!
                         // Generate the newly added `VarArgs` bytecode
                         // and read all variable arguments.
                         none
                     } else {
                         // Fixed arguments. `last_exp` is also discharged onto the stack as the last argument.
                         Some(nexp + 1)
                     }
                 } else { // no parameters
                     self. lex. next();
                     some(0)
                 }
             }
             Token::CurlyL =&gt; { // table construction without parentheses
                 self. table_constructor();
                 some(1)
             }
             Token::String(s) =&gt; { // string constant without parentheses
                 self.discharge(ifunc+1, ExpDesc::String(s));
                 some(1)
             }
             t =&gt; panic!(&quot;invalid args {t:?}&quot;),
         };

         // For `n` fixed arguments, convert to `n+1`;
         // Converts to `0` for variable arguments.
         let narg_plus = if let Some(n) = narg { n + 1 } else { 0 };

         ExpDesc::Call(ifunc, narg_plus)
     }</code></pre>
<p>The difference from the table construction statement introduced before is that the bytecode corresponding to the table construction statement is <code>SetList</code>, and in the case of fixed members, the associated parameter used to represent the quantity will not be <code>0</code>; so we can use <code>0</code> as a special value to represent a variable number of members. However, for the function call statement, it supports the case of no argument, that is to say, the parameter of the argument value associated with the bytecode <code>Call</code> may already be <code>0</code>, so it is not possible to simply put <code>0</code> as a special value. Then, there are 2 options:</p>
<ul>
<li>Choose another special value, such as <code>u8::MAX</code>, that is, 255 as a special value;</li>
<li>Still use <code>0</code> as a special value, but in the case of a fixed argument, add 1 to the parameter. For example, if there are 5 arguments, then write 6 in the <code>Call</code> bytecode; if N bytecodes, write N+1; in this way, you can ensure that in the case of a fixed parameter, this parameter must be greater than 0.</li>
</ul>
<p>I feel that the first solution is slightly better, it's clearer and less error-prone. But the official implementation of Lua uses the second solution. We also use the second option. Corresponding to the two variables in the above code:</p>
<ul>
<li><code>narg: Option&lt;usize&gt;</code> indicates the actual number of arguments, <code>None</code> indicates variable arguments, <code>Some(n)</code> indicates that there are <code>n</code> fixed arguments;</li>
<li><code>narg_plus: usize</code> is the corrected value to be written into <code>Call</code> bytecode.</li>
</ul>
<p>The same thing as the table construction statement introduced before is that since the special value <code>0</code> is used to represent the variable parameter, then when the virtual machine executes, there must be a way to know the actual number of arguments. The number of arguments can only be calculated by the distance between the pointer on the top of the stack and the function entry, so it is necessary to ensure that the top of the stack is all arguments and there are no temporary variables. For this requirement, there are two cases:</p>
<ul>
<li>The argument is also a variable arguments <code>...</code>, that is, the last argument is <code>VarArgs</code>, for example, the call statement is <code>foo(1, 2, ...)</code>, then since the virtual machine execution of <code>VarArgs</code> introduced before will ensure clean up temporary variables, so there is no need to clean up again in this case;</li>
<li>The argument is fixed arguments. For example, if the calling statement is <code>foo(g1+g2)</code>, then it is necessary to clean up the possible temporary variables.</li>
</ul>
<p>Correspondingly, the function call in the virtual machine execution phase, that is, the execution of <code>Call</code> bytecode, needs to be modified as follows:</p>
<ul>
<li>Modify the associated parameter narg_plus;</li>
<li>Clean up possible temporary variables on the stack when needed.</li>
</ul>
<p>code show as below:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, narg_plus) =&gt; { // `narg_plus` is the corrected number of real parameters
         self.base += func as usize + 1;
         match &amp;self.stack[self.base - 1] {
             Value::LuaFunction(f) =&gt; {
                 let narg = if narg_plus == 0 {
                     // Variable arguments. As mentioned above, the execution
                     // of VarArgs bytecode will clean up possible temporary
                     // variable, so the top of the stack can be used to determine
                     // the actual number of arguments.
                     self.stack.len() - self.base
                 } else {
                     // Fixed arguments. Need to subtract 1 for correction.
                     narg_plus as usize - 1
                 };

                 if narg &lt; f.nparam { // fill nil, original logic
                     self.fill_stack(narg, f.nparam - narg);
                 } else if f.has_varargs &amp;&amp; narg_plus != 0 {
                     // If the called function supports variable arguments, and the
                     // call is a fixed argument, then we need to clean up possible
                     // temporary variables on the stack
                     self.stack.truncate(self.base + narg);
                 }

                 self. execute(&amp;f);
             }</code></pre>
<p>So far, we have completed the part of the first scenario of variable arguments. This part is the most basic and also the most complex. Two other scenarios are described below.</p>
<h2 id="scenario-2-the-first-n-variable-arguments"><a class="header" href="#scenario-2-the-first-n-variable-arguments">Scenario 2: The first N Variable Arguments</a></h2>
<p>Now introduce the second scenario of variable arguments, which requires a fixed number of variable arguments. The number of paraargumentsmeters to be used in this scenario is fixed and can be compiled into bytecode, which is much simpler than the previous scenario.</p>
<p>This scenario includes 2 statements: a local variable definition statement and an assignment statement. When the variable arguments are used as the last expression after the equal sign <code>=</code>, the number will be expanded or reduced as required. For example, the following sample code:</p>
<pre><code class="language-lua">     local x, y = ... -- Take the first 2 arguments and assign them to x and y respectively
     t.k, t.j = a, ... -- Take the first argument and assign it to t.j
</code></pre>
<p>The processing of these two statements is basically the same. Only the first local variable definition statement is introduced here.</p>
<p>The processing flow of the previous statement is to first load the expressions on the right side of <code>=</code> onto the stack in order to complete the assignment of local variables. If the number of expressions on the right side of <code>=</code> is less than the number of local variables on the left, then generate <code>LoadNil</code> bytecode to assign values to the extra local variables; if it is not less than, no processing is required.</p>
<p>Now special treatment is required for the last expression: if the number of expressions is less than the number of local variables, and the last expression is a variable arguments <code>...</code>, then the arguments is read as needed; if it is not variable arguments, it still falls back to the original method, which is filled with <code>LoadNil</code>. The <code>explist()</code> function that was modified just now comes in handy again, the specific code is as follows:</p>
<pre><code class="language-rust  ignore">     let want = vars.len();

     // Read the list of expressions.
     // Keep and return the last expression `last_exp`, and discharge the previous
     // the expressions onto the stack in turn and return their number `nexp`.
     let (nexp, last_exp) = self.explist();
     match (nexp + 1).cmp(&amp;want) {
         Ordering::Equal =&gt; {
             // If the expression is consistent with the number of local variables,
             // the last expression is also dischargeed on the stack.
             self.discharge(self.sp, last_exp);
         }
         Ordering::Less =&gt; {
             // If the expressions are less than the number of local variables,
             // we need to try to treat the last expression specially! ! !
             self.discharge_expand_want(last_exp, want - nexp);
         }
         Ordering::Greater =&gt; {
             // If the expression is more than the number of local variables,
             // adjust the top pointer of the stack; the last expression
             // is no need to deal with it.
             self.sp -= nexp - want;
         }
     }</code></pre>
<p>In the above code, the added logic is <code>discharge_expand_want()</code> function, which is used to load <code>want - nexp</code> expressions onto the stack. code show as below:</p>
<pre><code class="language-rust  ignore">     fn discharge_expand_want(&amp;mut self, desc: ExpDesc, want: usize) {
         debug_assert!(want &gt; 1);
         let code = match desc {
             ExpDesc::VarArgs =&gt; {
                 // variadic expression
                 ByteCode::VarArgs(self.sp as u8, want as u8)
             }
             _ =&gt; {
                 // For other types of expressions, still use the previous method, that is, use LoadNil to fill
                 self.discharge(self.sp, desc);
                 ByteCode::LoadNil(self.sp as u8, want as u8 - 1)
             }
         };
         self.fp.byte_codes.push(code);
     }</code></pre>
<p>This function is similar to the <code>discharge_expand()</code> function in the first scenario above, but there are two differences:</p>
<ul>
<li>
<p>Previously, <em>all</em> variable arguments in the actual execution were required, but this function has a certain number of requirements, so there is an additional parameter <code>want</code>;</p>
</li>
<li>
<p>The previous function needs to return whether it is a variable arguments, so that the caller can make a distinction; but this function has no return value because the requirement is clear and the caller does not need to make a distinction.</p>
</li>
</ul>
<p>Compared with the first scenario above, another important change is that <code>VarArgs</code> bytecode adds an associated parameter to indicate how many arguments need to be loaded onto the stack. Because in this scenario, this parameter is definitely not less than 2, and in the next scenario, this parameter is fixed at 1, and 0 is not used, so 0 can be used as a special value to represent the value in the first scenario above: <em>all</em> arguments at execution time.</p>
<p>The virtual machine execution code of this bytecode is also changed as follows:</p>
<pre><code class="language-rust  ignore">     ByteCode::VarArgs(dst, want) =&gt; {
         self.stack.truncate(self.base + dst as usize);

         let len = varargs.len(); // actual number of arguments
         let want = want as usize; // need the number of arguments
         if want == 0 { // All arguments are required, and the process remains unchanged
             self.stack.extend_from_slice(&amp;varargs);
         } else if want &gt; len {
             // Need more than actual, fill `nil` with fill_stack()
             self.stack.extend_from_slice(&amp;varargs);
             self.fill_stack(dst as usize + len, want - len);
         } else {
             // needs as much or less than actual
             self.stack.extend_from_slice(&amp;varargs[..want]);
         }
     }</code></pre>
<p>So far, the second scenario of variable parameters has been completed.</p>
<h2 id="scenario-3-only-take-the-first-variable-argument"><a class="header" href="#scenario-3-only-take-the-first-variable-argument">Scenario 3: Only Take the First Variable Argument</a></h2>
<p>The two scenarios introduced above are in a specific statement context, and the variable arguments are loaded onto the stack through the <code>discharge_expand_want()</code> or <code>discharge_expand()</code> function respectively. And the 3rd scenario is everywhere except the above specific statement context. So from this perspective, the third scene can be regarded as a general scene, so a general loading method must be used. Before the variable arguments expression is introduced in this section, all other expressions are loaded onto the stack by calling the <code>discharge()</code> function, which can be regarded as a general loading method. So in this scenario, the variable arguments expression should also be loaded through the <code>discharge()</code> function.</p>
<p>In fact, this scenario has already been encountered above. For example, in the second scenario above, if the number of expressions on the right side of <code>=</code> is equal to the number of local variables, the last expression is processed by the <code>discharge()</code> function:</p>
<pre><code class="language-rust  ignore">     let (nexp, last_exp) = self.explist();
     match (nexp + 1).cmp(&amp;want) {
         Ordering::Equal =&gt; {
             // If the expression is consistent with the number of
             // local variables, the last expression is also normal
             // discharged on the stack.
             self.discharge(self.sp, last_exp);
         }</code></pre>
<p>Here the last expression of <code>discharge()</code> may also be a variable arguments expression <code>...</code>, then it is the current scene.</p>
<p>For another example, the <code>explist()</code> function is called in the above two scenarios to process the expression list. Except for the last expression, all previous expressions are loaded onto the stack by this function by calling <code>discharge()</code>. If there is a variable arguments expression <code>...</code> in the previous expression, such as <code>foo(a, ..., b)</code>, then it is also the current scene.</p>
<p>In addition, the above also lists examples of variable expressions in other statements, all of which belong to the current scene.</p>
<p>Since this scene belongs to a general scene, there is no need to make any changes in the syntax analysis stage, but only need to complete the processing of the variable expression <code>ExpDesc::VarArgs</code> in the <code>discharge()</code> function. This process is also very simple, just use the <code>VarArgs</code> bytecode introduced above, and only load the first argument to the stack:</p>
<pre><code class="language-rust  ignore">     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             ExpDesc::VarArgs =&gt; ByteCode::VarArgs(dst as u8, 1), // 1 means only load the first argument</code></pre>
<p>This completes the third scenario.</p>
<p>At this point, all the scenarios of variable arguments are finally introduced.</p>
<h2 id="summary-4"><a class="header" href="#summary-4">Summary</a></h2>
<p>This section begins by introducing the mechanism of parameters and arguments respectively. For parameters, syntax analysis puts the parameters in the local variable table and uses them as local variables. For arguments, the caller loads the parameters onto the stack, which is equivalent to assigning values to the parameters.</p>
<p>Most of the following pages introduce the processing of variable arguments, including three scenarios: all arguments, fixed number of arguments, and the first argument in general scenarios.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="return-value"><a class="header" href="#return-value">Return Value</a></h1>
<p>This section describes the return values of Lua functions. First introduce the case of fixed number return values, and then introduce the case of variable number.</p>
<p>Similar to the parameter characteristics in the previous section involving parameters and arguments, there are two places involved in realizing the return value of a function:</p>
<ul>
<li>
<p>The called function generates a return value before exiting. This is done with the <code>return</code> statement in Lua. Correspondingly, the <code>Return</code> bytecode needs to be added.</p>
</li>
<li>
<p>The caller reads and processes the return value. This part of the functionality is implemented in <code>Call</code> bytecode. Previous <code>Call</code> bytecode just called the function without processing the return value.</p>
</li>
</ul>
<p>Just as the arguments are passed by the stack, the return values are also passed by the stack.</p>
<p>We first introduce the <code>return</code> statement and <code>Return</code> bytecode that the function generates the return value.</p>
<h2 id="return-bytecode"><a class="header" href="#return-bytecode"><code>Return</code> Bytecode</a></h2>
<p>Between the called function and the caller, the return values are passed using the stack. The called function generate return values and loads them on the stack, and then notifies the caller of the return values' positions on the stack, and the caller reads the return values from the stack.</p>
<p>Functions in Lua language support multiple return values. If the positions of these return values on the stack are discontinuous, it is difficult to inform the caller of the specific return value. Therefore, all return values are required to be arranged continuously on the stack, so that the caller can be informed by the starting index on the stack and the number of return values. To do this, all return values need to be loaded onto the top of the stack in turn. Like the following example:</p>
<pre><code class="language-lua">local function foo()
     local x, y = 1, 2
     return x, &quot;Yes&quot;, g1+g2
end
</code></pre>
<p>The stack layout before the function returns is as follows:</p>
<pre><code>|       |
+-------+
|  foo  | The caller loads `foo` onto the stack
+=======+ &lt;--base
|   x   | 0 \
+-------+    + local variables
|   y   | 1 /
+-------+
|   x   | 2 \
+-------+    |
| &quot;yes&quot; | 3   + return value
+-------+    |
| g1+g2 | 4 /
+-------+
|  g2   | 5&lt;-- temporary variables
+-------+
|       |
</code></pre>
<p>The numbers 0~5 on the right side of the stack are relative addresses. Among them, 2~4 is the position of the return values on the stack, then the information to be returned by this function is <code>(2, 3)</code>, where <code>2</code> is the starting position of the return value on the stack, and <code>3</code> is the return values number. It can be seen that the newly added bytecode <code>Return</code> needs to be associated with 2 parameters.</p>
<p>In addition to the above-mentioned general cases, there are two special cases, that is, the cases where the number of return values is 0 and 1.</p>
<p>First of all, for the case where the number of return values is 0, that is, the return statement with no return value, although the <code>Return</code> bytecode can also be used to return <code>(0, 0)</code>, but for clarity, we add bytecode <code>Return0</code> without associate parameter for this case.</p>
<p>Secondly, for the case where the number of return values is 1, it can be optimized during syntax analysis. In the case of the above multiple return values, it is mandatory to load all the return values onto the stack sequentially for the sake of continuity and to be able to notify the caller of the position of the return value. And if there is only one return value, continuity is not required, so for local variables that are already on the stack, there is no need to load them on the stack again. Of course, other types of return values (such as global variables, constants, table indexes, etc.) still need to be loaded. Like the following example:</p>
<pre><code class="language-lua">local function foo()
     local x, y = 1, 2
     return x
end
</code></pre>
<p>The stack layout before the function returns is as follows:</p>
<pre><code>|       |
+-------+
|  foo  | The caller loads foo onto the stack
+=======+ &lt;--base
|   x   | 0 \    &lt;-----return values
+-------+    + local variables
|   y   | 1 /
+-------+
|       |
</code></pre>
<p>There is only one return value <code>x</code>, and it is a local variable, which is already on the stack, and it is enough to return <code>(0, 1)</code>, without loading it to the top of the stack again.</p>
<p>In summary, the newly added two bytecodes are defined as follows:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Return0,
     Return(u8, u8),</code></pre>
<p>The parsing process of the <code>return</code> statement is as follows:</p>
<ul>
<li>for no return value, generate <code>Return0</code> bytecode;</li>
<li>For a single return value, <em>on-demand</em> loaded onto the stack and generate <code>Return(?, 1)</code> bytecode;</li>
<li>For multiple return values, <em>force</em> to be loaded onto the stack sequentially and generate <code>Return(?, ?)</code> bytecode.</li>
</ul>
<h2 id="syntax-analysis-of-return-statement"><a class="header" href="#syntax-analysis-of-return-statement">Syntax Analysis of <code>return</code> statement</a></h2>
<p>The parsing process of the <code>return</code> statement is summarized above, and now the syntax analysis begins. The BNF definition of the <code>return</code> statement is as follows:</p>
<pre><code>retstat ::= return [explist][';']
</code></pre>
<p>In addition to optional multiple return value expressions, there can be 1 optional <code>;</code>. In addition, there is another rule, that is, the end token of a block must be followed by the return statement, such as <code>end</code>, <code>else</code>, etc. This statement is relatively simple, but there are more details. The code is first listed below:</p>
<pre><code class="language-rust  ignore">     fn ret_stat(&amp;mut self) {
         let code = match self. lex. peek() {
             // return;
             Token::SemiColon =&gt; {
                 self. lex. next();
                 ByteCode::Return0 // no return value
             }

             // return
             t if is_block_end(t) =&gt; {
                 ByteCode::Return0 // no return value
             }

             _ =&gt; { // has return values
                 let mut iret = self.sp;

                 // Read the list of expressions. Only the last one is kept and ExpDesc
                 // is returned, while the previous ones are loaded onto the stack.
                 // Return value: `nexp` is the number of previously loaded expressions,
                 // and `last_exp` is the last expression.
                 let (nexp, last_exp) = self.explist();

                 // check optional ';'
                 if self.lex.peek() == &amp;Token::SemiColon {
                     self. lex. next();
                 }
                 // check block end
                 if !is_block_end(self.lex.peek()) {
                     panic!(&quot;'end' expected&quot;);
                 }

                 if nexp == 0 {
                     // single return value, loaded *on demand*
                     iret = self.discharge_any(last_exp);
                 } else {
                     // Multiple return values, other return values have been loaded to
                     // the top of the stack in turn, now we need to put the last
                     // Expressions are also *forced* to be loaded on top of the stack,
                     // after other return values
                     self.discharge(self.sp, last_exp);
                 }

                 ByteCode::Return(iret as u8, nexp as u8 + 1)
             }
         };
         self.fp.byte_codes.push(code);
     }</code></pre>
<p>Because the processing of single and multiple return values is different, when reading the return value list, keep the last expression and not directly load it on the stack. At this point, the modified <code>explist()</code> function in the previous section comes in handy again. If there is only the last expression, that is, <code>nexp == 0</code>, then it is a single expression, and it is loaded on the stack as needed; otherwise, it is the case of multiple return values, and other return values have been loaded to the stack in turn At the top, it is necessary to force the last expression to be loaded on the top of the stack, behind other return values.</p>
<p>To review, in the above code, the <code>discharge_any()</code> method in the case of a single return value is <em>on-demand</em> loading, that is, it does not process expressions already on the stack (local variables or temporary variables, etc.); and The <code>discharge()</code> method in the case of multiple return values is <em>forced</em> to load.</p>
<h2 id="return-bytecode-execution"><a class="header" href="#return-bytecode-execution">Return Bytecode Execution</a></h2>
<p>After completing the syntax analysis, the next step is to introduce the execution of the <code>Return</code> bytecode by the virtual machine. Two things need to be done:</p>
<ul>
<li>
<p>To exit from the execution of the current function <code>execute()</code>, use the <code>return</code> statement of Rust;</p>
</li>
<li>
<p>The most intuitive way to tell the caller the position of the return value is to return the two parameters associated with <code>Return</code> bytecode: the starting position and number of return values on the stack. However, the starting position here needs to be converted from a relative position to an absolute position. code show as below:</p>
</li>
</ul>
<pre><code class="language-rust  ignore">     ByteCode::Return(iret, nret) =&gt; {
         return (self. base + iret as usize, nret as usize);
     }</code></pre>
<p>This is a bit long-winded, and there are 2 problems:</p>
<ul>
<li>
<p>The prototype of the Rust function type in Lua (such as the <code>print</code> function) is <code>fn (&amp;mut ExeState) -&gt; i32</code>, and there is only 1 return value <code>i32</code>, which represents the number of Rust function return values. If the Lua function type returns 2 values, the return information of these two types of functions is inconsistent, which is inconvenient to handle later.</p>
</li>
<li>
<p>Later in this section, a variable number of return values of Lua functions will be supported, and the specific number of return values needs to be calculated according to the execution situation.</p>
</li>
</ul>
<p>So it is also changed here to only return the number of Lua function return values, but not returning the starting position. For this reason, possible temporary variables on the stack need to be cleaned up to ensure that the return value is at the top of the stack. In this way, the caller can determine the position of the return value only according to the number of return values. Also using the above example:</p>
<pre><code>|       |
+-------+
|  foo  | The caller loads foo onto the stack
+=======+ &lt;--base
|   x   | 0 \
+-------+    + local variables
|   y   | 1 /
+-------+
|   x   | 2 \
+-------+    |
| &quot;yes&quot; | 3   + return values
+-------+    |
| g1+g2 | 4 /
+-------+
|       | &lt;--clean up the temporary variable `g2`
</code></pre>
<p>In this example, after clearing the temporary variable <code>g2</code> at the top of the stack, only return <code>3</code> to the calling function, and the calling function can read the 3 values at the top of the stack as the return value.</p>
<p>So why do we need to associate 2 parameters in the <code>Return</code> bytecode? In addition to the number of return values, but also the starting position of the return value? This is because it is difficult to determine whether there are temporary variables on the top of the stack during execution during the syntax analysis phase (such as <code>g2</code> in the above example), and even if it can be determined, there is nothing to do with these temporary variables (unless a bytecode is added to clean up the temporary variables ). Therefore, the return value cannot be expressed only by the number. In the virtual machine execution stage, since possible temporary variables can be cleaned up, there is no need to return to the starting address without the interference of temporary variables.</p>
<p>In summary, the execution code of <code>Return</code> bytecode is as follows:</p>
<pre><code class="language-rust  ignore">     ByteCode::Return(iret, nret) =&gt; {
         // convert relative address to absolute address
         let iret = self.base + iret as usize;

         // clean up temporary variables to ensure that `nret`
         // at the top of the stack is the return value
         self.stack.truncate(iret + nret as usize);

         return nret as usize;
     }
     ByteCode::Return0 =&gt; {
         return 0;
     }</code></pre>
<p>Correspondingly, the entry function <code>execute()</code> executed by the virtual machine also needs to modify the prototype, change it to return a <code>usize</code> value:</p>
<pre><code class="language-rust  ignore">     pub fn execute(&amp;mut self, proto: &amp;FuncProto) -&gt; usize {</code></pre>
<h2 id="bytecode-traversal-and-function-exit"><a class="header" href="#bytecode-traversal-and-function-exit">Bytecode Traversal and Function Exit</a></h2>
<p>Now that the <code>execute()</code> function is mentioned, let's talk about the traversal and exit of the bytecode sequence.</p>
<p>At the beginning, this project only supported sequential execution, using Rust Vec's iterator:</p>
<pre><code class="language-rust  ignore">     for code in proto.byte_codes.iter() {
         match *code {</code></pre>
<p>Later, after the jump statement is supported, it is necessary to traverse manually, and judge whether to exit by whether the <code>pc</code> exceeds the bytecode sequence:</p>
<pre><code class="language-rust  ignore">     let mut pc = 0;
     while pc &lt; proto.byte_codes.len() {
         match proto.byte_codes[pc] {</code></pre>
<p>Lua's <code>return</code> statement is now supported, and the execution of the corresponding <code>Return</code> bytecode will exit the <code>execute()</code> function. If all Lua functions eventually contain the <code>Return</code> bytecode, there is no need to check whether the pc has exceeded the bytecode sequence to determine whether to exit. In this way, the original <code>while</code> loop in the <code>execute()</code> function can be changed to a <code>loop</code> loop, reducing a conditional judgment:</p>
<pre><code class="language-rust  ignore">     let mut pc = 0;
     loop {
         match proto.byte_codes[pc] {
             ByteCode::Return0 =&gt; { // Return or Return0 bytecode, exit function
                 return 0;
             }</code></pre>
<p>To do this, we append the <code>Return0</code> bytecode at the end of all Lua functions:</p>
<pre><code class="language-rust  ignore">fn chunk(lex: &amp;mut Lex&lt;impl Read&gt;, end_token: Token) -&gt; FuncProto {
     let mut proto = ParseProto::new(lex);
     assert_eq!(proto.block(), end_token);
     if let Some(goto) = proto. gotos. first() {
         panic!(&quot;goto {} no destination&quot;, &amp;goto.name);
     }

     // All Lua functions end with `Return0` bytecode
     proto.fp.byte_codes.push(ByteCode::Return0);

     proto.fp
}</code></pre>
<p>So far, the function of exiting the function and generating a return value is completed. Next, introduce the second part: the caller reads the return value.</p>
<h2 id="read-return-values-position"><a class="header" href="#read-return-values-position">Read Return Values: Position</a></h2>
<p>After the called function returns through the <code>return</code> statement, the virtual machine execution sequence returns back to the <code>Call</code> bytecode of the outer calling function, where the return values are read and processed. How to handle the return values? It depends on the different application scenarios where the function call is made. Because the Lua function supports multiple return values, and the specific number of return values cannot be determined during the syntax analysis stage, similar to the variable parameters expression <code>...</code> in the previous section, the processing of the function return values is simlar with the variable parameter and also includes 3 scenarios:</p>
<ol>
<li>
<p>When used as the last argument of a function call, the last value of a <code>return</code> statement, or the last array member of a table construction, read all return values. For example, the following example:</p>
<pre><code class="language-lua">print(&quot;hello: &quot;, foo(1, 2)) -- last argument
local t = {1, 2, foo()} -- last list member
return a+b, foo() -- the last return value
</code></pre>
</li>
<li>
<p>When used as the last expression after the equal sign <code>=</code> of a local variable definition statement or an assignment statement, the number of return values will be expanded or reduced as required. For example, the following example:</p>
<pre><code class="language-lua">local x, y = foo() -- take the first 2 actual parameters and assign them to x and y respectively
t.k, t.j = a, foo() -- take the first actual parameter and assign it to t.j
</code></pre>
</li>
<li>
<p>Other places only represent the first actual parameter passed in. For example, the following example:</p>
<pre><code class="language-lua">local x, y = foo(), b -- not the last expression, just take the first argument and assign it to x
t.k, t.j = foo(), b -- not the last expression, just take the first argument and assign it to t.k
if foo() then -- conditional judgment
   t[foo()] = foo() + f -- table index, and binary operands
end
</code></pre>
</li>
</ol>
<p>In addition, there is another scenario:</p>
<ol start="4">
<li>
<p>For a single function call statement, the return values are ignored at this time. For example, the following example:</p>
<pre><code class="language-lua">print(&quot;no results&quot;)
foo(1, 2, 3)
</code></pre>
</li>
</ol>
<p>The fourth scenario does not need to deal with the return values, so ignore it for now. In the previous three scenarios, it is necessary to move the return values from the top of the stack to the position of the function entry. For example, for the <code>print(&quot;hello&quot;, sqr(3, 4))</code> statement, the stack layout before calling the <code>sqr()</code> function is shown in the left figure below:</p>
<pre><code>|       |        |       |                |       |
+-------+        +-------+                +-------+
| print |        | print |                | print |
+-------+        +-------+                +-------+
|&quot;hello&quot;|        |&quot;hello&quot;|                |&quot;hello&quot;|
+-------+        +-------+                +-------+
|  sqr  |        |  sqr  |              / |   9   | &lt;--original sqr entry position
+-------+        +-------+ &lt;--base   /-+  +-------+
|   3   |        |   3   |           |  \ |   16  |
+-------+        +-------+           |    +-------+
|   4   |        |   4   |           |    |       |
+-------+        +-------+           |
|       |        |   9   | \         |
                 +-------+  +return--/
                 |   16  | / values
                 +-------+
                 |       |
</code></pre>
<p>In the left picture, the <code>print</code> function is at the top of the stack, followed by the parameter <code>&quot;hello&quot;</code> string constant and the <code>sqr()</code> function, and then the two parameters of the <code>sqr()</code> function: <code>3</code> and <code>4</code>. The important point here is that in the syntax analysis stage, the arguments of the function are generated by <code>explist()</code> bytecodes, which are loaded onto the stack in turn, so the <code>sqr()</code> function must be located in the <code>print()</code> function's argument location. Then, the return value of the <code>sqr()</code> function should be moved to the position of the <code>sqr()</code> function as the argument of the <code>print()</code> function, as shown in the rightmost figure in the above figure.</p>
<p>Therefore, the above three stack layout diagrams are summarized as follows:</p>
<ul>
<li>
<p>The picture on the left is the state before the <code>sqr()</code> function call;</p>
</li>
<li>
<p>The picture in the middle is after the <code>sqr()</code> function is called, that is, the state after the <code>Return</code> bytecode introduced in the previous part of this section is executed;</p>
</li>
<li>
<p>The picture on the right is the expected state after calling the <code>sqr()</code> function, that is, the return value of the <code>sqr()</code> function is used as the return value of the <code>print()</code> function.</p>
</li>
</ul>
<p>Therefore, what we need to do is to change the stack layout from the middle picture to the right picture, so in the processing flow of <code>Call</code> bytecode, move the return value from the top of the stack to the position of the function entry, which is the last line in the following code :</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, narg_plus) =&gt; {
         self.base += func as usize + 1;
         match &amp;self.stack[self.base - 1] {
             Value::LuaFunction(f) =&gt; {
                 // The processing of parameters is omitted here.

                 // Call the function, `nret` is the number of return values at the top of the stack
                 let nret = self. execute(&amp;f);

                 // Delete the stack values from the function entry to the
                 // starting position of the return values, so the return
                 // values are moved to the function entry position.
                 self.stack.drain(self.base+func as usize .. self.stack.len()-nret);
             }</code></pre>
<p>Here, the return values are not directly moved to the function entry position, but the stack data from the function entry to the start position of the return value is cleared through the <code>Vec::drain()</code> method to realize the return value in place. This is also done to clean up the stack space occupied by the called function at the same time, so as to release resources in time.</p>
<h2 id="read-return-value-number"><a class="header" href="#read-return-value-number">Read Return Value: Number</a></h2>
<p>The above describes where to put the return values, now let's deal with the number of return values. This is also the same as the variable parameter expression in the previous section. According to the above four scenarios, it is also divided into four types:</p>
<ol>
<li>All return values;</li>
<li>Fixed the first N return values;</li>
<li>The first return value;</li>
<li>No return value is required.</li>
</ol>
<p>Similar to <code>VarArgs</code> bytecode, <code>Call</code> bytecode also needs to add a parameter to indicate how many return values are needed:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Call(u8, u8, u8) // Add the third associated parameter, indicating how many return values are required</code></pre>
<p>But there is a difference here, that is the number of parameters associated with <code>VarArgs</code>, and the value <code>0</code> means all variable arguments. The fourth scenario is added here for the function call, which does not need a return value, that is, a return value of <code>0</code> is required, so the new associated parameters of the <code>Call</code> bytecode cannot be represented by <code>0</code> as a special value for all return values. This is like the scene in the previous section <a href="./ch08-02.arguments.html#scenario-1-all-variable-arguments">Number of parameters</a>, that is, there are already <code>0</code> parameters, so it cannot be simply used <code>0</code> is a special value. There are two solutions to this problem:</p>
<ul>
<li>
<p>Refer to the processing method of the number of parameters in the previous section, use <code>0</code> to represent all return values, and change the case of fixed N return values to N+1 and encode them into the <code>Call</code> bytecode. This is also the scheme adopted by Lua's official implementation;</p>
</li>
<li>
<p>Take the &quot;no need to return value&quot; in the fourth scenario as &quot;ignore the return value&quot;, that is, there is no need to process the return value, or it doesn't matter how to process the return value. Then in this scenario, we can fill in any number for this associated parameter. Here we choose to fill in <code>0</code>.</p>
</li>
</ul>
<p>We choose the latter option. That is to say, the value <code>0</code> has two meanings:</p>
<ul>
<li>All return values are required;</li>
<li>No return value is required.</li>
</ul>
<p>Although the meanings of these two scenarios are different, the processing method is the same when the virtual machine is executed, and the return value is not processed. In other words, all return values (if any) will be placed at the function entry.</p>
<p>If the value of this parameter is not <code>0</code>, it corresponds to the second and third scenarios above, that is, the situation where the first N and the first return values need to be fixedIn this case, you need to deal with:</p>
<ul>
<li>If the actual return value is less than the expected demand, then <code>nil</code> needs to be added;</li>
<li>Otherwise, no processing is required. The extra return value is considered as a temporary variable on the stack and has no effect.</li>
</ul>
<p>Next, add this nil filling process in the process of executing <code>Call</code> bytecode in the virtual machine:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, narg_plus, want_nret) =&gt; {
         self.base += func as usize + 1;
         match &amp;self.stack[self.base - 1] {
             Value::LuaFunction(f) =&gt; {
                 let nret = self. execute(&amp;f);
                 self.stack.drain(self.base+func as usize .. self.stack.len()-nret);

                 // Fill nil as needed
                 // If want_nret==0, there is no need to process it, and it will not enter the if{} branch.
                 let want_nret = want_nret as usize;
                 if nret &lt; want_nret {
                     self.fill_stack(nret, want_nret - nret);
                 }
             }</code></pre>
<p>At this point, the virtual machine execution part of <code>Call</code> bytecode is completed.</p>
<h2 id="syntax-analysis-of-scenarios"><a class="header" href="#syntax-analysis-of-scenarios">Syntax Analysis of Scenarios</a></h2>
<p>In previous chapters, we always introduce syntax analysis to generate bytecode first, and then introduce the virtual machine to execute the bytecode. But this time is different. The above only introduces the virtual machine execution of <code>Call</code> bytecode in different scenarios; it does not introduce syntax analysis, that is, how to generate <code>Call</code> bytecode in each scenario. Make it up now.</p>
<p>The first and second scenarios above are exactly the same as the <a href="./ch08-02.arguments.html#scenario-1-all-variable-arguments">corresponding scenario</a> of variable parameter expressions, so there is no need to do these statements here to modify, we only need to add <code>ExpDesc::Call</code> expressions in <code>discharge_expand()</code> and <code>discharge_expand_want()</code>. The code of <code>discharge_expand()</code> is listed below, and ``discharge_expand_want()` is similar, so it is omitted here.</p>
<pre><code class="language-rust  ignore">     fn discharge_expand(&amp;mut self, desc: ExpDesc) -&gt; bool {
         let code = match desc {
             ExpDesc::Call(ifunc, narg_plus) =&gt; { // Add function call expression
                 ByteCode::Call(ifunc as u8, narg_plus as u8, 0)
             }
             ExpDesc::VarArgs =&gt; {
                 ByteCode::VarArgs(self.sp as u8, 0)
             }
             _ =&gt; {
                 self.discharge(self.sp, desc);
                 return false
             }
         };
         self.fp.byte_codes.push(code);
         true
     }</code></pre>
<p>In Lua, when the number of values cannot be determined during the syntax analysis stage, there are only variable arguments and function calls. So these two functions are now complete. If there are other similar statements, we can also add statements to this function without modifying the specific application scenario.</p>
<p>Next, look at the third scenario, which only takes the first return value. The same as the variable arguments statement in the previous section, the loading of the <code>ExpDesc::Call</code> expression is also completed in the <code>discharge()</code> function. Unlike the variable arguments statement, the first associated parameter of the <code>VarArgs</code> bytecode generated by the variable arguments is the target address, and the three parameters associated with the <code>Call</code> bytecode here have no target address of. It is introduced above that when the virtual machine is executed, the return value is placed at the entry address of the function, but the <code>discharge()</code> function is to load the value of the expression to the specified address. Therefore, the loading of the <code>ExpDesc::Call</code> expression may require 2 bytecodes: first generate the <code>Call</code> bytecode to call the function and put the return value at the function entry position, and then generate the <code>Move</code> bytecode to put the first A return value is assigned to the target address. code show as below:</p>
<pre><code class="language-rust  ignore">     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             ExpDesc::Call(ifunc, narg_plus) =&gt; {
                 // Generate Call, keep only 1 return value, and put it in ifunc position
                 self.fp.byte_codes.push(ByteCode::Call(ifunc as u8, narg_plus as u8, 1));

                 // Generate Move, copy return value from ifunc to dst position
                 self.fp.byte_codes.push(ByteCode::Move(dst as u8, ifunc as u8));
             }</code></pre>
<p>For example, the following sample code:</p>
<pre><code class="language-lua">local x, y
x = foo()
</code></pre>
<p>Its stack layout is as follows:</p>
<pre><code>|       |          |       |          |       |
+-------+          +-------+          +-------+
|   x   |          |   x   |    /----&gt;|   x   |
+-------+          +-------+    |     +-------+
|   y   |          |   y   |    |     |   y   |
+-------+          +-------+    |     +-------+
|  foo  |    /----&gt;|  100  |----/     |       |
+-------+    |     +-------+    Move bytecode assigns the return value to the target address
:       :    |     |       |
+-------+    |
|  100  |----/ `Call` bytecode moves the returns value 100 to `foo` position
+-------+
|       |
</code></pre>
<ul>
<li>The picture on the left is the stack layout before the <code>foo()</code> function returns, assuming <code>100</code> at the top of the stack is the return value of the function;</li>
<li>The picture in the middle shows that after the <code>Call</code> bytecode is executed, the return value is moved to the function entry position, which is the function completed above in this section;</li>
<li>The figure on the right is the <code>Move</code> bytecode assigning the return value to the target address, that is, the local variable <code>x</code>.</li>
</ul>
<p>It can be seen that 2 bytecodes are generated in this scenario, and the return value is also moved 2 times. There is room for optimization here. The reason why 2 bytecodes are needed is because the <code>Call</code> bytecode has no parameters associated with the target address, so it cannot be directly assigned. The reason why there is no associated target address parameter is because the <code>Call</code> bytecode has already stuffed 3 parameters, and there is no space to stuff it into the target address.</p>
<p>Once the problem is identified, the optimization solution becomes obvious. Since only one return value is always required in this scenario, the third associated parameter (the number of required return values) in <code>Call</code> bytecode is meaningless. So you can add a bytecode dedicated to this scenario, delete the third parameter in the <code>Call</code> bytecode, and make room for the parameter of the target address. For this, we add <code>CallSet</code> bytecode:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Call(u8, u8, u8), // Associated parameters: function entry, number of arguments, number of expected return values
     CallSet(u8, u8, u8), // Associated parameters: target address, function entry, number of arguments</code></pre>
<p>In this way, in the <code>discharge()</code> function, the function call statement only needs one bytecode:</p>
<pre><code class="language-rust  ignore">     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             ExpDesc::Call(ifunc, narg) =&gt; {
                 ByteCode::CallSet(dst as u8, ifunc as u8, narg as u8)
             }</code></pre>
<p>The virtual machine execution of <code>CallSet</code> bytecode is as follows:</p>
<pre><code class="language-rust  ignore">     ByteCode::CallSet(dst, func, narg) =&gt; {
         // Call functions
         let nret = self. call_function(func, narg);

         if nret == 0 { // no return value, set nil
             self. set_stack(dst, Value::Nil);
         } else {
             // use swap() to avoid clone()
             let iret = self.stack.len() - nret as usize;
             self.stack.swap(self.base+dst as usize, iret);
         }

         // Clean up the stack space occupied by the function call
         self.stack.truncate(self.base + func as usize + 1);
     }</code></pre>
<p>The <code>call_function()</code> method in the above is a function that extracts the execution flow of <code>Call</code> bytecode. After calling the function, if there is no return value, set the target address to <code>nil</code>, otherwise assign the first return value to the target address. The last line cleans up the stack space occupied by function calls, and there are 2 cases in cleaning:</p>
<ul>
<li>If the target address is a local variable, then the cleanup location is from the function entry;</li>
<li>If the target address is a temporary variable, set the target address of the function return value as the function entry position in <code>discharge_any()</code>, so the cleaning position starts from one position behind the function entry.</li>
</ul>
<p>In summary, always start cleaning from a position behind the function entry position, which can satisfy the above two conditions. Only in the case of local variables, one more function entry will be reserved.</p>
<h2 id="variable-number-of-return-values"><a class="header" href="#variable-number-of-return-values">Variable Number of Return Values</a></h2>
<p>The syntax analysis and virtual machine execution of the return value are introduced above, but one place is still missing. Among the three application scenarios of variable parameters listed in the previous section, the first scenario includes three statements: table construction, function argument, and function return value. At that time, only the first two statements were introduced. Now that the return value statement is supported, the last statement is added.</p>
<p>This section <a href="ch08-03.results.html#syntax-analysis-of-return-statement">above</a> introduces the syntax analysis of the return statement, but at that time, all expressions of the return value were loaded onto the stack in sequence, that is, only a fixed number of return values was supported. When the last expression of the function return value statement is a variable parameter or a function call statement, then all variable parameters or all return values of the function when the virtual machine is executed will be used as the return value of this function, that is to say, the number of return values cannot be determined during the parsing phase, that is, a variable number of return values.</p>
<p>Variable number of return values, syntax analysis can refer to the previous section <a href="./ch08-02.arguments.html#scenario-1-all-variable-arguments">table construction</a> or <a href="./ch08-02.arguments.html#scenario-1-all-variable-arguments-continued">function arguments</a>, that is, use the modified <code>explist()</code> function , special treatment is given to the last expression. The specific code is omitted here.</p>
<p>What needs to be explained is how to represent &quot;variable number&quot; in bytecode. In this section, two new return value-related bytecodes are added, <code>Return0</code> and <code>Return</code>. Among them, <code>Return0</code> is used when there is no return value, so the parameter of the number of return values associated in <code>Return</code> bytecode will not be <code>0</code>, then <code>0</code> can be used as a special value to indicate variable number.</p>
<h2 id="summary-of-variable-number-statements-and-scenario"><a class="header" href="#summary-of-variable-number-statements-and-scenario">Summary of Variable Number Statements and Scenario</a></h2>
<p>Here is a summary of statements and scenarios related to variable quantities. Statements that directly result in variable numbers include:</p>
<ul>
<li>Variable argument statement <code>...</code>, there are <a href="./ch08-02.arguments.html#expdescvarargs-and-application-scenarios">3 application scenarios</a>;</li>
<li>Function call statement, in addition to the 3 application scenarios of variable parameters, there is also a scenario of ignoring the return value.</li>
</ul>
<p>Among the several application scenarios of these two statements, the first scenario is to take all the actual parameters or return values when the virtual machine is executed. This scenario includes 3 statements:</p>
<ul>
<li>Table construction, corresponding to <code>SetList</code> bytecode;</li>
<li>Function arguments, corresponding to <code>Call/CallSet</code> bytecode;</li>
<li>The return value of the function corresponds to the <code>Return</code> bytecode of the called function and the <code>Call/CallSet</code> bytecode of the calling function.</li>
</ul>
<p>In the above bytecodes, in order to represent the state of &quot;actually all expressions when the virtual machine is executed&quot;, <code>0</code> is used as a special value, among which:</p>
<ul>
<li>
<p>The second parameter of <code>Call/CallSet</code> bytecode represents the number of actual parameters. Because the function call originally supports no parameters, in order to use <code>0</code> as a special value, we have to correcte the number with adding by 1 for fixed number case, that is, N fixed parameters are encoded into N+1 in the bytecode;</p>
</li>
<li>
<p>The third parameter of <code>Call/CallSet</code> bytecode represents the number of expected return values. The function call also supports the situation that the return value is not required, but we understand &quot;no need&quot; as &quot;ignore&quot;, then it is no problem to read all the return values, so <code>0</code> can be used as a special value;</p>
</li>
<li>
<p>The second parameter of <code>SetList</code> and <code>Return</code> bytecodes both represent the number. However, when these two bytecodes are used for fixed numbers, no expressions are supported, so <code>0</code> can be directly used as a special value.</p>
</li>
</ul>
<p>In addition, it needs to be emphasized again that when <code>0</code> is used to represent a special value in the above bytecode, the number of specific expressions is calculated from the top of the stack, which must ensure that there is no temporary variable on the top of the stack, so the virtual machine must explicitly clean up temporary variables when executing variable parameter and function call statements.</p>
<h2 id="summary-5"><a class="header" href="#summary-5">Summary</a></h2>
<p>This section begins by introducing fixed number return values. The called function puts the return value on the top of the stack through the <code>Return/Return0</code> bytecode, and then the calling function reads the return value in the <code>Call/CallSet</code> bytecode.</p>
<p>The variable number of return values was introduced later, which is similar to the variable parameters in the previous section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-function-and-apis"><a class="header" href="#rust-function-and-apis">Rust Function and APIs</a></h1>
<p>The previous three sections of this chapter introduce the functions defined in Lua, and this section introduces the functions defined in Rust. For the sake of simplicity, these two types of functions are called &quot;Lua functions&quot; and &quot;Rust functions&quot; respectively.</p>
<p>In fact, we have already been exposed to Rust functions. The <code>print()</code> that was supported in the <code>hello, world!</code> version of the first chapter is the Rust function. The interpreter at that time realized the definition and calling process of Rust functions. which is defined as follows:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     RustFunction(fn (&amp;mut ExeState) -&gt; i32),</code></pre>
<p>Here is an example of the implementation code of <code>print()</code> function:</p>
<pre><code class="language-rust  ignore">fn lib_print(state: &amp;mut ExeState) -&gt; i32 {
     println!(&quot;{}&quot;, state.stack[state.base + 1]);
     0
}</code></pre>
<p>The calling method of the Rust function is also similar to the Lua function, and the Rust function is also called in the <code>Call</code> bytecode:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, _) =&gt; {
         let func = &amp;self. stack[func as usize];
         if let Value::Function(f) = func {
             f(self);</code></pre>
<p>The codes listed above are the functions of the implemented Rust functions, but they are only the most basic definitions and calls, and still lack parameters and return values. This section adds these two features to Rust functions.</p>
<p>One thing that needs to be explained is that in Lua code, the function call statement does not distinguish between Lua functions and Rust functions. In other words, the two types are not distinguished during the parsing phase. It is only in the virtual machine execution stage that the two types need to be treated differently. Therefore, what is described below in this section is all about the virtual machine stage.</p>
<h2 id="argument"><a class="header" href="#argument">Argument</a></h2>
<p>The arguments of Rust functions are also passed through the stack.</p>
<p>You can see that the implementation of the current <code>print()</code> function only supports one parameter, which is by directly reading the data on the stack: <code>state.stack[state.base + 1])</code>, where <code>self.base</code> is the function entry address , <code>+1</code> is the address immediately following, that is, the first parameter.</p>
<p>Now to support multiple parameters, it is necessary to inform the Rust function of the specific number of parameters. There are two options:</p>
<ul>
<li>Modify the Rust function prototype definition, add a parameter to express the number of parameters. This solution is simple to implement, but it is inconsistent with Lua's official C function prototype;</li>
<li>Adopt the variable parameter mechanism in the previous Lua function, that is, determine the number of parameters by the position of the top of the stack.</li>
</ul>
<p>We take the latter approach. This requires cleaning up possible temporary variables on the top of the stack before calling the function Rust:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, narg_plus) =&gt; {
         let func = &amp;self. stack[func as usize];
         if let Value::Function(f) = func {
             // narg_plus!=0, fixed parameters, need to clean up possible
             //               temporary variables on the top of the stack;
             // narg_plus==0, variable parameters, no need to clean up.
             if narg_plus != 0 {
                 self.stack.truncate(self.base + narg_plus as usize - 1);
             }

             f(self);</code></pre>
<p>After cleaning up the possible temporary variables at the top of the stack, in the Rust function, the specific number of parameters can be judged through the top of the stack: <code>state.stack.len() - state.base</code>; we can also directly read any argument, such as the Nth parameter: <code>state.stack[state.base + N])</code>. So modify the <code>print()</code> function as follows:</p>
<pre><code class="language-rust  ignore">fn lib_print(state: &amp;mut ExeState) -&gt; i32 {
     let narg = state.stack.len() - state.base; // number of arguments
     for i in 0 .. narg {
         if i != 0 {
             print!(&quot;\t&quot;);
         }
         print!(&quot;{}&quot;, state.stack[state.base + i]); // print the i-th argument
     }
     println!(&quot;&quot;);
     0
}</code></pre>
<h2 id="return-value-1"><a class="header" href="#return-value-1">Return Value</a></h2>
<p>The return value of the Rust function is also passed through the stack. The Rust function puts the return value on the top of the stack before exiting, and returns the number, which is the function of the <code>i32</code> type return value of the Lua function prototype. This is the same mechanism as the Lua function introduced in the previous section. We only need to process the return value of the Rust function according to the return value of the Lua function introduced in the previous section when the <code>Call</code> bytecode is executed:</p>
<pre><code class="language-rust  ignore">     ByteCode::Call(func, narg_plus) =&gt; {
         let func = &amp;self. stack[func as usize];
         if let Value::Function(f) = func {
             if narg_plus != 0 {
                 self.stack.truncate(self.base + narg_plus as usize - 1);
             }

             // Return the number of return values of the Rust function,
             // which is consistent with the Lua function
             f(self) as usize</code></pre>
<p>Convert the return value of the Rust function <code>f()</code> from <code>i32</code> to <code>usize</code> type and return, indicating the number of return values. Here the type conversion from <code>i32</code> to <code>usize</code> feels bad, because the C function in the official Lua implementation returns a negative number to indicate failure. We have directly panicked on all errors so far. Subsequent chapters will deal with errors uniformly. When <code>Option&lt;usize&gt;</code> is used instead of <code>i32</code>, this garish conversion will be removed.</p>
<p>The previous <code>print()</code> function had no return value and returned <code>0</code>, so it did not reflect the feature of return value. Let's take another Lua standard library function <a href="https://www.lua.org/manual/5.4/manual.html#pdf-type"><code>type()</code></a> with a return value as an example. The function of this function is to return the type of the first parameter, and the type of the return value is a string, such as &quot;nil&quot;, &quot;string&quot;, &quot;number&quot; and so on.</p>
<pre><code class="language-rust  ignore">fn lib_type(state: &amp;mut ExeState) -&gt; i32 {
     let ty = state.stack[state.base + 1].ty(); // the type of the first parameter
     state.stack.push(ty); // Push the result onto the stack
     1 // Only 1 return value
}</code></pre>
<p>Among them, the <code>ty()</code> function is a new method for the <code>Value</code> type, which returns a description of the type, and the specific code is omitted here.</p>
<h2 id="rust-api"><a class="header" href="#rust-api">Rust API</a></h2>
<p>So far, the characteristics of the parameters and return values of Rust functions have been realized. However, the access and processing of arguments and return values above are too direct, and the ability of Rust functions is too strong, not only can access the parameters of the current function, but also can access the entire stack space, and even the entire <code>state</code> state. This is irrational and dangerous. It is necessary to restrict the access of Rust functions to <code>state</code>, including the entire stack, which requires the limited ability of Rust functions to access <code>state</code> through the API. We have come to a new world: the Rust API, of course called the <a href="https://www.lua.org/manual/5.4/manual.html#4">C API</a> in the official Lua implementation.</p>
<p>The Rust API is an API provided by the Lua interpreter for Rust functions (the Lua library implemented by Rust). Its roles are as follows:</p>
<pre><code>     +------------------+
     |     Lua code     |
     +---+----------+---+
         |          |
         |  +-------V----------+
         |  | Standard Library |
         |  |    (Rust)        |
         |  +-------+----------+
         |          |Rust API
         |          |
+--------V----------V--------+
| Lua Virtual Machine (Rust) |
+----------------------------+
</code></pre>
<p>There are 3 functional requirements in the Rust function in the above section, all of which should be fulfilled by the API:</p>
<ul>
<li>Read the actual number of arguments;</li>
<li>read specified argument;</li>
<li>create return value</li>
</ul>
<p>These three requirements are described in turn below. The first is the function of reading the actual number of arguments, which corresponds to the <a href="https://www.lua.org/manual/5.4/manual.html#lua_gettop"><code>lua_gettop()</code></a> API in the official implementation of Lua. For this we provide <code>get_top()</code> API:</p>
<pre><code class="language-rust  ignore">impl&lt;'a&gt; ExeState {
     // Return to the top of the stack, that is, the number of parameters
     pub fn get_top(&amp;self) -&gt; usize {
         self.stack.len() - self.base
     }</code></pre>
<p>Although the <code>get_top()</code> function is also a method of the <code>ExeState</code> structure, it is provided as an API for external calls. The methods before <code>ExeState</code> (such as <code>execute()</code>, <code>get_stack()</code>, etc.) are all internal methods for virtual machine execution calls. In order to distinguish these two types of methods, we add an <code>impl</code> block to the <code>ExeState</code> structure to implement the API alone to increase readability. It's just that Rust does not allow the method of implementing the structure in different files, so it cannot be split into another file.</p>
<p>Then, the function of reading the specified parameters does not correspond to a function in the official Lua implementation, but a series of functions, such as <code>lua_toboolean()</code>, <code>lua_tolstring()</code>, etc., for different types. With the generic capabilities of the Rust language, we can provide only one API:</p>
<pre><code class="language-rust  ignore">     pub fn get&lt;T&gt;(&amp;'a self, i: isize) -&gt; T where T: From&lt;&amp;'a Value&gt; {
         let narg = self. get_top();
         if i &gt; 0 { // positive index, counting from self.base
             let i = i as usize;
             if i &gt; narg {
                 panic!(&quot;invalid index: {i} {narg}&quot;);
             }
             (&amp;self. stack[self. base + i - 1]). into()
         } else if i &lt; 0 { // Negative index, counting from the top of the stack
             let i = -i as usize;
             if i &gt; narg {
                 panic!(&quot;invalid index: -{i} {narg}&quot;);
             }
             (&amp;self.stack[self.stack.len() - i]).into()
         } else {
             panic!(&quot;invalid 0 index&quot;);
         }
     }</code></pre>
<p>You can see that this API also supports negative indexes, which means counting down from the top of the stack, which is the behavior of Lua's official API, and it is also a very common method of use. This also reflects the advantages of the API over direct access to the stack.</p>
<p>However, there is also a behavior that is inconsistent with the official API: when the index exceeds the stack range, the official will return <code>nil</code>, but here we panic directly. We will discuss this in detail later when we introduce error handling.</p>
<p>Based on the above two APIs, you can redo the <code>print()</code> function:</p>
<pre><code class="language-rust  ignore">fn lib_print(state: &amp;mut ExeState) -&gt; i32 {
     for i in 1 ..= state. get_top() {
         if i != 1 {
             print!(&quot;\t&quot;);
         }
         print!(&quot;{}&quot;, state.get::&lt;&amp;Value&gt;(i).to_string());
     }
     println!(&quot;&quot;);
     0
}</code></pre>
<p>Finally, let's look at the last function, creating the return value. Like the above API for reading arguments, there are also a series of functions in the official Lua implementation, such as <code>lua_pushboolean()</code>, <code>lua_pushlstring()</code>, etc. And here you can also add only one API with the help of generics:</p>
<pre><code class="language-rust  ignore">     pub fn push(&amp;mut self, v: impl Into&lt;Value&gt;) {
         self.stack.push(v.into());
     }</code></pre>
<p>Based on this API, <code>self.stack.push()</code> in the last line of <code>type()</code> function above can be changed to <code>self.push()</code>.</p>
<p>Although the implementation of the <code>print()</code> and <code>type()</code> functions has not changed significantly after replacing the API, the API provides a encapsulation for <code>ExeState</code>, which will gradually reflect the convenience in the process of gradually adding library functions safety.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tail-call"><a class="header" href="#tail-call">Tail Call</a></h1>
<p>The Lua language supports tail call elimination. This section describes and supports tail calls.</p>
<p>First we introduce the concept of tail calls. A tail call is formed when the last action of a function is to call another function without doing any other work. For example, the following sample code:</p>
<pre><code class="language-lua">function foo(a, b)
     return bar(a + b)
end
</code></pre>
<p>The last action of the <code>foo()</code> function (and in this case the only action) is to call the <code>bar()</code> function. Let's take a look at the execution process of the <code>foo()</code> function without introducing a tail call, as shown in the following figure:</p>
<pre><code>|       |        |       |        |       |        |       |
+-------+        +-------+        +-------+        +-------+
| foo() |        | foo() |        | foo() |      / |  ret1 |
+-------&lt;&lt;       +-------+        +-------&lt;&lt;   /-+ +-------+
|   a   |        |   a   |        |   a   |    | \ |  ret2 |
+-------+        +-------+        +-------+    |   +-------+
|   b   |        |   b   |        |   b   |    |   |       |
+-------+        +-------+        +-------+    |
| bar() |        | bar() |      / |  ret1 | \  |
+-------+        +-------&lt;&lt;   /-+ +-------+  &gt;-/return values
|  a+b  |        |  a+b  |    | \ |  ret2 | /
+-------+        +-------+    |   +-------+
|       |        :       :    |   |       |
                 +-------+    |
                 |  ret1 | \  |
                 +-------+  &gt;-/return values
                 |  ret2 | /
                 +-------+
                 |       |
</code></pre>
<ul>
<li>
<p>The first picture on the far left is the stack layout before calling the <code>bar()</code> function inside the <code>foo()</code> function. That is, before calling <code>Call(bar)</code> bytecode.</p>
</li>
<li>
<p>The second figure is the stack layout immediately after the <code>bar()</code> function call has completed. That is, after the <code>Return</code> bytecode of the <code>bar()</code> function is executed, but before returning to the <code>Call(bar)</code> bytecode of the <code>foo()</code> function. Suppose this function has two return values <code>ret1</code> and <code>ret2</code>, which are currently on the top of the stack.</p>
</li>
<li>
<p>The third figure is the stack layout after the <code>bar()</code> function returns. That is, the <code>Call(bar)</code> bytecode of <code>foo()</code> is executed. That is, move the two return values to the entry function position of <code>bar()</code>.</p>
</li>
<li>
<p>The fourth figure is the stack layout after the <code>foo()</code> function returns. That is, after the <code>Call(foo)</code> bytecode of the outer caller is executed. That is, move the two return values to the entry function position of <code>foo()</code>.</p>
</li>
</ul>
<p>The next three graphs are executed consecutively. Observe the optimization space in it:</p>
<ul>
<li>
<p>An obvious optimization idea is that the copying of the last two return values can be completed in one step. But this is difficult to optimize, and it doesn't optimize much performance;</p>
</li>
<li>
<p>Another not-so-obvious point is that the stack space of the <code>foo()</code> function is no longer used after the <code>bar()</code> function in the first leftmost figure is ready to be called. Therefore, we can clean up the stack space occupied by the <code>foo()</code> function before calling the <code>bar()</code> function. According to this idea, the following redraws the calling process:</p>
</li>
</ul>
<pre><code>|       |        |       |        |       |        |       |
+-------+        +-------+        +-------+        +-------+
| foo() |      / | bar() |        | bar() |      / |  ret1 |
+-------&lt;&lt;   /-+ +-------&lt;&lt;       +-------&lt;&lt;   /-+ +-------+
|   a   |    | \ |  a+b  |        |  a+b  |    | \ |  ret2 |
+-------+    |   +-------+        +-------+    |   +-------+
|   b   |    |   |       |        :       :    |   |       |
+-------+    |                    +-------+    |
| bar() | \  |                    |  ret1 | \  |
+-------+  &gt;-/                    +-------+  &gt;-/
|  a+b  | /                       |  ret2 | /
+-------+                         +-------+
|       |                         |       |
</code></pre>
<ul>
<li>
<p>The first picture on the left remains unchanged, and it is still the state before the <code>bar()</code> function call;</p>
</li>
<li>
<p>In the second picture, before calling <code>bar()</code>, the stack space of the <code>foo()</code> function is cleared;</p>
</li>
<li>
<p>The third picture, corresponding to the second picture above, is after calling <code>bar()</code> function.</p>
</li>
<li>
<p>The fourth picture corresponds to the last picture above. Since the stack space of the <code>foo()</code> function has been cleaned up just now, the third figure above is skipped.</p>
</li>
</ul>
<p>Compared with the above ordinary process, although the operation steps of this new process have been changed, they have not been reduced, so the performance is not optimized. However, there are optimizations in the use of stack space! The stack space of <code>foo()</code> has been freed before the <code>bar()</code> function is executed. 2 layers of function calls, but only takes up 1 layer of space. The advantage brought by this is not obvious in this example, but it is obvious in recursive calls, because there are usually many layers of recursive calls. If the last item of the recursive call satisfies the above tail call, then after applying the new process, it can support unlimited recursive calls without causing stack overflow! The stack overflow here refers to the stack of the Lua virtual machine drawn in the above figure, not the stack overflow of the Rust program.</p>
<p>Compared with the normal process above, this new process has a small difference. The <code>&lt;&lt;</code> on the stack in each figure above represents the current <code>self.base</code> position. It can be seen that in the above ordinary process, <code>self.base</code> has changed; but in the new process, the whole process has not changed.</p>
<p>After introducing the concept of tail call, the specific implementation is introduced below.</p>
<h2 id="syntax-analysis-10"><a class="header" href="#syntax-analysis-10">Syntax Analysis</a></h2>
<p>Before starting the syntax analysis, clarify the rules of the next tail call again: when the last action of a function is to call another function without doing other work, it forms a tail call. Here are some counterexamples from the book &quot;Lua Programming&quot;:</p>
<pre><code class="language-lua">function f1(x)
     g(x) -- discard the return value of g(x) before f1() returns
end
function f2(x)
     return g(x) + 1 -- also execute +1
end
function f3(x)
     return x or g(x) -- also limit the return value of g(x) to 1
end
function f4(x)
     return (g(x)) -- also limit the return value of g(x) to 1
end
</code></pre>
<p>In the Lua language, only calls of the form <code>return func(args)</code> are tail calls. Of course, <code>func</code> and <code>args</code> here can be very complicated, such as <code>return t.k(a+b.f())</code> is also a tail call.</p>
<p>After the rules are clarified, it is relatively simple to judge tail calls during syntax analysis. When parsing the return statement, add a judgment on the tail call:</p>
<pre><code class="language-rust  ignore">     let iret = self.sp;
     let (nexp, last_exp) = self.explist();

     if let (0, &amp;ExpDesc::Local(i)) = (nexp, &amp;last_exp) {
         // There is only 1 return value and it is a local variable
         ByteCode::Return(i as u8, 1)

     } else if let (0, &amp;ExpDesc::Call(func, narg_plus)) = (nexp, &amp;last_exp) {
         // New tail call: only one return value, and it is a function call
         ByteCode::TailCall(func as u8, narg_plus as u8)

     } else if self. discharge_expand(last_exp) {
         // The last return value is a variable type, such as variable arguements or function calls,
         // then the number of return values cannot be known during the syntax analysis phase
         ByteCode::Return(iret as u8, 0)

     } else {
         // The last return value is fixed
         ByteCode::Return(iret as u8, nexp as u8 + 1)
     }</code></pre>
<p>There are 4 cases in the above code. The second case is a newly added tail call, and the other three cases are already supported in the previous sections of this chapter, so they will not be introduced here.</p>
<p>The newly added bytecode <code>TailCall</code> is similar to the function call bytecode <code>Call</code>, but since the return value of the tail call must be a function call, the number of return values must be unknown, so the third associated parameter is omitted. So far, there are three bytecodes related to function calls:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Call(u8, u8, u8),
     CallSet(u8, u8, u8),
     TailCall(u8, u8), // add tail call</code></pre>
<h2 id="virtual-machine-execution-9"><a class="header" href="#virtual-machine-execution-9">Virtual Machine Execution</a></h2>
<p>Next, look at the virtual machine execution part of the tail call. From the tail call process introduced at the beginning of this section, it can be concluded that compared with ordinary function calls, there are three differences in the execution of tail calls:</p>
<ul>
<li>Before calling the inner function, the stack space of the outer function should be cleared in advance, which is also the meaning of tail call;</li>
<li>After the inner function returns, since the outer function has been cleaned up, there is no need to return to the outer function, but directly return to the outer calling function.</li>
<li>There is no need to adjust <code>self.base</code> throughout.</li>
</ul>
<p>Thus, the execution flow of <code>TailCall</code> bytecode can be realized as follows:</p>
<pre><code class="language-rust  ignore">     ByteCode::TailCall(func, narg_plus) =&gt; {
         self.stack.drain(self.base-1 .. self.base+func as usize);
         return self. do_call_function(narg_plus);
     }</code></pre>
<p>Very simple, just two lines of code:</p>
<p>Line 1, through <code>self.stack.drain()</code> to clean up the stack space of the outer function.</p>
<p>Line 2 returns directly from the current <code>execute()</code> through the <code>return</code> statement, that is to say, after the inner function is executed, it does not need to return to the current function, but directly returns to the outer caller. In addition, according to the rules of tail calls listed above, this line of Rust code itself is also a tail call. So as long as the Rust language also supports tail call elimination, then our Lua interpreter will not increase its own stack during execution.</p>
<p>In addition, the newly added <code>do_call_function()</code> method in line 2 executes the function call, which is extracted from the <code>call_function()</code> method called by the <code>Call</code> and <code>CallSet</code> bytecodes in the previous section, except that the update to <code>self.base</code> is removed. And the <code>call_function()</code> method is modified to wrap this new method:</p>
<pre><code class="language-rust  ignore">     fn call_function(&amp;mut self, func: u8, narg_plus: u8) -&gt; usize {
         self.base += func as usize + 1; // get into new world
         let nret = self. do_call_function(narg_plus);
         self.base -= func as usize + 1; // come back
         nret
     }</code></pre>
<h2 id="test-9"><a class="header" href="#test-9">Test</a></h2>
<p>So far, we have completed the tail call. Verify with the following Lua code:</p>
<pre><code class="language-lua">function f(n)
     if n &gt; 10000 then return n end
     return f(n+1)
end
print(f(0))
</code></pre>
<p>But I get a stack overflow error when executing:</p>
<pre><code>$ cargo r --test_lua/tailcall.lua

thread 'main' has overflowed its stack
fatal runtime error: stack overflow
[1] 85084 abort cargo r -- test_lua/tailcall.lua
</code></pre>
<p>At first I thought that the debug version of Rust did not perform tail call optimization, but after adding <code>--release</code>, it can only support a greater recursion depth, which delays the stack overflow, but eventually the stack overflow will still occur. This goes back to what I just said: &quot;So as long as the Rust language also supports tail call elimination, then...&quot;, the assumption in front of this sentence may not be true, that is, the Rust language may not support tail call elimination. Here is an <a href="https://dev.to/seanchen1991/the-story-of-tail-call-optimizations-in-rust-35hf">article</a> that introduces the discussion of tail calls in the Rust language. The conclusion is probably due to the implementation too complicated (may involve resource drop), and the benefits are limited (programmers can manually change recursion to loop if necessary), so in the end Rust language does not support tail call elimination. In this way, in order to make the tail call elimination of Lua completed in this section meaningful, we can only change the recursive call to the <code>execute()</code> function into a loop. This change itself is not difficult, but there are still two places to modify the function call process in the future, one is the calling method of the entry function of the entire program, and the other is to support the state preservation of the function in the coroutine. So we will make this change after completing the final function call process.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="closure"><a class="header" href="#closure">Closure</a></h1>
<p>The previous chapter introduced functions, and all functions in the Lua language are actually closures. This chapter introduces closures.</p>
<p>The so-called closure is the function prototype associated with some variables. In Lua, these associated variables are called Upvalue. If you understand closures in Rust, then according to <a href="https://doc.rust-lang.org/stable/book/ch13-01-closures.html">&quot;Rust Programming Language&quot;</a> it is &quot;capturing environment&quot; means the same thing as &quot;associated variable&quot;. So Upvalue is fundamental to understanding and implementing closures.</p>
<p>The section 1 of this chapter introduces the most basic concept of Upvalue; the following sections 2 and 3 introduce the important feature of Upvalue, escape, which is what makes the closure really powerful; Section 4 introduces the Rust closure corresponding to the Rust function. The following sections 5 and 6 are the two application scenarios of closure and Upvalue respectively.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="upvalue"><a class="header" href="#upvalue">Upvalue</a></h1>
<p>Before introducing closures, this section first introduces an important part of closures: upvalue.</p>
<p>This section mainly introduces the concept of upvalue, and introduces the changes needed to support upvalue in the syntax analysis and virtual machine execution stages. It is very complicated to realize the complete features of upvalue, so in order to focus on the change of the overall structure and process, this section only supports the most basic upvalue features, and leave it to the next section to introduce the difficult part: escape.</p>
<p>The sample code below shows the most basic scenario of upvalue:</p>
<pre><code class="language-lua">local a = 1
local function foo()
     print(a) -- What type of variable is `a`? Local variable, or global variable?
end
</code></pre>
<p>The entire code can be seen as a top-level function, which defines two local variables: <code>a</code> and the function <code>foo</code>. The reference <code>a</code> in <code>print(a)</code> inside the <code>foo()</code> function refers to a local variable defined outside the function, so what kind of variable is the <code>a</code> inside the function? First, it is not defined inside the <code>foo()</code> function, so it is not a local variable; second, it is a local variable defined in the outer function, so it is not a global variable. Local variables that refer to outer functions like this are called <em>upvalue</em> in Lua. There is also the concept of closure in the Rust language, and local variables in the outer function can also be referenced, which is called &quot;capture environment&quot;, which should be the same concept with upvalue.</p>
<p>upvalues are very common in Lua. In addition to the above-mentioned obvious cases, there is also the fact that calling local functions at the same level is also an upvalue, such as the following code:</p>
<pre><code class="language-lua">local function foo()
     print &quot;hello, world&quot;
end
local function bar()
     foo() -- upvalue
end
</code></pre>
<p>The <code>foo()</code> function called in the <code>bar()</code> function is upvalue. In addition, recursive calls to local functions are also upvalue.</p>
<p>After introducing the concept of upvalue, the syntax analysis process of upvalue is as follows.</p>
<h2 id="variable-resolution-process"><a class="header" href="#variable-resolution-process">Variable Resolution Process</a></h2>
<p>The previous interpreter only supports two variable types: local variables and global variables. The variable parsing process is as follows:</p>
<ol>
<li>Match in the local variable list of the current function, if found, it is a local variable;</li>
<li>Otherwise, it is a global variable.</li>
</ol>
<p>Now to add support for the upvalue type, the parsing process of the variable needs to be added one step, which is changed to:</p>
<ol>
<li>Match in the local variable list of the current function, if found, it is a local variable;</li>
<li>Match in the local variables list of upper layer functions, if found, it will be upvalue; (NEW STEP)</li>
<li>Otherwise it is a global variable.</li>
</ol>
<p>The newly added step 2 looks simple, but the specific implementation is very complicated, and the description here is not accurate, which will be described in detail in the next section. This section focuses on the overall process, that is, how to deal with it after parsing the upvalue.</p>
<p>Similar to local variables and global variables, a new type of ExpDesc is also added for upvalue:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     Local(usize), // local variables or temporary variables on the stack
     upvalue(usize), // upvalue
     Global(usize), // global variable</code></pre>
<p>To review, the associated parameter of the local variable <code>ExpDesc::Local</code> represents the index on the stack, and the associated parameter of the global variable <code>ExpDesc::Global</code> represents the index of the variable name in the constant table. What parameters do upvalue need to be associated with? Take the following sample code that contains multiple upvalues as an example:</p>
<pre><code class="language-lua">local a, b, c = 100, 200, 300
local function foo()
     print (c, b)
end
</code></pre>
<p>In the above code, there are two upvalues in the <code>foo()</code> function, <code>c</code> and <code>b</code>, which correspond to the index 2 and 1 of the local variable in the upper function respectively (the index starts counting from 0), so naturally, they can be represented by <code>ExpDesc::upvalue(2)</code> and <code>ExpDesc::upvalue(1)</code>. In this way, when the virtual machine is executing, it can also conveniently index to the local variables on the stack of the upper layer function. Simple and natural. But when the escape of upvalue is introduced in the next section, this solution cannot meet the requirements. But for the sake of simplicity, this section will be used for the time being.</p>
<h2 id="parsing-context"><a class="header" href="#parsing-context">Parsing Context</a></h2>
<p>The new step 2 in the above variable resolution process requires access to local variables of the outer functions. In the last chapter <a href="./ch08-01.define_and_call.html#transform-parseproto">Analysis Function</a>, recursion is used to support multi-layer function definition. This is not only simple to implement, but also provides a certain degree of encapsulation, that is, only the information of the current function can be accessed. This is originally an advantage, but now in order to support upvalue, we need to access the local variables of the outer function, so this encapsulation becomes a disadvantage that needs to be overcome. Programs are becoming more and more complex and confusing in such ever-increasing demands.</p>
<p>When recursively parsing multi-layer functions before, there is one member throughout, that is, <code>lex: Lex&lt;R&gt;</code> in <code>ParseProto</code>, which needs to be accessed when parsing all functions. Now in order to be able to access the local variables of the outer function, a similar member is needed throughout to store the local variables of each function. To do this, we create a new data structure containing the original <code>lex</code> and the new list of local variables:</p>
<pre><code class="language-rust  ignore">struct ParseContext&lt;R: Read&gt; {
     all_locals: Vec&lt;Vec&lt;String&gt;&gt;, // Local variables of each layer function
     lex: Lex&lt;R&gt;,
}</code></pre>
<p>The <code>all_locals</code> member represents the local variable list of each layer function. Each time a function of a new layer is parsed, a new member is pushed into it; after parsing is complete, it is popped. So the last member in the list is the list of local variables for the current function.</p>
<p>Then in <code>ParseProto</code>, replace the original <code>lex</code> with <code>ctx</code>, and delete the original locals:</p>
<pre><code class="language-rust  ignore">struct ParseProto&lt;'a, R: Read&gt; {
     // delete: locals: Vec&lt;String&gt;,
     ctx: &amp;'a mut ParseContext&lt;R&gt;, // add ctx to replace the original lex
     ...</code></pre>
<p>And all places where the locals field is used in the syntax analysis code must also be modified to the last member of ctx.all_locals, which is the local variable list of the current function. The specific code is omitted here.</p>
<p>So far, there are three data structures related to syntax analysis:</p>
<ul>
<li><code>FuncProto</code>, which defines the function prototype, is the output of the syntax analysis stage and the input of the virtual machine execution stage, so all fields are <code>pub</code>;</li>
<li><code>ParseProto</code>, used internally in the parsing phase, and only in the current function;</li>
<li><code>ParseContext</code>, the global state used internally by the parsing phase and accessible at all function levels.</li>
</ul>
<p>After the transformation of <code>ParseProto</code>, with the ability to access the outer function, the upvalue can be parsed. But here is just saying that it has the ability to analyze, and the specific analysis process will be introduced in the next section.</p>
<h2 id="bytecode-5"><a class="header" href="#bytecode-5">Bytecode</a></h2>
<p>After parsing the upvalue, for its processing, you can refer to the previous <a href="./ch04-05.table_rw_and_bnf.html#execute-the-assignment">discussion of global variables</a>, the conclusion is as follows:</p>
<ul>
<li>read, first loaded on the stack, converted to a temporary variable;</li>
<li>Assignment, only supports assignment from local/temporary variables and constants. For other types of expressions, it is first loaded into a temporary variable on the stack and then assigned.</li>
</ul>
<p>To this end, compared with global variables, add 3 upvalue-related bytecodes:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     // global variable
     GetGlobal(u8, u8),
     SetGlobal(u8, u8),
     SetGlobalConst(u8, u8),

     //upvalue
     Getupvalue(u8, u8), // Load upvalue onto the stack
     Setupvalue(u8, u8), // Assign value from the stack
     SetupvalueConst(u8, u8), // assign value from constant</code></pre>
<p>The generation of these three new bytecodes can also be completed by referring to global variables. The specific code is omitted here.</p>
<h2 id="virtual-machine-execution-10"><a class="header" href="#virtual-machine-execution-10">Virtual Machine Execution</a></h2>
<p>The analysis process of upvalue is introduced above, and the corresponding bytecode has completed the syntax analysis stage. The rest is the virtual machine execution phase.</p>
<p>According to the above processing scheme for upvalue, that is, the associated parameter of <code>ExpDesc::upvalue</code> represents the local variable index of the upper-level function. When the virtual machine is executed, it will also encounter the same problem as the syntax analysis: the current function needs to access the upper-level functions' local variables. Therefore, in order to complete the virtual machine execution phase, big changes must be made to the current code structure.</p>
<p>However, the above-mentioned upvalue processing scheme is only a temporary scheme in this section. In the next section, in order to support the escape of upvalue, there will be a completely different scheme and a completely different virtual machine execution process. Therefore, in order to avoid useless work, the execution of the virtual machine under this scheme will not be implemented for the time being. Interested friends can try to change it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="upvalue-escape-and-closure"><a class="header" href="#upvalue-escape-and-closure">Upvalue Escape and Closure</a></h1>
<p>The previous section introduced the concept of upvalue, and took the most basic usage of upvalue as an example to introduce the modification of syntax analysis to support upvalue. This section introduces the complete features of upvalue, mainly the escape of upvalue.</p>
<p>The following refers to the sample code in the book &quot;Lua Programming&quot;:</p>
<pre><code class="language-lua">local function newCounter()
     local i = 0
     return function ()
         i = i + 1 -- upvalue
         print(i)
     end
end

local c1 = newCounter()
c1() -- output: 1
c1() -- output: 2
</code></pre>
<p><code>newCounter()</code> in the above code is a typical factory function, which creates and returns an anonymous function. What needs to be explained here is that the returned anonymous function refers to the local variable <code>i</code> in <code>newCounter()</code>, which is upvalue.
The second half of the code calls the <code>newCounter()</code> function and assigns the returned anonymous function to <code>c1</code> and calls it. At this time, the <code>newCounter()</code> function has ended, and it seems that the local variable <code>i</code> defined in it has also exceeded the scope. At this time, calling <code>c1</code> to refer to the local variable <code>i</code> will cause problems (if you are C Language programmers should understand this). However, in Lua, the closure mechanism ensures that calling <code>c1</code> here is no problem. That is, the escape of upvalue.</p>
<p>The book &quot;Lua Programming&quot; is for Lua programmers, and it is enough to introduce the concept of upvalue escape. But our purpose is to <em>implement</em> an interpreter (not just <em>use</em> an interpreter), so we must not only know that this is no problem, but also know how to do it, that is, how to realize the escape of upvalue.</p>
<h2 id="unfeasible-static-storage-solution"><a class="header" href="#unfeasible-static-storage-solution">Unfeasible Static Storage Solution</a></h2>
<p>The easiest way is to refer to the static variable inside the function in C language. For the local variable referenced by upvalue (such as <code>i</code> in the <code>newCounter()</code> function here), it is not placed on the stack, but placed in a static area. But this solution is not feasible, because the static variable in C language is globally unique, and the upvalue in Lua will generate a new copy every time it is called. For example, following the above code, continue with the following code:</p>
<pre><code class="language-lua">local c2 = newCounter()
c2() -- output: `1`. A new count starts.
c1() -- output: `3`. Continue with the output of c1 above.
</code></pre>
<p>Calling <code>newCounter()</code> again will generate a new counter, in which the local variable <code>i</code> will be re-initialized to 0 and start counting again. At this point, there are two counters: <code>c1</code> and <code>c2</code>, each of which has an independent local variable <code>i</code>. So when <code>c2()</code> is called, it will start counting again from 1; if interspersed with <code>c1()</code> before calling, it will continue the previous counting. How interesting!</p>
<pre><code>   --+---+--              +---+   +---+
     | i |                | i |   | i |
   --+-^-+--              +-^-+   +-^-+
       |                    |       |
   /---+---\                |       |
   |       |                |       |
+----+   +----+          +----+   +----+
| c1 |   | c2 |          | c1 |   | c2 |
+----+   +----+          +----+   +----+
</code></pre>
<p>The left figure above shows that <code>i</code> is placed in the globally unique static storage, then all counter functions point to the unique i. This does not meet our needs. What we need is a separate <code>i</code> for each counter function as shown on the right.</p>
<h2 id="storage-scheme-on-the-heap"><a class="header" href="#storage-scheme-on-the-heap">Storage Scheme on the Heap</a></h2>
<p>Since it cannot be placed on the stack, nor can it be placed in the global static area, it can only be placed on the heap. The next question is, when to put it on the heap? There are several possible scenarios:</p>
<ol>
<li>When entering the function, put all local variables referenced by upvalue on the heap;</li>
<li>When a local variable is referenced by upvalue, it is moved from the stack to the heap;</li>
<li>When the function exits, move all local variables referenced by upvalue to the heap;</li>
</ol>
<p>The first solution does not work, because a local variable may have been used as a local variable before it is referenced by upvalue, and related bytecodes have been generated. The second solution should be feasible, but after the local variable is referenced by upvalue, it may be used as a local variable in the current function. It is not necessary to move it to the heap in advance. After all, access to the stack is faster and more convenient. So we choose option 3.</p>
<p>This operation of moving local variables from the stack to the heap, we follow the code implemented by Lua official, is also called &quot;close&quot;.</p>
<p>Next, in order to demonstrate that an upvalue is accessed before and after escaping, we modify the sample code based on the counter sample above. The inner function is called once inside the <code>newCounter()</code> function before returned. To do this, we assign this anonymous function to a local variable <code>retf</code>:</p>
<pre><code class="language-lua">local function newCounter()
     local i = 0
     local function retf()
         i = i + 1 -- upvalue
         print(i)
     end
     retf() -- called inside newCounter()
     return retf -- return retf
end
</code></pre>
<p>This example is introduced in two parts. First, <code>retf()</code> is called inside the factory function, and then the upvalue escape caused by the factory function returning <code>retf</code>.</p>
<p>First of all, when <code>retf()</code> is called inside the factory function, <code>i</code> to be operated by <code>retf</code> is still on the stack. The schematic diagram is as follows.</p>
<pre><code>     |          |
     +----------+
base |newCounter|
     +----------+
   0 |    i     |&lt;- - - - - - - - - - \
     +----------+                     |
   1 |   retf   +--+-&gt;+-FuncProto-----+--+
     +----------+  |  |byte_codes:    |  |
   2 |   retf   +--/  | GetUpvalue(0, 0) |
     +----------+     | ...              |
     |          |     +------------------+
</code></pre>
<p>In the figure, the stack is on the left, where <code>newCounter</code> is the entry of the function call and the base position of the current function. The <code>i</code> and the first <code>retf</code> are local variables, and the second <code>retf</code> is the entry on the stack of the function call. The two <code>retf</code>s point to same function prototype. In the bytecode sequence in the <code>retf</code> function prototype, the first bytecode <code>Getupvalue</code> is to load upvalue <code>i</code> onto the stack to perform addition. This bytecode has two associated parameters. The first is the target address loaded onto the stack, which is ignored here; the second is the source address of upvalue, refer to the syntax analysis of upvalue in the previous section, the meaning of this parameter is: the stack of local variables of the upper function index. In this example, it is the index of <code>i</code> in the newCounter() function, which is <code>0</code>. So far, it is still the content of the previous section, and escape has not been involved.</p>
<p>Now consider the escape of upvalue. After the <code>newCounter()</code> function exits, the three spaces on the left stack will be destroyed, and <code>i</code> will no longer exist. In order for the retf function to continue to access <code>i</code>, before the <code>newCounter()</code> function exits, it is necessary to close the local variable <code>i</code> and move <code>i</code> from the stack to the heap. The schematic diagram is as follows:</p>
<pre><code>     |          |
     +----------+
base |newCounter|         +===+
     +----------+  close  | i |&lt;- - - \
   0 |    i     +--------&gt;+===+       ?
     +----------+                     ?
   1 |   retf   +----&gt;+-FuncProto-----?--+
     +----------+     |byte_codes:    ?  |
     |          |     | GetUpvalue(0, 0) |
                      | ...              |
                      +------------------+
</code></pre>
<p>Although this ensures that <code>i</code> can continue to be accessed, there is a very obvious problem: the second parameter associated with the bytecode <code>Getupvalue</code> cannot locate <code>i</code> on the heap (the continuous <code>?</code> in the figure Wire). This is also mentioned in the <a href="./ch09-01.upvalue.html#variable-resolution-process">previous section</a>, it is not feasible to directly use the index of the local variable on the stack to represent the upvalue scheme. Improvements need to be made on the basis of this scheme.</p>
<h2 id="improvement-upvalue-intermediary"><a class="header" href="#improvement-upvalue-intermediary">Improvement: Upvalue Intermediary</a></h2>
<p>In order to still be able to be accessed by upvalue after closing the local variable, we need an upvalue intermediary. At the beginning, the index on the stack is used to represent the upvalue, and when the local variable of the outer function is closed, it is moved to this intermediary.</p>
<p>The following two figures show the situation after adding the upvalue intermediary.</p>
<pre><code>     |          |             - - - - - - \
     +----------+            |            |
base |newCounter|            |      *-----+-+---
     +----------+            |      |Open(0)|
   0 |    i     |&lt;- - - - - -       *-^-----+---
     +----------+                     |
   1 |   retf   +--+-&gt;+-FuncProto-----+--+
     +----------+  |  |byte_codes:    |  |
   2 |   retf   +--/  | GetUpvalue(0, 0) |
     +----------+     | ...              |
     |          |     +------------------+
</code></pre>
<p>The figure above is a schematic diagram of calling the <code>retf()</code> function inside the <code>newCounter()</code> function. Compared with the previous version, the upvalue intermediary list (the list with <code>*</code> as the corner in the figure) is added, and there is only one member: <code>Open(0)</code>, which means that this local variable has not been closed and is on the stack The relative index is 0. In the function prototype of <code>retf</code>, although the second parameter associated with the bytecode <code>Getupvalue</code> has not changed, its meaning has changed, and it has become the index of the intermediary list. It just happens to be 0 in this example.</p>
<pre><code>     |          |          /----------------\
     +----------+          |                |
base |newCounter|          |        *-------V-+---
     +----------+  close   |        |Closed(i)|
   0 |    i     +----------/        *-^-------+---
     +----------+                     |
   1 |   retf   +----&gt;+-FuncProto-----+--+
     +----------+     |byte_codes:    |  |
     |          |     | GetUpvalue(0, 0) |
                      | ...              |
                      +------------------+
</code></pre>
<p>The figure above is a schematic diagram after the local variable <code>i</code> is closed before the <code>newCounter()</code> function returns. The members of the upvalue intermediary list added in the figure above become <code>Closed(i)</code>, that is, the local variable <code>i</code> is moved to this intermediary list. In this way, <code>Getupvalue</code> can still locate the 0th upvalue intermediary and access the closed <code>i</code>.</p>
<h2 id="improvement-shared-upvalue"><a class="header" href="#improvement-shared-upvalue">Improvement: Shared Upvalue</a></h2>
<p>The above scheme can support the current simple escape scenario, but it does not support the scenario where multiple closures share the same local variable. For example, the following sample code:</p>
<pre><code class="language-lua">local function foo()
     local i, ip, ic = 0, 0, 0
     local function producer()
         i = i + 1
         ip = ip + 1
     end
     local function consumer()
         i = i - 1
         ic = ic + 1
     end
     return produce, consume
end
</code></pre>
<p>The two internal functions returned by the above <code>foo()</code> function both refer to the local variable <code>i</code>, and it is obvious that the two functions share <code>i</code> and operate on the same <code>i</code> instead of being independent <code>i</code>. Then when the <code>foo()</code> function finishes closing <code>i</code>, two functions are needed to share the closed <code>i</code>. Since these two functions have different upvalue lists, namely <code>i, ip</code> and <code>i, ic</code>, the two functions do not need to share the same upvalue list. Then it can only be shared separately for each upvalue.</p>
<p>The following figure shows the scheme of sharing each upvalue separately:</p>
<pre><code>     |          |
     +----------+     +=======+
base |    foo   |     |Open(0)|&lt;===============+------------\
     +----------+     +=======+                |            |
   0 |    i     |&lt;- -/  +=======+              |            |
     +----------+       |Open(1)|&lt;-------------|---\        |
   1 |    ip    |&lt;- - - +=======+              |   |        |
     +----------+         +=======+            |   |        |
   2 |    ic    |&lt;- - - - |Open(2)|&lt;-----------|---|--------|---\
     +----------+         +=======+          *-+-+-+-+--    |   |
   3 | producer +----&gt;+-FuncProto--------+   | i |ip |      |   |
     +----------+     |byte_codes:       |   *-^-+-^-+--    |   |
   4 | consumer +--\  | GetUpvalue(0, 0)-+----/    |        |   |
     +----------+  |  | ...              |         |        |   |
     |          |  |  | GetUpvalue(0, 1)-+---------/        |   |
                   |  | ...              |                  |   |
                   |  +------------------+                  |   |
                   |                                      *-+-+-+-+--
                   \--------------&gt;+-FuncProto-------+    | i |ic |
                                  |byte_codes:       |    *-^-+-^-+--
                                  | GetUpvalue(0, 0)-+-----/    |
                                  | ...              |          |
                                  | GetUpvalue(0, 1)-+----------/
                                  | ...              |
                                  +------------------+
</code></pre>
<p>The picture above is slightly more complicated, but most of it is the same as the previous scheme. The leftmost is still the stack. Then see that the content pointed to by the <code>producer()</code> function is still the function prototype and the corresponding upvalue list. Since this function uses two upvalues, two bytecodes are listed. Then there is a difference: in the upvalue list, it is not directly the upvalue, but the address of the upvalue. The real upvalue is allocated on the heap alone, which is <code>Open(0)</code>, <code>Open(1)</code> and <code>Open(2)</code> in the figure. These 3 upvalues can access local variables on the stack through indexes. The last <code>consumer()</code> function is similar, the difference is that different upvalues are referenced.</p>
<p>When the <code>foo()</code> function ends and all local variables referenced by upvalue are closed, <code>Open(0)</code>, <code>Open(1)</code> and <code>Open(2)</code> in the above figure are replaced by <code>Closed(i)</code>, <code>Closed(ip)</code> and <code>Closed(ic)</code>. At this time, the <code>i</code> in the upvalue lists corresponding to <code>producer()</code> and <code>consumer()</code> functions point to the same <code>Closed(i)</code>. In this way, after the outer <code>foo()</code> function exits, these two functions can still access the same <code>i</code>. Only 3 upvalues are replaced, the changes are relatively small, and the closed picture is omitted here.</p>
<h2 id="definition-of-closure"><a class="header" href="#definition-of-closure">Definition of Closure</a></h2>
<p>Before continuing to introduce more upvalue usage scenarios, we first introduce the concept of closure based on the above scheme.</p>
<p>According to the above scheme, the returned <code>retf</code> is not only a function prototype, but also includes the corresponding upvalue list. And the function prototype plus upvalue is <em>closure</em>! Add Lua closure type in <code>Value</code>:</p>
<pre><code class="language-rust  ignore">pub enum upvalue { // upvalue intermediary in the above figure
     Open(usize),
     Closed(Value),
}
pub struct LuaClosure {
     proto: Rc&lt;FuncProto&gt;,
     upvalues: Vec&lt;Rc&lt;RefCell&lt;upvalue&gt;&gt;&gt;,
}
pub enum Value {
     LuaFunction(Rc&lt;FuncProto&gt;), // Lua function
     LuaClosure(Rc&lt;LuaClosure&gt;), // Lua closure</code></pre>
<p>In this way, although the different closures returned by multiple calls to the <code>newCounter()</code> function share the same function prototype, each has an independent upvalue. This is also the reason why the two counters c1 and c2 at the beginning of this section can count independently.</p>
<p>The following figure shows a schematic diagram of two counters:</p>
<pre><code>             +-LuaClosure--+
|      |     |       proto-+----------------------+--&gt;+-FuncProto--------+
+------+     |    upvalues-+---&gt;+---+--           |   |byte_codes:       |
|  c1  +----&gt;+-------------+    | i |             |   | GetUpvalue(0, 0) |
+------+                        +-+-+--           |   | ...              |
|  c2  +-\                        |               |   +------------------+
+------+ |                        V=========+     |
|      | |                        |Closed(i)|     |
         |                        +=========+     |
         \--&gt;+-LuaClosure--+                      |
             |       proto-+----------------------/
             |    upvalues-+---&gt;+---+--
             +-------------+    | i |
                                +-+-+--
                                  |
                                  V=========+
                                  |Closed(i)|
                                  +=========+
</code></pre>
<p>Similarly, we also modify the schematic diagram in the shared upvalue example above. For clarity, delete the specific content of <code>FuncProto</code>; then merge the function prototype and upvalue list into <code>LuaClosure</code>. As shown below.</p>
<pre><code>     |          |
     +----------+     +=======+
base |    foo   |     |Open(0)|&lt;========+----------\
     +----------+     +=======+         |          |
   0 |    i     |&lt;- -/  +=======+       |          |
     +----------+       |Open(1)|&lt;------|---\      |
   1 |    ip    |&lt;- - - +=======+       |   |      |
     +----------+         +=======+     |   |      |
   2 |    ic    |&lt;- - - - |Open(2)|&lt;----|---|------|---\
     +----------+         +=======+     |   |      |   |
   3 | producer +----&gt;+-LuaClosure--+   |   |      |   |
     +----------+     | proto       |   |   |      |   |
   4 | consumer +--\  | upvalues   -+&gt;*-+-+-+-+--  |   |
     +----------+  |  +-------------+ | i |ip |    |   |
     |          |  |                  *---+---+--  |   |
                   |                               |   |
                   \------------&gt;+-LuaClosure--+   |   |
                                 | proto       |   |   |
                                 | upvalues   -+&gt;*-+-+-+-+--
                                 +-------------+ | i |ic |
                                                 *---+---+--
</code></pre>
<p>It can be seen from the figure that compared with the Lua function <code>LuaFunction</code> defined in the previous chapter, although the closure <code>LuaClosure</code> can have an independent upvalue list, it has one more memory allocation and pointer jump. Here we are faced with a choice: to completely replace the function with the closure, or to coexist? The official implementation of Lua is the former, which is also the source of the phrase &quot;all functions in Lua are closures&quot;. The advantage of substitution is that there is one less type, and the code is a little simpler; the advantage of coexistence is that the function type allocates less memory and one pointer jump after all. In addition to these two advantages and disadvantages, there is a larger difference that affects behavior. For example, the following sample code:</p>
<pre><code class="language-lua">local function foo()
     return function () print &quot;hello, world!&quot; end
end
local f1 = foo()
local f2 = foo()
print(f1 == f2) -- true or false?
</code></pre>
<p>Here the anonymous function returned by calling <code>foo()</code> does not include the upvalue. So the question is, are the two return values ​​of the two calls to <code>foo()</code> equal?</p>
<ul>
<li>
<p>If the <code>LuaFunction</code> type is reserved, then the return value is <code>LuaFunction</code> type, and <code>f1</code> and <code>f2</code> only involve the function prototype and are equal. Validation can be performed with the code from the previous chapter.</p>
</li>
<li>
<p>If the <code>LuaFunction</code> type is not reserved, the returned function is of the <code>LuaClosure</code> type. Although it does not contain upvalue, it is also two different closures, <code>f1</code> and <code>f2</code> are not equal.</p>
</li>
</ul>
<p>So which of the above behaviors meets the requirements of <a href="https://www.lua.org/manual/5.4/manual.html#3.4.4">Lua language</a>? The answer is: both can. The description of function comparison in the Lua manual is as follows:</p>
<blockquote>
<p>Functions created at different times but with no detectable differences may be classified as equal or not (depending on internal caching details).</p>
</blockquote>
<p>That is, it doesn't matter, and there is no guarantee on it. Then we can choose whatever we want. In this project, we initially chose closures instead of functions, and later added function types back. I don't feel much difference.</p>
<h2 id="syntax-snalysis-of-closure"><a class="header" href="#syntax-snalysis-of-closure">Syntax Snalysis of Closure</a></h2>
<p>When there was no closure before and it was still LuaFunction, the processing of function definition was very intuitive:</p>
<ul>
<li>Parse the function definition and generate the function prototype FuncProto;</li>
<li>Wrap FuncProto with <code>Value::LuaFunction</code> and put it in the constant table;</li>
<li>Generate bytecodes such as <code>LoadConst</code> to read the constant table.</li>
</ul>
<p>Function definitions are treated in a similar way to other types of constants. Recall that the relevant code is as follows:</p>
<pre><code class="language-rust  ignore">     fn funcbody(&amp;mut self, with_self: bool) -&gt; ExpDesc {
         // omit preparation

         // The proto returned by the chunk() function is the FuncProto type
         let proto = chunk(self. lex, has_varargs, params, Token::End);
         ExpDesc::Function(Value::LuaFunction(Rc::new(proto)))
     }
     fn discharge(&amp;mut self, dst: usize, desc: ExpDesc) {
         let code = match desc {
             // omit other types

             // Add the function reason to the constant table and generate LoadConst bytecode
             ExpDesc::Function(f) =&gt; ByteCode::LoadConst(dst as u8, self. add_const(f) as u16),</code></pre>
<p>Now in order to support closures, the following improvements need to be made:</p>
<ul>
<li>
<p>The relevant Value type definition has been changed to <code>LuaClosure(Rc&lt;LuaClosure&gt;)</code>, so the parsed function prototype FuncProto cannot be directly put into the constant table. Although it can be placed indirectly, it is not intuitive. It is better to add a new table in the function prototype FuncProto to save the prototype list of the inner function.</p>
</li>
<li>
<p>When the virtual machine executes the function definition, an upvalue is generated in addition to the function prototype. Then the bytecode that directly reads the constant table like <code>LoadConst</code> does not meet the demand. A special bytecode needs to be added to aggregate the function prototype and the generated upvalue into a closure.</p>
</li>
<li>
<p>In addition, when generating upvalue, we need to know which local variables of the upper function are used by this function. Therefore, the function prototype also needs to add a list of upvalue references to upper-level local indexes.</p>
</li>
</ul>
<p>In summary, the newly added bytecode for creating a closure is as follows:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     Closure(u8, u16),</code></pre>
<p>The two parameters associated with this bytecode are similar to the <code>LoadConst</code> bytecode, which are the target address on the stack and the index of the internal function prototype list <code>inner_funcs</code>.</p>
<p>In addition, two new members need to be added to the function prototype as follows:</p>
<pre><code class="language-rust  ignore">pub struct FuncProto {
     pub upindexes: Vec&lt;usize&gt;,
     pub inner_funcs: Vec&lt;Rc&lt;FuncProto&gt;&gt;,</code></pre>
<p>where <code>inner_funcs</code> is a list of prototypes of the inner functions defined inside the function. <code>upindexes</code> is the index of the local variable that the current function refers to the upper function, and this member needs to be modified later. It should be noted that <code>inner_funcs</code> is used when the current function acts as an outer function, and <code>upindexes</code> is used when the current function acts as a inner function.</p>
<p>After we introduce the complete features of upvalue later, we will introduce the analysis of the upvalue index <code>upindexes</code>.</p>
<p>Now, after introducing the definition and syntax analysis of closures, let's look at other scenarios of upvalue.</p>
<h2 id="improvement-references-to-upvalue"><a class="header" href="#improvement-references-to-upvalue">Improvement: References to Upvalue</a></h2>
<p>The upvalues introduced before are all references to the <em>local variables</em> of the upper-level functions. Now let’s look at the references to the <em>upvalues</em> of the upper-level functions. Make a modification to the counting closure example at the beginning of this section, and put the incremental code <code>i = i + 1</code> into a layer of functions:</p>
<pre><code class="language-lua">local function newCounter()
     local i = 0
     return function ()
         print(i) -- upvalue
         local function increase()
             i = i + 1 -- where does `i` refer?
         end
         increase()
     end
end

local c1 = newCounter()
c1()
</code></pre>
<p>In this example, the <code>i</code> in the first line of the print statement of the anonymous function returned by the <code>newCounter()</code> function is the ordinary upvalue introduced before, pointing to the local variable of the upper-level function. And what is <code>i</code> in the internal function <code>increase()</code> function? Also upvalue. Who is this upvalue a reference to?</p>
<p>Can it be regarded as a <em>cross-layer</em> reference to the local variable <code>i</code> in the outermost <code>newCounter()</code> function? No, because it cannot be realized when the virtual machine is executed. When the anonymous function returns, the internal <code>increase()</code> function has not been created; only when the anonymous function is called outside, the internal <code>increase()</code> function will be created and executed; at this time the outermost <code>newCounter()</code> has ended, and the local variable <code>i</code> no longer exists, so it cannot be referenced.</p>
<p>Since it cannot be a <em>cross-layer</em> reference to the <em>local variable</em> <code>i</code> in the outermost <code>newCounter()</code> function, it can only be a reference to the <em>upvalue</em> <code>i</code> in the anonymous function of the outer layer.</p>
<p>In order to support references to upvalue, first, modify the definition of the upvalue list in <code>FuncProto</code> just now, from only supporting local variables to also supporting upvalue:</p>
<pre><code class="language-rust  ignore">pub enum UpIndex {
     Local(usize), // index of local variables in upper functions
     Upvalue(usize), // index of upvalues in upper functions
}

pub struct FuncProto {
     pub upindexes: Vec&lt;UpIndex&gt;, // change from usize to UpIndex
     pub inner_funcs: Vec&lt;Rc&lt;FuncProto&gt;&gt;,</code></pre>
<p>Then, look at the schematic diagram of calling the internal <code>increase()</code> function when executing the returned anonymous function counter <code>c1</code> in the above example:</p>
<pre><code>|          |
+----------+
|    c1    +--------------------&gt;+-LuaClosure--+
+----------+                     | proto       |
| increase |                     | upvalues    +---&gt;+---+--
+----------+                     +-------------+    | i |
| increase +--&gt;+-LuaClosure--+                      +-+-+--
+----------+   | proto       |                        |
|          |   | upvalues    +---&gt;+---+--             |
               +-------------+    | i |               |
                                  +-+-+--             V=========+
                                    \----------------&gt;|Closed(i)|
                                                      +=========+
</code></pre>
<p>On the left is the stack. Among them, <code>c1</code> is the function call entry, and the corresponding closureThe upvalue <code>i</code> contained in the package is referenced in the print statement.</p>
<p>The first <code>increase</code> below the stack is a local variable in <code>c1</code>. The second <code>increase</code> is the function call entry, and the upvalue <code>i</code> contained in the corresponding closure is referenced in the statement that performs the increment operation. In the function prototype, this upvalue should correspond to the 0th upvalue of the upper-level function, namely <code>UpIndex::upvalue(0)</code>, so when the virtual machine executes and generates this closure, this upvalue points to the 0th of <code>c1</code> upvalue, which is <code>Closed(i)</code> in the figure. In this way, the increment operation of <code>i</code> in this function will also be reflected in the print statement of <code>c1</code> function.</p>
<h2 id="improvement-references-across-multiple-layer-functions"><a class="header" href="#improvement-references-across-multiple-layer-functions">Improvement: References Across Multiple Layer Functions</a></h2>
<p>Let's look at another scenario: cross-layer references. Slightly modifying the above use case to put the <code>print</code> statement after the increment operation, we get the following sample code:</p>
<pre><code class="language-lua">local function newCounter()
     local i = 0
     return function ()
         local function increase()
             i = i + 1 -- upvalue of upper-upper local
         end
         increase()
         print(i) -- upvalue
     end
end
</code></pre>
<p>The difference between this example and the above example is that when the <code>increase()</code> function is parsed, the upvalue <code>i</code> has not been generated in the anonymous function to be returned, so <code>i</code> in the <code>increase()</code> function points to who? Summarize the previous upvalue types: either it refers to the local variable of the upper-level function, or the upvalue of the upper-level function, and analyzes that it cannot be referenced across multiple layers of functions. Therefore, there is only one solution: create an upvalue in the middle layer function. This upvalue is not used in the current function (by now), it is only used to reference the inner function.</p>
<p>The current function does not use the created upvalue &quot;by now&quot;. But in the subsequent analysis process, it may still be used. For example, after the above example, the following <code>print</code> statement uses this upvalue.</p>
<p>In this example, the prototypes and schematic diagrams of the two functions are the same as the above example. omitted here.</p>
<p>At this point, all the upvalue features are finally introduced, and the final solution is given. During this period, syntax analysis and virtual machine execution are also involved. Next, according to the final plan, we will briefly organize syntax analysis and virtual machine execution.</p>
<h2 id="syntax-analysis-of-upvalue-index"><a class="header" href="#syntax-analysis-of-upvalue-index">Syntax Analysis of Upvalue Index</a></h2>
<p>When introducing <a href="ch09-02.escape_and_closure.html#syntax-snalysis-of-closure">Syntax Analysis of Closures</a>, it is pointed out that in the function prototype <code>FuncProto</code>, a new member <code>upindexes</code> needs to be added to represent the upvalue index of the current function.</p>
<p>In the <a href="./ch09-01.upvalue.html#variable-resolution-process">previous section</a>, the variable parsing process is listed:</p>
<ol>
<li>Match in the local variable list of the current function, if found, it is a local variable;</li>
<li>Match in the local variable list of upper-level functions, if found, it will be upvalue;</li>
<li>Otherwise it is a global variable.</li>
</ol>
<p>According to the introduction of the complete features of upvalue earlier in this section, the above-mentioned step 2 is extended to the more detailed analysis steps of the upvalue index. The final process of variable analysis is as follows:</p>
<ol>
<li>Match in the local variable list of the current function, if found, it is a local variable;</li>
<li>Match in the upvalue list of the current function, if found, the upvalue already exists; (reuse upvalue)</li>
<li>Match in the local variable list of outer functions, if found, add an upvalue; (ordinary upvalue)</li>
<li>Match in the upvalue list of the outer function, if found, add an upvalue; (reference to the upvalue in the upper function)</li>
<li>Match in the local variable list of the outer functions, if found, create an upvalue in all intermediate layer functions, and add an upvalue; (references across multi-layer functions)</li>
<li>Match in the upvalue list of the outer functions, if found, create an upvalue in all intermediate layer functions, and add an upvalue; (a reference to an upvalue across multi-layer functions)</li>
<li>Repeat steps 5 and 6 above, if the outermost function is still not matched, it is a global variable.</li>
</ol>
<p>There is obviously a lot of duplication in this process. The most obvious is that steps 3 and 4 are special cases of steps 5 and 6, that is, there is no intermediate layer function, so steps 3 and 4 can be removed. In addition, when the code is implemented, steps 1 and 2 can also be omitted as special cases. Since there is too much content in this section, the specific code will not be posted here.</p>
<p>In the syntax analysis in the previous section, in order to support upvalue, it is necessary to access the local variable list of the upper-level function, so the new context <code>ParseContext</code> data structure is added, which contains the local variable list of functions at all levels. This section introduces that upvalue can also refer to the upvalue of upper-level functions, so it is also necessary to add the upvalue list of functions at all levels in <code>ParseContext</code>.</p>
<pre><code class="language-rust  ignore">struct ParseContext&lt;R: Read&gt; {
     all_locals: Vec&lt;Vec&lt;String&gt;&gt;,
     all_upvalues: Vec&lt;Vec&lt;(String, UpIndex)&gt;&gt;, // new
     lex: Lex&lt;R&gt;,
}

pub struct FuncProto {
     pub upindexes: Vec&lt;UpIndex&gt;,</code></pre>
<p>In the above code, <code>ParseContext</code> is the parsing context, which is the internal data structure of parsing. The member type of its upvalue list <code>all_upvalues</code> is <code>(String, UpIndex)</code>, where String is the name of the upvalue variable, which is used for the matching in step 4 and step 6; <code>UpIndex</code> is the index of upvalue.</p>
<p><code>FuncProto</code> is the output of the syntax analysis stage, which is used by the virtual machine execution stage. At this time, the upvalue variable name is not needed, and only the UpIndex index is needed.</p>
<h2 id="virtual-machine-execution-11"><a class="header" href="#virtual-machine-execution-11">Virtual Machine Execution</a></h2>
<p>In the front part of this section, when introducing the upvalue design scheme, it was basically introduced according to the execution phase of the virtual machine, so we will go through it again here.</p>
<p>First, the closure is created, that is, the function is defined. To this end, a new bytecode <code>ByteCode::Closure</code> is introduced, whose responsibility is to generate upvalue, package it together with the function prototype as a closure, and load it on the stack.</p>
<p>What needs to be explained here is that in the syntax analysis phase, in order to access the local variables of the upper-level function, the <code>ParseContext</code> context needs to be introduced; however, in the virtual machine execution phase, although upvalue also needs to access the stack space of the upper-level function, it does not need for a similar context. This is because when the closure is created, the upvalue list is generated by the outer function and passed into the closure, and the inner function can indirectly access the stack space of the outer function through the upvalue list.</p>
<p>Besides, in addition to passing the closure into the generated upvalue list, the outer function itself also needs to maintain the list for two purposes:</p>
<ul>
<li>
<p>As mentioned in the <a href="ch09-02.escape_and_closure.html#improvement-shared-upvalue">Shared upvalue</a> section above, if a function contains multiple closures, the upvalue of these closures must share local variables. Therefore, when creating an upvalue, first check whether the upvalue associated with this local variable has been created. If so, share; otherwise, create a new one.</p>
<p>There is a small problem here, the check of whether this has been created is carried out during the virtual machine execution phase. There are generally not many upvalue lists, so it is not necessary to use a hash table. If Vec is used, the time complexity of this matching check is O(n). When there are many upvalues, this may affect performance. Can this matching check be placed in the syntax analysis stage? This issue will be addressed in detail in the next section.</p>
</li>
<li>
<p>When the outer function exits, upvalue needs to be closed.</p>
<p>It should be noted that, theoretically speaking, only escaped upvalues need to be closed; there is no need to close unescaped upvalues. However, it is very difficult to determine whether an upvalue escapes or not at the syntax stage. Because except for the obvious escape case where the internal function is used as the return value in the above example, there are also situations such as assigning the internal function to an external table. It is also very troublesome to judge whether to escape in the virtual machine stage. So for the sake of simplicity, we refer to the official implementation of Lua here, and close all upvalues at the end of the function, regardless of whether they escape.</p>
</li>
</ul>
<p>The timing of closing upvalue is where all functions exit, including <code>Return</code>, <code>Return0</code> and <code>TailCall</code> bytecodes. The specific closing code is omitted here.</p>
<h2 id="summary-6"><a class="header" href="#summary-6">Summary</a></h2>
<p>This section introduces the escape of upvalue and adds closure types. But it mainly introduces how to design and manage upvalue, but does not talk about specific operations, including how to create, read, write, and close upvalue. However, after the design plan is explained clearly, these specific operations are relatively simple. This section is already very long, so the introduction and code of this part will be omitted.</p>
<h2 id="rust-dst"><a class="header" href="#rust-dst">Rust DST</a></h2>
<p>Now introduce a feature of the Rust language, DST.</p>
<p>The definition of the closure data structure <code>LuaClosure</code> earlier in this section is as follows:</p>
<pre><code class="language-rust  ignore">pub struct LuaClosure {
     proto: Rc&lt;FuncProto&gt;,
     upvalues: Vec&lt;Rc&lt;RefCell&lt;upvalue&gt;&gt;&gt;,
}</code></pre>
<p>The function prototype <code>proto</code> field is ignored here, and only the upvalue list <code>upvalues</code> field is concerned. In order to store any upvalue, the upvalues here are defined as a list Vec. This requires an additional allocation of memory. The memory layout of the entire closure is as follows:</p>
<pre><code>+-LuaClosure--+
| proto       |
| upvalues:   |    upvalue list
|   ptr     --+---&gt;+------+------+-
|   capacity  |    |      |      |
|   length    |    +------+------+-
+-------------+

</code></pre>
<p>In the figure above, the closure <code>LuaClosure</code> is on the left, and the extra memory on the right pointed to by <code>ptr</code> is the actual storage space of the upvalue list Vec. There are three disadvantages of allocating an additional memory in this way:</p>
<ul>
<li>Waste of memory, each segment of memory requires additional management space and waste due to alignment;</li>
<li>When applying for memory, one more allocation needs to be performed, which affects performance;</li>
<li>When accessing upvalue, one more pointer jump is required, which also affects performance.</li>
</ul>
<p>For the requirement of this variable-length array, the classic approach in C language is: define a zero-length array in the data structure, and then specify the actual length as needed when actually allocating memory. The sample code is as follows:</p>
<pre><code class="language-c">// define the data structure
struct lua_closure {
     struct func_proto *proto;
     int n_upavlue; // actual number
     struct upvalue upvalues[0]; // zero-length array
}

// request memory
struct lua_closure *c = malloc(sizeof(struct lua_closure) // basic space
         + sizeof(struct upvalue) * n_upvalue); // extra space

// initialization
c-&gt;n_upvalue = n_upvalue;
for (int i = 0; i &lt; n_upvalue; i++) {
     c-&gt;upvalues[i] = ...
}
</code></pre>
<p>The corresponding memory layout is as follows:</p>
<pre><code>+-------------+
| proto       |
| n_upvalue   |
:             : \
:             :  + Upvalue列表
:             : /
+-------------+
</code></pre>
<p>This approach can avoid the above three disadvantages. Can this be done in Rust? For example, the following definition:</p>
<pre><code class="language-rust  ignore">pub struct LuaClosure {
     proto: Rc&lt;FuncProto&gt;,
     upvalues: [Rc&lt;RefCell&lt;upvalue&gt;&gt;], // slice
}</code></pre>
<p>In this definition, the type of upvalues has changed from list <code>Vec</code> to slice <code>[]</code>. The good news is that Rust supports the DST type (that is, the slice here) as the last field of the data structure, which means that the above definition is legal. The bad news is that such data structures cannot be initialized. A data structure that cannot be initialized, is of course useless. To quote <a href="https://doc.rust-lang.org/nomicon/exotic-sizes.html">The Rustonomicon</a>: custom DSTs are a largely half-baked feature for now.</p>
<p>We can think about why it cannot be initialized? For example, <code>Rc</code> has <code>Rc::new_uninit_slice()</code> API to create slices, so can a similar API be added to create this data structure containing slices? In addition, you can also refer to <a href="https://docs.rs/dyn_struct/latest/dyn_struct/struct.DynStruct.html">dyn_struct</a>.</p>
<p>However, even if it can be initialized, and the definition of the above data structure can be used, but there will be another problem: since the upvalues field is DST, then the entire <code>LuaClosure</code> will also become DST, so the pointer will become a fat pointer, including the actual length of the slice, <code>Rc&lt;LuaClosure&gt;</code> becomes 2 words, which in turn causes <code>enum Value</code> to change from 2 words to 3 words. This does not meet our requirements, just like <code>Rc&lt;str&gt;</code> cannot be used to define the string type before.</p>
<p>Since slice cannot be used, is there any other solution? Fixed-length arrays can be used. For example, modify the definition as follows:</p>
<pre><code class="language-rust  ignore">enum Varupvalues {
     One(Rc&lt;RefCell&lt;upvalue&gt;&gt;), // 1 upvalue
     Two([Rc&lt;RefCell&lt;upvalue&gt;&gt;; 2]), // 2 upvalues
     Three([Rc&lt;RefCell&lt;upvalue&gt;&gt;; 3]), // 3 upvalues
     Four([Rc&lt;RefCell&lt;upvalue&gt;&gt;; 4]), // 4 upvalues
     More(Vec&lt;Rc&lt;RefCell&lt;upvalue&gt;&gt;&gt;), // more upvalue
}

pub struct LuaClosure {
     proto: Rc&lt;FuncProto&gt;,
     upvalues: Varupvalues,
}</code></pre>
<p>In this way, for closures with no more than 4 upvalues, additional memory allocation can be avoided. This should satisfy most cases. In the case of more upvalues, the waste of allocating another piece of memory is relatively not that great. Another advantage of this solution is that it does not involve unsafe. Of course, the problem with this solution is that it will bring coding complexity. Since the creation of <code>LuaClosure</code> is only generated once when the closure is created, it is not a high-frequency operation, so there is no need to make it so complicated. Therefore, in the end, we still use the original <code>Vec</code> solution.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="escape-from-block-and-goto"><a class="header" href="#escape-from-block-and-goto">Escape from Block and <code>goto</code></a></h1>
<p>The previous section covered upvalue escapes from functions. But in fact, the scope of local variables is the block, so whenever the block ends, upvalue escape may occur. And a function can also be regarded as a kind of block, so the escape from a function introduced in the previous section can be regarded as a special case of escape from a block.</p>
<p>In addition, there is another escape scenario, that is, the <code>goto</code> statement jumps backwards and skips the definition of local variables, and the local variables will also become invalid at this time.</p>
<p>In the previous section, there was too much content, so in order not to add extra details, these two escape scenes are introduced separately in this section.</p>
<h2 id="escape-from-block"><a class="header" href="#escape-from-block">Escape from block</a></h2>
<p>First look at a sample code that escapes from the block:</p>
<pre><code class="language-lua">do
     local i = 0
     c1 = function()
         i = i + 1 -- upvalue
         print(i)
     end
end -- the end of the block, the local variable `i` becomes invalid
</code></pre>
<p>In this example, the anonymous function defined in <code>do .. end</code> block refers to the local variable <code>i</code> defined in it as upvalue. When the block ends, the local variable <code>i</code> will be invalid, but because it is still referenced by the anonymous function, it needs to escape.</p>
<p>Although a function can be regarded as a special case of a block, a special case is a special case after all, and the more general escape from a block is still very different. When the function ends in the previous section, close all upvalues in relevant bytecodes such as <code>Return/Return0/TailCall</code>, because each function will have one of these bytecodes at the end. However, there is no similar fixed bytecode at the end of the block, so a new bytecode <code>Close</code> is added for this purpose. This bytecode closes the local variable referenced by upvalue in the current block.</p>
<p>The easiest way is to generate a <code>Close</code> bytecode at the end of each block, but since the escape from the block is very rare, it's not worth to add a bytecode to all blocks. Therefore, it is necessary to judge whether there is an escape in this block during the syntax analysis stage. If not, there is no need to generate <code>Close</code> bytecode.</p>
<p>The next step is how to judge whether there are local variables escaping in a block. There are several possible implementations. For example, refer to the multi-level function nesting method in the previous section, and also maintain a block nesting relationship. However, there is a lighter approach, which is to add a flag bit to each local variable, and set this flag bit if it is referenced by upvalue. Then at the end of the block, judge whether the local variables defined in this block have been marked, and then you can know whether you need to generate <code>Close</code> bytecode.</p>
<p>The specific definition and execution flow of <code>Close</code> bytecode is omitted here.</p>
<h2 id="escape-from-goto"><a class="header" href="#escape-from-goto">Escape from <code>goto</code></a></h2>
<p>I really can't think of an example of a reasonable escape from <code>goto</code>. But it is still possible to construct an unreasonable example:</p>
<pre><code class="language-lua">::again::
     if c1 then -- false when the first execution reaches here
         c1() -- after assigning a value to c1 below, c1 is a closure that includes an upvalue
     end

     local i = 0
     c1 = function()
         i = i + 1 -- upvalue
         print(i)
     end
     go to again
</code></pre>
<p>In the above code, <code>if</code> is judged to be false at the first execution, the call to <code>c1</code> is skipped; after assigning a value to c1 below, c1 is a closure that includes an upvalue; then goto jumps back to the beginning, and at this time we can call c1; but at this time the local variable <code>i</code> is also invalid, so it needs to be closed.</p>
<p>In the above code, from the definition of <code>again</code> label at the beginning to the last <code>goto</code> statement can also be regarded as a block, then the method of escaping from the block just introduced can be used to process the goto statement. But the goto statement has a special place. We introduced <a href="./ch06-06.goto.html">goto statement</a> before, there are two ways to match label and goto statement:</p>
<ul>
<li>Match while parsing. That is, when the label is parsed, the goto statement that has already appeared is matched; when the goto statement is parsed, the label that has already appeared is matched;</li>
<li>After the block ends (that is, when the label defined in it becomes invalid), match the existing label and goto statement at one time.</li>
</ul>
<p>The implementation difficulty of these two methods is similar, but due to another feature of the goto statement, that is, the goto statement that jumps forward needs to ignore the void statement. In order to process the void statement more conveniently, the second solution above was adopted. However, now to support escapes, when a goto statement is parsed (precisely before the generated <code>Jump</code> bytecode), <em>may</em> generate a <code>Close</code> bytecode. Whether it will be generated or not depends on whether the definition of escaped local variables is skipped when goto jumps backwards. That is, only by matching the label and goto statement can we know whether the <code>Close</code> bytecode is required. If we still follow the second scheme to do the matching after the end of the block, even if you we that <code>Close</code> needs to be generated at the end of the block, it can no longer be inserted into the bytecode sequence. Therefore, it can only be changed to the first solution of matching while parsing, and judge whether it is necessary to generate <code>Close</code> bytecode in time during matching.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-closure"><a class="header" href="#rust-closure">Rust Closure</a></h1>
<p>The previous sections introduced closures defined in Lua. In addition, the official implementation of the Lua language also supports C language closures. Our interpreter is implemented by Rust, so it will naturally be changed to Rust closures. This section introduces Rust closures.</p>
<h2 id="c-closures-in-the-official-implementation-of-lua"><a class="header" href="#c-closures-in-the-official-implementation-of-lua">C Closures in the Official Implementation of Lua</a></h2>
<p>Let's first look at the C closures in the official implementation of Lua. The C language itself does not support closures, so it must rely on the cooperation of Lua to realize closures. Specifically, the upvalue is stored on the Lua stack, and then bound to the C function prototype to form a C closure. Lua provides a way for C functions to access upvalue on the stack through API.</p>
<p>Here is the C closure version of the counter example code:</p>
<pre><code class="language-c">// counter function prototype
static int counter(Lua_State *L) {
     int i = lua_tointeger(L, lua_upvalueindex(1)); // read upvalue count
     lua_pushinteger(L, ++i); // add 1 and push it to the top of the stack
     lua_copy(L, -1, lua_upvalueindex(1)); // Update the upvalue count with the new value at the top of the stack
     return 1; // return the count at the top of the stack
}

// factory function, create closure
int new_counter(Lua_State *L) {
     lua_pushinteger(L, 0); // push onto the stack
    
     // Create a C closure, the function prototype is counter, and also
     // includes 1 upvalue, which is 0 pushed in the previous line.
     lua_pushcclosure(L, &amp;counter, 1);

     // The created C closure is pressed on the top of the stack, and the
     // following return 1 means return to the C closure on the top of the stack
     return 1;
}
</code></pre>
<p>Let's look at the second function <code>new_counter()</code> first, which is also a factory function for creating closures. First call <code>lua_pushinteger()</code> to push the upvalue count to the top of the stack; then call <code>lua_pushcclosure()</code> to create a closure. To review, a closure consists of a function prototype and some upvalues, which are specified by the last two parameters of the <code>lua_pushcclosure()</code> function. The first parameter specifies the function prototype <code>counter</code>, and the second parameter <code>1</code> means that the 1 value at the top of the stack is an upvalue, that is, the 0 just pushed. The following figure is a schematic diagram of the stack before and after calling this function to create a C closure:</p>
<pre><code>|     |                            |         |
+-----+                            +---------+
|  i  +--\  +-C_closure------+&lt;----+ closure |
+-----+  |  | proto: counter |     +---------+
|     |  |  | upvalues:      |     |         |
         \--+--&gt; i           |
            +----------------+
</code></pre>
<p>The far left of the above figure is to push the count i=0 to the top of the stack. In the middle is the created C closure, including the function prototype and upvalue. On the far right is the stack layout after the closure is created, and the closure is pushed onto the stack.</p>
<p>Look at the first function <code>counter()</code> in the above code, which is the function prototype of the closure created. This function is relatively simple, the most critical of which is the <code>lua_upvalueindex()</code> API, which generates an index representing the upvalue, which can be used to read and write the upvalue encapsulated in the closure.</p>
<p>Through the call flow of the code in the above example to the relevant API, we can basically guess the specific implementation of the C closure. Our Rust closures can also refer to this approach. However, Rust natively supports closures! So we can use this feature to implement Rust closures in Lua more simply.</p>
<h2 id="rust-closure-definition"><a class="header" href="#rust-closure-definition">Rust Closure Definition</a></h2>
<p>To implement the &quot;Rust closure&quot; type in Lua with the closure of the Rust language, it is to create a new Value type including the closure of the Rust language.</p>
<p><a href="https://doc.rust-lang.org/stable/book/ch13-01-closures.html">&quot;Rust Programming Language&quot;</a> has introduced Rust's closures in detail, so I won't say more here. We just need to know that Rust closures are a trait. Specifically, the Rust closure type in Lua is <code>FnMut (&amp;mut ExeState) -&gt; i32</code>. Then you can try to define the Rust closure type of Value in Lua as follows:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     RustFunction(fn (&amp;mut ExeState) -&gt; i32), // normal function
     RustClosure(FnMut (&amp;mut ExeState) -&gt; i32), // Closure</code></pre>
<p>However, this definition is illegal, and the compiler will report the following error:</p>
<pre><code>error 782| trait objects must include the `dyn` keyword
</code></pre>
<p>This involves the <em>static dispatch</em> and <em>dynamic dispatch</em> of traits in Rust. <a href="https://doc.rust-lang.org/stable/book/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch">&quot;Rust Programming Language&quot;</a> also has a detailed introduction for this, so I won’t say more here.</p>
<p>Then, we add <code>dyn</code> according to the compiler's prompt:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     RustClosure(dyn FnMut (&amp;mut ExeState) -&gt; i32),</code></pre>
<p>The compiler still reports an error, but with a different one:</p>
<pre><code>error 277| the size for values of type `(dyn for&lt;'a&gt; FnMut(&amp;'a mut ExeState) -&gt; i32 + 'static)` cannot be known at compilation time
</code></pre>
<p>That is to say, the trait object is a DST. This was introduced in <a href="./ch03-00.optimize_string.html">Introduction to String Definition</a> before, but what I encountered at that time was slice, and now it is trait, which are also the two most important DSTs in Rust. <a href="https://doc.rust-lang.org/stable/book/ch19-04-advanced-types.html#dynamically-sized-types-and-the-sized-trait">&quot;Rust Programming Language&quot;</a> also has a detailed introduction for this. The solution is to encapsulate a layer of pointers outside. Since Value supports Clone, <code>Box</code> cannot be used, only <code>Rc</code> can be used. And because it is <code>FnMut</code> instead of <code>Fn</code>, it will change the captured environment when it is called, so another layer of <code>RefCell</code> is needed to provide internal variability. So the following definition is obtained:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     RustClosure(Rc&lt;RefCell&lt;dyn FnMut (&amp;mut ExeState) -&gt; i32&gt;&gt;),</code></pre>
<p>Finally compiled this time! However, think about why <code>Rc&lt;str&gt;</code> was not used when introducing various definitions of strings? Because for the DST type, the actual length needs to be stored in the external pointer or reference, then the pointer will become a &quot;fat pointer&quot;, which needs to occupy 2 words. This will further cause the size of the entire Value to become larger. In order to avoid this situation, we can only add another layer of <code>Box</code>, let the Box contain a specific length and become a fat pointer, so that <code>Rc</code> can restore 1 word. It is defined as follows:</p>
<pre><code class="language-rust  ignore">pub enum Value {
     RustClosure(Rc&lt;RefCell&lt;Box&lt;dyn FnMut (&amp;mut ExeState) -&gt; i32&gt;&gt;&gt;),</code></pre>
<p>After defining the type of Rust closure, I also encountered the same problem as Lua closure: should I keep the type of Rust function? It doesn't make much difference whether to keep it or not. We chose to keep it here.</p>
<h2 id="virtual-machine-execution-12"><a class="header" href="#virtual-machine-execution-12">Virtual Machine Execution</a></h2>
<p>The virtual machine implementation of Rust closures is very simple. Because closures and functions are called in the same way in the Rust language, the invocation of Rust closures is the same as the invocation of previous Rust functions:</p>
<pre><code class="language-rust  ignore">     fn do_call_function(&amp;mut self, narg_plus: u8) -&gt; usize {
         match self.stack[self.base - 1].clone() {
             Value::RustFunction(f) =&gt; { // Rust normal function
                 // omit the preparation of parameters
                 f(self) as usize
             }
             Value::RustClosure(c) =&gt; { // Rust closure
                 // Omit the same parameter preparation process
                 c.borrow_mut()(self) as usize
             }</code></pre>
<h2 id="test-10"><a class="header" href="#test-10">Test</a></h2>
<p>This completes the Rust closure type. After borrowing the closure of the Rust language itself, this implementation is very simple. There is no need to use the Lua stack to cooperate like the official Lua implementation, and there is no need to introduce some special APIs.</p>
<p>The following code shows how the counter example at the beginning of this section can be implemented using Rust closures:</p>
<pre><code class="language-rust  ignore">fn test_new_counter(state: &amp;mut ExeState) -&gt; i32 {
     let mut i = 0_i32;
     let c = move |_: &amp;mut ExeState| {
         i += 1;
         println!(&quot;counter: {i}&quot;);
         0
     };
     state.push(Value::RustClosure(Rc::new(RefCell::new(Box::new(c)))));
     1
}</code></pre>
<p>Compared with the C closure at the beginning of this section, this version is clearer except for the last statement to create a closure, which is very verbose. The last statement will also be optimized when the interpreter API is sorted out later.</p>
<h2 id="limitations-of-rust-closures"><a class="header" href="#limitations-of-rust-closures">Limitations of Rust Closures</a></h2>
<p>As you can see from the sample code above, the captured environment (or upvalue) <code>i</code> needs to be moved into the closure. This also leads to the fact that upvalues cannot be shared among multiple closures. Lua's official C closure does not support sharing, so there is no problem.</p>
<p>Another point that needs to be explained is that Lua's official C closure uses Lua's stack to store upvalue, which leads to the type of upvalue being Lua's Value type. And we use the closure of Rust language, then upvalue can be &quot;more&quot; types, not limited to the Value type. However, the two should be functionally equivalent:</p>
<ul>
<li>The &quot;more&quot; types supported by Rust closures can be implemented in Lua with LightUserData, that is, pointers; although this is very unsafe for Rust.</li>
<li>The internal types supported in Lua, such as Table, can also be obtained through the API <a href="./ch08-04.rust_functions_and_api.html#rust-api"><code>get()</code></a> in our interpreter (and In Lua's official implementation, the table type is internal and not external).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generic-for-statement"><a class="header" href="#generic-for-statement">generic-for Statement</a></h1>
<p>Closures were introduced in the previous sections of this chapter. The most typical application scenario of a closure is an iterator, and the most common place for an iterator is a <code>for</code> statement. So much so that &quot;Lua Programming&quot; and <a href="https://doc.rust-lang.org/stable/book/ch13-00-functional-features.html">&quot;Rust Programming Language&quot;</a> both put Closures, iterators, and the <code>for</code> statement introduced together. The <code>for</code> statement in the Lua language has two formats, numeric and generic. <a href="./ch06-05.numerical-for.html">Previously</a> has introduced the numerical-for statement, this section introduces the generic-for statement using iterators.</p>
<p>After introducing closures, the concept of an iterator itself is straightforward. The counter closure that has been used as an example in the previous sections of this chapter can be regarded as an iterator, which generates an incremented number each time. Let's look at a slightly more complex iterator to traverse the array part of a table. This is also the function of the <code>ipairs()</code> function that comes with the Lua language:</p>
<pre><code class="language-lua">function ipairs(t)
     local i = 0
     return function ()
         i = i + 1
         local v = t[i]
         if v then
             return i, v
         end
     end
end
</code></pre>
<p>In the above code, <code>ipairs()</code> is a factory function that creates and returns a closure as an iterator. This iterator has 2 upvalues, one is the fixed table <code>t</code>, and the other is the traversed position <code>i</code>. We can call these two upvalues as &quot;iteration environments&quot;. During the traversal process, the iterator returns the index and value of the array; when the traversal ends, it does not return a value, and it can also be considered as returning <code>nil</code>.</p>
<p>This iterator can be called directly, but is more commonly used in a generic-for statement:</p>
<pre><code class="language-lua">-- call the iterator directly
local iter = ipairs(t)
while true do
     local i, v = iter()
     if not i then break end
     block -- do something
end

-- used in a generic-for statement
for i, v in ipairs(t) do
     block -- do something
end
</code></pre>
<p>The use of iterators is certainly very convenient, but the previous sections also introduced that creating a closure requires additional overhead compared to creating a normal function, that is, both Lua closures and Rust closures require 2 extra times Memory allocation and 2 pointer jumps. Therefore, the generic for statement in the Lua language is specially optimized for this purpose, that is, the generic for statement itself replaces the closure to save the &quot;iteration environment&quot; (that is, 2 upvalues). Since there is no need for upvalue, the iterator does not need to use closures, but only ordinary functions.</p>
<p>Specifically, the <a href="https://www.lua.org/manual/5.4/manual.html#3.3.5">grammar</a> of the generic for statement is as follows:</p>
<pre><code>stat ::= for namelist in explist do block end
namelist ::= Name {‘,’ Name}
</code></pre>
<p>Its execution process is as follows:</p>
<ul>
<li>
<p>At the beginning of the loop, <code>explist</code> is evaluated to get 3 values: the iteration function, the immutable state, and the control variable. In most cases, <code>explist</code> is a function call statement, so the evaluation follows the evaluation rules of the function return value, that is, if there are less than 3, it will be filled with nil, and if it exceeds 3, the excess will be discarded. Of course, instead of using a function call, you can directly list 3 values.</p>
</li>
<li>
<p>Then, before each execution of the loop, use the latter two values (immutable state and control variables) as parameters to call the iteration function, and judge the first return value: if it is nil, terminate the loop; otherwise, assign the return value to <code>namelist</code>, and additionally assign the first return value to the control variable as a parameter for subsequent calls to the iteration function.</p>
</li>
</ul>
<p>It can be seen that the three values returned by <code>explist</code> are put together to form a closure function: the iteration function is the function prototype, and the latter two are upvalues. It's just that the generic-for statement helps maintain these two upvalues. Using this feature of the generic-for statement, reimplement the above iterator for traversing the array as follows:</p>
<pre><code class="language-lua">local function iter(t, i) -- both t and i are changed from upvalue to parameter
     i = i + 1
     local v = t[i]
     if v then
         return i, v
     end
end

function ipairs(t)
     return iter, t, 0
end
</code></pre>
<p>Compared with the closure version above, here both <code>t</code> and <code>i</code> have changed from upvalue to parameters, and <code>iter</code> has become an ordinary function.</p>
<p>From this point of view, the generic-for statement can be completed without the need for a closure (such as after the function was introduced in the previous chapter). But after all, this is an optimization based on closures. Only by mastering closures can we understand why we do this. That's why we implement the generic-for statement after introducing closures.</p>
<p>In addition, the function call statement <code>ipairs(t)</code> here only returns 3 variables, and these 3 variables can also be listed directly in the generic for statement:</p>
<pre><code class="language-lua">for i, v in ipairs(t) do ... end
for i, v in iter, t, 0 do ... end -- directly list 3 variables
</code></pre>
<p>The following direct list method omits a function call, but it is inconvenient. So the first one is more common.</p>
<p>After introducing the characteristics of the generic-for statement in Lua, let's start to implement it.</p>
<h2 id="accomplish"><a class="header" href="#accomplish">Accomplish</a></h2>
<p>According to the above introduction, the generic-for statement saves and maintains the iteration environment by itself. Where is that saved? Naturally, it is still on the stack. Just like the numerical-for statement will automatically create 3 variables (1 count variable and 2 anonymous variables) on the stack, the generic-for statement also needs to automatically create 3 anonymous variables, corresponding to the above iteration environment: iteration function, immutable state, control variables. These 3 variables are obtained after evaluating <code>explist</code>, as shown in the stack diagram shown in the left figure below:</p>
<pre><code>|           |        |           |     |           |
+-----------+        +-----------+     +-----------+
| iter func |entry   | iter func |     | iter func |
+-----------+        +-----------+     +-----------+
| state     |\       | state     |     | state     |
+-----------+ 2args  +-----------+     +-----------+
| ctrl var  |/       | ctrl var  |     | ctrl var  |&lt;--first return value
+-----------+        +-----------+   -&gt;+-----------+
|           |        :           :  /  | name-     | i
                     +-----------+ /   | list      | v
                     | return-   |-    |           |
                     | values    |
                     |           |
</code></pre>
<p>Next, the loop is executed, including three steps: calling the iterative function, judging whether to continue the loop, and controlling variable assignment.</p>
<p>First, the iteration function <code>iter func</code> is called with the immutable state <code>state</code> and the control variable <code>ctrl var</code> as two parameters. Look at the stack diagram in the left figure, it has just been arranged into a function call formation, so the function can be called directly;</p>
<p>Secondly, after calling the function (the middle picture above), judge whether the first return value is nil, if so, exit the loop; if there is no return value, also exit the loop; otherwise, continue to execute the loop. Before executing the loop body, the return value needs to be processed (right picture above):</p>
<ul>
<li>
<p>Assign the first return value to the control variable (ctrl-var in the above figure) as the parameter for the next call to the iterative function;</p>
</li>
<li>
<p>Assign the return value to the variable list, which is <code>namelist</code> in the above BNF. For example, in the above example of traversing the array, it is <code>i, v</code>. If the number of return values is less than the variable list, it will be filled with nil. This padding operation is consistent with ordinary function calls. The inconsistency is that the return value of an ordinary function call will be moved to the function entry, which is the position of <code>iter func</code> in the above figure; but here it is shifted down by 3 positions.</p>
</li>
</ul>
<p>One thing that needs to be explained here is that the control variable <code>ctrl-var</code> is the first name of <code>namelist</code>. So in fact, there is no need to reserve a place for <code>ctrl-var</code> on the stack; after calling the iterative function each time, just move all the return values directly to the place of <code>ctrl-var</code> in the figure, so that the first return value happens to be where <code>ctrl-var</code> is. The figure below is a comparison of the two schemes. The left picture is the original plan, which specially reserved the position for <code>ctrl-var</code>; the right picture is the new plan, which only needs 2 anonymous variables to save the iteration environment, and <code>ctrl-var</code> overlaps with the first name:</p>
<pre><code> |           |      |           |
 +-----------+      +-----------+
 | iter func |      | iter func |
 +-----------+      +-----------+
 | state     |      | state     |
 +-----------+      +-----------+
 | ctrl var  |     i| name-     | &lt;--ctrl var
 +-----------+     v| list      |
i| name-     |      |           |
v| list      |
 |           |
</code></pre>
<p>The solution on the right is simpler, with one less variable assignment. And under normal circumstances, the functions of the two programs are the same. But in one case, the function will be different, that is, when the control variable is modified in the loop body. For example, the following sample code:</p>
<pre><code class="language-lua">for i, v in ipairs(t) do
     i = i + 1 -- modify the control variable `i`
     print(i)
end
</code></pre>
<p>According to the scheme in the left figure above, the <code>i</code> modified here is a variable exposed to programmers, and the control variable <code>ctrl var</code> is a hidden anonymous variable, and these two variables are independent. So modifications to <code>i</code> do not affect the control variable <code>ctrl var</code>. So this loop can still traverse the entire array.</p>
<p>According to the scheme on the right, <code>i</code> and <code>ctrl var</code> are the same value, and modifying <code>i</code> means modifying <code>ctrl var</code>, which affects the next iteration function call, and eventually leads to the failure to traverse the entire array normally.</p>
<p>Which behavior is more reasonable? <a href="https://www.lua.org/manual/5.4/manual.html#3.3.5">Lua Manual</a> explains: You should not change the value of the control variable during the loop. In other words, there is no clear definition of this behavior, so any solution is fine. However, the official implementation of Lua is based on the behavior in the left picture. In order to maintain consistency, we also choose the left picture here.</p>
<h2 id="bytecode-6"><a class="header" href="#bytecode-6">Bytecode</a></h2>
<p>The above describes the operation of the generic-for statement in the loop. These operations require a new bytecode <code>ForCallLoop</code> to complete.</p>
<p>Before defining this bytecode, let's see where this bytecode should be placed? Is it the beginning of the loop, or the end of the loop? If you follow the Lua code, it should be placed at the beginning of the loop, and then generate a <code>Jump</code> bytecode at the end of the loop to jump back and continue the loop, like this:</p>
<pre><code>ForCallLoop # If calling the iteration function returns nil, jump to the end
... block ...
Jump (back-to-ForCallLoop)
</code></pre>
<p>But in this case, 2 bytecodes are executed for each loop, <code>ForCallLoop</code> at the beginning and <code>Jump</code> at the end. To reduce the bytecode once, we can put <code>ForCallLoop</code> at the end of the loop, so that only 2 bytecodes need to be executed in the first loop, and only 1 bytecode needs to be executed in each subsequent loop:</p>
<pre><code>Jump (forward-to-ForCallLoop)
... block ...
ForCallLoop # If the return of calling the iteration function is not nil, then jump to the above block
</code></pre>
<p>After determining the bytecode location, let's look at the definition. This bytecode needs to be associated with 3 parameters:</p>
<ul>
<li>the stack index of the iteration function <code>iter func</code>;</li>
<li>The number of variables used for the assignment of the return value. If the number of return values is less than the number of variables, you need to fill in nil;</li>
<li>Jump distance.</li>
</ul>
<p>Both the first two parameters can be represented by 1 byte, so there is only 1 byte left for the final jump distance, which can only represent a distance of 255, which is not enough. For this reason, we can only add a <code>Jump</code> bytecode to complete this function. However, in most cases, the loop body is not large, and the distance does not exceed 255. It is a bit wasteful to add another bytecode for a small number of large loop bodies. The best thing to do in this situation is to:</p>
<ul>
<li>For the small loop body, the jump distance can be programmed into <code>ForCallLoop</code> bytecode, only this 1 bytecode is used;</li>
<li>For the large loop body, set the jump distance of the third parameter in the <code>ForCallLoop</code> bytecode to 0, and add a <code>Jump</code> bytecode to cooperate.</li>
</ul>
<p>In this way, when the virtual machine is executed:</p>
<ul>
<li>In the case where the loop needs to jump backwards: for a small loop body, jump directly according to the third parameter; for a large loop body, the third parameter is 0, actually jump to the next Jump bytecode, and then Execute the jump of the loop body again.</li>
<li>In the case where the loop needs to continue to execute forward: for small loop bodies, no special processing is required; for large loop bodies, the next Jump bytecode needs to be skipped.</li>
</ul>
<p>In summary, the bytecode <code>ForCallLoop</code> is defined as follows:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     ForCallLoop(u8, u8, u8),</code></pre>
<p>The specific syntax analysis and virtual machine execution code are omitted here.</p>
<p>At this point, the generic-for statement is completed. We also finished <a href="https://www.lua.org/manual/5.4/manual.html#9">all the syntax of Lua</a>! (Applause please!)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-_env"><a class="header" href="#environment-_env">Environment _ENV</a></h1>
<p>Go back to the first &quot;hello, world!&quot; example in Chapter 1. In the output of <code>luac -l</code> displayed at that time, the bytecode for reading the global variable <code>print</code> is as follows:</p>
<pre><code>2 [1] GETTABUP 0 0 0 ; _ENV &quot;print&quot;
</code></pre>
<p>Looking at the complex name of the bytecode and the strange <code>_ENV</code> comment behind it, it is not simple. At that time, this bytecode was not introduced, but the more intuitive bytecode <code>GetGlobal</code> was redefined to read global variables. In this section, let’s supplement the introduction of <code>_ENV</code>.</p>
<h2 id="current-global-variables"><a class="header" href="#current-global-variables">Current Global Variables</a></h2>
<p>Our current handling of global variables is straightforward:</p>
<ul>
<li>
<p>In the syntax analysis stage, variables that are not local variables and upvalues are considered as global variables, and corresponding bytecodes are generated, including <code>GetGlobal</code>, <code>SetGlobal</code> and <code>SetGlobalConst</code>;</p>
</li>
<li>
<p>In the execution phase of the virtual machine, define <code>global: HashMap&lt;String, Value&gt;</code> in the execution state <code>ExeState</code> data structure to represent the global variable table. Subsequent reads and writes to global variables operate on this table.</p>
</li>
</ul>
<p>This approach is intuitive and has no downsides. However, there is another way to bring more powerful features, which is the environment <code>_ENV</code> introduced in Lua version 5.2. &quot;Lua Programming&quot; has a very detailed description of <code>_ENV</code>, including why <code>_ENV</code> should be used instead of global variables and application scenarios. We will not go into details here, but directly introduce its design and implementation.</p>
<h2 id="how-_env-works"><a class="header" href="#how-_env-works">How _ENV Works</a></h2>
<p>The principle of <code>_ENV</code>:</p>
<ul>
<li>
<p>In the parsing phase, convert all global variables into indexes of table &quot;_ENV&quot;, such as <code>g1 = g2</code> to <code>_ENV.g1 = _ENV.g2</code>;</p>
</li>
<li>
<p>So what is <code>_ENV</code> itself? Since all Lua code segments can be considered as a function, <code>_ENV</code> can be considered as a local variable outside the code segment, which is upvalue. For example, for the above code segment <code>g1 = g2</code>, a more complete conversion result is as follows:</p>
</li>
</ul>
<pre><code class="language-lua">local _ENV = XXX -- predefined global variable table
return function (...)
     _ENV.g1 = _ENV.g2
end
</code></pre>
<p>All &quot;global variables&quot; have become indexes of <code>_ENV</code>, and <code>_ENV</code> itself is also an upvalue, so there are no global variables! In addition, the key point is that <code>_ENV</code> itself has nothing special except that it is preset in advance, it is just an ordinary variable. This means that it can be manipulated like ordinary variables, which brings a lot of flexibility, such as a sandbox can be easily implemented. The specific usage scenarios will not be expanded here. If you are interested, you can refer to &quot;Lua Programming&quot;.</p>
<h2 id="implementation-of-_env"><a class="header" href="#implementation-of-_env">Implementation of _ENV</a></h2>
<p>According to the above introduction, use <code>_ENV</code> to transform global variables.</p>
<p>First, in the syntax analysis stage, the global variable is transformed into an index to <code>_ENV</code>. The relevant code is as follows:</p>
<pre><code class="language-rust  ignore">fn simple_name(&amp;mut self, name: String) -&gt; ExpDesc {
     // Omit the matching of local variables and upvalue, and return directly if they match.

     // If there is no match,
     // - Previously considered to be a global variable, return ExpDesc::Global(name)
     // - Now transformed into _ENV.name, the code is as follows:
     let env = self.simple_name(&quot;_ENV&quot;.into()); // call recursively, look for _ENV
     let ienv = self. discharge_any(env);
     ExpDesc::IndexField(ienv, self. add_const(name))
}</code></pre>
<p>In the above code, first try to match the variable <code>name</code> from local variables and upvalue. This part was introduced in detail in <a href="./ch09-02.escape_and_closure.html">upvalue</a> and is omitted here. Here we only look at the case where the matching fails. In this case, <code>name</code> was previously considered to be a global variable, and <code>ExpDesc::Global(name)</code> was returned. Now to transform it into <code>_ENV.name</code>, it is necessary to locate <code>_ENV</code> first. Since <code>_ENV</code> is also an ordinary variable, the <code>simple_name()</code> function is called recursively with <code>_ENV</code> as an argument. In order to ensure that this call does not recurse infinitely, it is necessary to pre-set <code>_ENV</code> in the preparation phase of syntax analysis. So in this recursive call, <code>_ENV</code> will definitely be matched as a local variable or upvalue, and will not be called recursively again.</p>
<p>So how to pre-set <code>_ENV</code>? In the above introduction, <code>_ENV</code> is the upvalue as the whole code block. But for the sake of convenience, we can use <code>_ENV</code> as a parameter in the <code>load()</code> function to achieve the same effect:</p>
<pre><code class="language-rust  ignore">pub fn load(input: impl Read) -&gt; FuncProto {
     let mut ctx = ParseContext { /* omitted */ };

     // _ENV as the first and only parameter
     chunk(&amp;mut ctx, false, vec![&quot;_ENV&quot;.into()], Token::Eos)
}</code></pre>
<p>In this way, when parsing the outermost code of the code block, when the <code>simple_name()</code> function is called, a local variable of <code>_ENV</code> will be matched; and an upvalue of <code>_ENV</code> will be matched for the code inside the function.</p>
<p>This is just a promise that there must be a <code>_ENV</code> variable. And the fulfillment of this promise needs to be performed in the virtual machine execution stage. When creating an execution state <code>ExeState</code>, immediately after the function entry, <code>_ENV</code> must be pushed onto the stack as the first parameter. In fact, the previous initialization of the <code>global</code> member in <code>ExeState</code> is transferred to the stack. code show as below:</p>
<pre><code class="language-rust  ignore">impl ExeState {
     pub fn new() -&gt; Self {
         // global variable table
         let mut env = Table::new(0, 0);
         env.map.insert(&quot;print&quot;.into(), Value::RustFunction(lib_print));
         env.map.insert(&quot;type&quot;.into(), Value::RustFunction(lib_type));
         env.map.insert(&quot;ipairs&quot;.into(), Value::RustFunction(ipairs));
         env.map.insert(&quot;new_counter&quot;.into(), Value::RustFunction(test_new_counter));

         ExeState {
             // Push 2 values on the stack: the virtual function entry, and the global variable table _ENV
             stack: vec![Value::Nil, Value::Table(Rc::new(RefCell::new(env)))],
             base: 1, // for entry function
         }
     }</code></pre>
<p>In this way, the transformation of <code>_ENV</code> is basically completed. This transformation is very simple, but the function it brings is very powerful, so <code>_ENV</code> is a very beautiful design.</p>
<p>In addition, since there is no concept of global variables, the previous codes related to global variables, such as <code>ExpDesc::Global</code> and the generation and execution of 3 bytecodes related to global variables, can be deleted. Note that no new ExpDesc or bytecode is introduced to implement <code>_ENV</code>. But just not yet.</p>
<h2 id="optimization"><a class="header" href="#optimization">Optimization</a></h2>
<p>Although the above transformation is fully functional, there is a performance problem. Since <code>_ENV</code> is upvalue in most cases, for global variables, two bytecodes will be generated in the above <code>simple_name()</code> function:</p>
<pre><code>Getupvalue ($tmp_table, _ENV) # first load _ENV onto the stack
GetField ($dst, $tmp_table, $key) # before indexing
</code></pre>
<p>In the original scheme that does not use <code>_ENV</code>, only one bytecode <code>GetGlobal</code> is needed. This new solution obviously reduces performance. To make up for the performance loss here, it is only necessary to provide bytecodes that can directly index the upvalue table. To do this, add 3 bytecodes:</p>
<pre><code class="language-rust  ignore">pub enum ByteCode {
     // Deleted 3 old bytecodes that directly manipulate the global variable table
     // GetGlobal(u8, u8),
     // SetGlobal(u8, u8),
     // SetGlobalConst(u8, u8),

     // Add 3 corresponding bytecodes for operating the upvalue table
     GetUpField(u8, u8, u8),
     SetUpField(u8, u8, u8),
     SetUpFieldConst(u8, u8, u8),</code></pre>
<p>Correspondingly, the expression of the upvalue table index should also be increased:</p>
<pre><code class="language-rust  ignore">enum ExpDesc {
     // deleted global variable
     // Global(usize),

     // Added index to upvalue table
     IndexUpField(usize, usize),</code></pre>
<p>The index to the upvalue table here only supports string constants, which is also the scenario for global variables. Although this <code>IndexUpField</code> is added for global variable optimization, it can also be applied to ordinary upvalue table indexes. Therefore, in the function of parsing table indexes, <code>IndexUpField</code> optimization can also be added. The specific code is omitted here.</p>
<p>After defining <code>IndexUpField</code>, the original variable parsing function can be modified:</p>
<pre><code class="language-rust  ignore">fn simple_name(&amp;mut self, name: String) -&gt; ExpDesc {
     // Omit the matching of local variables and upvalue, and return directly if they match.

     // If there is no match,
     // - Previously considered to be a global variable, return ExpDesc::Global(name)
     // - Now transformed into _ENV.name, the code is as follows:
     let iname = self. add_const(name);
     match self. simple_name(&quot;_ENV&quot;.into()) {
         ExpDesc::Local(i) =&gt; ExpDesc::IndexField(i, iname),
         ExpDesc::upvalue(i) =&gt; ExpDesc::IndexUpField(i, iname), // new IndexUpField
         _ =&gt; panic!(&quot;no here&quot;), // because &quot;_ENV&quot; must exist!
     }
}</code></pre>
<p>As before, after a variable fails to match both the local variable and the upvalue, it still uses <code>_ENV</code> as a parameter to recursively call the <code>simple_name()</code> function. But here we know that the result returned by <code>_ENV</code> must be a local variable or an upvalue. In these two cases, <code>ExpDesc::IndexField</code> and <code>ExpDesc::IndexUpField</code> are generated respectively. Then generate the 3 new bytecodes above when reading and writing <code>ExpDesc::IndexUpField</code>.</p>
<p>In this way, it is equivalent to replacing <code>ExpDesc::Global</code> with <code>ExpDesc::IndexUpField</code>. The processing of <code>ExpDesc::Global</code> was deleted before, and now it is added back from <code>ExpDesc::IndexUpField</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="to-be-continued"><a class="header" href="#to-be-continued">To Be Continued</a></h1>
<p>We have implemented the core features of the Lua interpreter. Still, we're far from our original goal - a complete, performant, production-grade interpreter. I will continue to improve this interpreter, but due to busy work and insufficient spare time, I will suspend this series of articles. Writing articles is more tiring than writing code. Combined with my experience of reading Yu Yuan's &quot;Handwriting Operating System by Yourself&quot; when I was in school, I only followed the first half of the book and practiced it. After mastering the basic development methods and getting started with writing an operating system, the rest is to write it by myself. I think the parts of this series of articles that have been completed so far should also provide an introductory knowledge of implementing a Lua interpreter, and interested readers can implement the remaining parts independently.</p>
<p>Here is a partial list of some unfinished features:</p>
<ul>
<li>
<p>Metatable is a very important feature of Lua language, providing flexible and powerful features. However, its implementation principle is very simple. It only needs to make an extra layer of judgment when the virtual machine executes the relevant bytecode, and it does not even need to modify the part of syntax analysis. Here is an implementation detail: the garbage collection of our interpreter uses RC, which may cause circular references and lead to memory leaks. A table setting itself as its own metatable is a common circular reference. To avoid circular references in this common scenario, special handling is required for this case.</p>
</li>
<li>
<p>UserData, is one of the basic types of Lua. However, we have not yet encountered the need to use UserData. We can implement this type later when we encounter this requirement when implementing the standard library. In the official implementation of Lua, creating a new UserData is to allocate for memory in Lua, and then hand it over to the C function to initialize. However, uninitialized memory is not allowed in Rust, so we have to think about how to create a UserData value.</p>
</li>
<li>
<p>LightUserData, also one of the basic types of Lua. It's just a raw pointer, and doesn't need to do anything special about it.</p>
</li>
<li>
<p>Error handling. Our current way of handling all errors is to panic, which is not feasible. At least we need to distinguish between expected errors and program bugs. The former may also need to subdivide lexical analysis, syntax analysis, virtual machine execution, Rust API and other types. <a href="https://doc.rust-lang.org/stable/book/ch09-00-error-handling.html">Error handling</a> is also a feature of the Rust language. It's also a great opportunity to experience Rust's error handling.</p>
</li>
<li>
<p>Performance optimization. High performance is one of our initial goals, and some optimizations have been made during the implementation, such as the design of the string type, but the final result is not yet known, and we still need to test to know. There are some <a href="https://github.com/gligneul/Lua-Benchmarks">benchmark</a> <a href="https://programming-language-benchmarks.vercel.app/lua">examples</a> codes of Lua performance tests on the Internet, we can follow the Lua official Implement a comparative test. This also verifies correctness by the way.</p>
</li>
<li>
<p>Optimized table construction. For the table construction with all constant elements, there is no need to load it on the stack, and even the table can be created directly in the syntax analysis stage.</p>
</li>
<li>
<p>Rust API. The more usage scenarios of the Lua language are glue languages, so the external API is very important. Our interpreter is mainly used for programs written in Rust language, so it should provide a set of APIs that conform to the Rust calling method. This is inconsistent with the C API provided by the official Lua implementation. We have already implemented some basic APIs, such as reading values on the stack, etc., using generics, which simplifies the API and calling methods, which is inconsistent with the C API. <a href="https://www.boringcactus.com/2020/09/16/survey-of-rust-embeddable-scripting-languages.html">Here</a> has a comparative survey of the calling methods of the scripting language implemented by Rust.</p>
</li>
<li>
<p>Library. The current interpreter is a stand-alone program, but the most common usage scenario for Lua is a library that is called by other programs. So we need to transform our project into a library.</p>
</li>
<li>
<p>Support parameter passing and return value of the entire code segment.</p>
</li>
<li>
<p>The standard library, which is a feature other than the core of the interpreter, involves more aspects. In addition to the packages listed below, there are some basic functions in the standard library, such as <code>type()</code> and <code>ipairs()</code>, which we have already implemented, and most of the rest are not difficult. The only trouble is <code>pairs()</code> function. The efficient implementation of the <code>pairs()</code> function in the official Lua implementation depends on the implementation of the table. And we use Rust's <code>HashMap</code> to implement the dictionary part of the table, there may be no simple way to implement it.</p>
</li>
<li>
<p>The math library, most functions have corresponding implementations in the Rust standard library, the only thing that needs to be manually implemented is the function to generate random numbers. Since this function is not provided in the C language standard, Lua's official implementation makes this function itself. Although we can also use the <code>random</code> crate, it is better to refer to the official Lua implementation and implement this random number generation function by ourselves. In addition, generating random numbers requires maintaining a global state. In the official implementation of Lua, this state is a UserData type and is added to Lua's Register. And we can use the characteristics of Rust closures to put this state in closures, which is more convenient and efficient.</p>
</li>
<li>
<p>The string library, the trouble is regular matching. For convenience, Lua language defines and implements a set of regular matching rules. So we can only follow its definition and reimplement it in Rust. It should be very complicated here, but after completion, we will have a deeper understanding of regular matching.</p>
</li>
<li>
<p>The io library, the trouble is the representation of the file. The <code>FILE</code> type is provided in the C language standard, which can represent all file types, including standard input and output, ordinary files, etc., and can also represent multiple modes such as read-only, write-only, and read-write. But in the Rust language these seem to be independent. If we want to provide an API consistent with the io library, we need to do encapsulation.</p>
</li>
<li>
<p>The coroutine library, requires a thorough understanding of Lua's coroutines, and will also make great adjustments to the existing function call process.</p>
</li>
<li>
<p>The debug library, I have not used this library, I don't know much, but I feel that if to implement this library I will either need a lot of unsafe code, or make a lot of changes to the existing process. So in the end one may choose not to implement this library.</p>
</li>
</ul>
<p>In addition to the above list of unfinished functions, there are some small improvements to the current code, such as refining the comments, applying the <code>let..else</code> syntax supported in the new version of Rust, and some small code optimizations, etc. For this reason, we add <a href="https://github.com/WuBingzheng/build-lua-in-rust/tree/main/listing/to_be_continued">to_be_continued</a>, which can also be seen as the final version of the code corresponding to this series of articles.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="references"><a class="header" href="#references">References</a></h1>
<ul>
<li>
<p><a href="https://www.lua.org/manual/5.4/">Lua 5.4 Reference Manual</a>, which is also the requirements document for this project.</p>
</li>
<li>
<p>&quot;Lua Programming (4th Edition)&quot;, the official Lua tutorial. Although it is based on the Lua 5.3 version, it has little impact due to the <a href="http://www.lua.org/manual/5.4/readme.html#changes">not many changes</a> of the 5.4 version.</p>
</li>
<li>
<p><a href="https://www.luafaq.org/#T1.26">Why is there no continue statement?</a>, an explanation of why there is no continue statement in Lua.</p>
</li>
<li>
<p><a href="https://doc.rust-lang.org/stable/book/title-page.html">《Rust Programming Language》</a>, the official Rust tutorial.</p>
</li>
<li>
<p><a href="https://doc.rust-lang.org/">Official Rust Documentation</a>, mainly refer to the standard library part.</p>
</li>
<li>
<p><a href="https://manishearth.github.io/blog/2015/09/01/designing-a-gc-in-rust/">Designing a GC in Rust</a>, introduces the design idea of implementing GC in Rust.</p>
</li>
<li>
<p><a href="https://crates.io/crates/gc">gc-crate</a>, an implementation based on the above design ideas.</p>
</li>
<li>
<p><a href="https://manishearth.github.io/blog/2021/04/05/a-tour-of-safe-tracing-gc-designs-in-rust/">A Tour of Safe Tracing GC Designs in Rust</a> , introducing a GC design implemented in Rust. I just remember one thing: implementing GC in Rust is hard.</p>
</li>
<li>
<p><a href="https://coredumped.dev/2022/04/11/implementing-a-safe-garbage-collector-in-rust/">Implementing a safe garbage collector in Rust</a>, another project that uses Rust to implement GC.</p>
</li>
<li>
<p><a href="https://zackoverflow.dev/writing/unsafe-rust-vs-zig/">When Zig is safer and faster than Rust</a>, starting from Roc language using Zig instead of Rust to implement the GC part, to illustrate the use It is difficult to implement certain functions in unsafe Rust.</p>
</li>
<li>
<p><a href="https://github.com/kyren/luster">Luster</a>, a Lua interpreter implemented in Rust, also uses GC instead of RC, but the project is not completed.</p>
</li>
<li>
<p><a href="https://dev.to/seanchen1991/the-story-of-tail-call-optimizations-in-rust-35hf">The Story of Tail Call Optimizations in Rust</a>, a discussion of tail call support in the Rust language.</p>
</li>
<li>
<p><a href="https://www.reddit.com/r/rust/comments/8coe49/lua_bindings_lua_hlua_or_rlua/">Lua bindings: lua, hlua or rlua?</a>, there are three existing Lua crates on Reddit: lua, hlua and A simple comparison of rlua.</p>
</li>
<li>
<p><a href="https://www.boringcactus.com/2020/09/16/survey-of-rust-embeddable-scripting-languages.html">A Survey of Rust Embeddable Scripting Languages</a>, for several that can be used in Rust A comparison of the usage of different scripting languages (including Lua).</p>
</li>
<li>
<p><a href="https://github.com/rust-lang/rust/pull/47857">Implement TryFrom for float to integer types</a>.</p>
</li>
<li>
<p><a href="https://gist.github.com/CrockAgile/09065649ae5a52629599ebc5645922d6">Floating Point Arcade</a>, an introduction to converting integer random numbers to floating point numbers.</p>
</li>
<li>
<p><a href="https://nnethercote.github.io/perf-book/title-page.html">The Rust Performance Book</a>.</p>
</li>
<li>
<p>《Lua设计与实现》, it feels like a source code reading note of Lua's official implementation. It directly talks about the details of the code implementation, and it is very difficult to read when you first get started.</p>
</li>
<li>
<p>《自己动手实现Lua》, which is very similar to this series of articles, also implements a Lua interpreter from scratch. But this book is based on the bytecode definition in the official implementation of Lua as the starting point. First implement the virtual machine to execute the bytecode, and then implement the compiler to generate the bytecode. And our series of articles is based on the Lua language manual, designing and implementing the compilation process, virtual machine, bytecode definition, etc.</p>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
